{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSVm2q6pXdlWq1rL0KQyvj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VrijKun/CS6910_Assignement_3/blob/main/DL_Assignement_3_local_run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lHT4qEMQnyv",
        "outputId": "20f8d442-c9e5-45d5-b70d-30bc56a72709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May 14 21:52:21 2024       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 551.78                 Driver Version: 551.78         CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA T1000                 WDDM  |   00000000:01:00.0  On |                  N/A |\n",
            "| 35%   46C    P8             N/A /   50W |     643MiB /   4096MiB |      1%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A      2120    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
            "|    0   N/A  N/A      6832    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
            "|    0   N/A  N/A     11084    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
            "|    0   N/A  N/A     11332    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
            "|    0   N/A  N/A     11372    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
            "|    0   N/A  N/A     11384    C+G   ...__8wekyb3d8bbwe\\Microsoft.Notes.exe      N/A      |\n",
            "|    0   N/A  N/A     14204    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
            "|    0   N/A  N/A     15380    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
            "|    0   N/A  N/A     15760    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
            "|    0   N/A  N/A     17796    C+G   ...e Stream\\90.0.3.0\\GoogleDriveFS.exe      N/A      |\n",
            "|    0   N/A  N/A     19784    C+G   ...on\\124.0.2478.97\\msedgewebview2.exe      N/A      |\n",
            "|    0   N/A  N/A     20332    C+G   ...\\Local\\slack\\app-4.38.115\\slack.exe      N/A      |\n",
            "|    0   N/A  N/A     21420    C+G   ...on\\124.0.2478.80\\msedgewebview2.exe      N/A      |\n",
            "|    0   N/A  N/A     22132    C+G   ...41.0_x64__v10z8vjag6ke6\\HP.myHP.exe      N/A      |\n",
            "|    0   N/A  N/A     22436    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe      N/A      |\n",
            "|    0   N/A  N/A     23052    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
            "|    0   N/A  N/A     27348    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
            "|    0   N/A  N/A     28404    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For local run time you don't have to run this\n",
        "!yes | wget \"https://drive.google.com/drive/folders/1tmm5HT2Zwj-4vDZzRFc4Av4KoWHYowoG?usp=sharing\""
      ],
      "metadata": {
        "id": "DNTkPBjP9dlM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a43a698-241a-4053-8b8b-1a14a5c3c735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'yes' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For local run time you don't have to run this\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "6vIU8i0W7h5V",
        "outputId": "f48765ae-c066-4d72-b83f-635e5e0207c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# For local run time you don't have to run this\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      3\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIpsTgHh9eYR",
        "outputId": "58de07a5-4f53-4ada-cd39-f308ddfd54a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas\n",
            "  Downloading pandas-2.0.3-cp38-cp38-win_amd64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asl 5\\.conda\\envs\\cuda121_pytorch222\\lib\\site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asl 5\\.conda\\envs\\cuda121_pytorch222\\lib\\site-packages (from pandas) (2023.3.post1)\n",
            "Collecting tzdata>=2022.1 (from pandas)\n",
            "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\asl 5\\.conda\\envs\\cuda121_pytorch222\\lib\\site-packages (from pandas) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\asl 5\\.conda\\envs\\cuda121_pytorch222\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Downloading pandas-2.0.3-cp38-cp38-win_amd64.whl (10.8 MB)\n",
            "   ---------------------------------------- 0.0/10.8 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/10.8 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.1/10.8 MB 2.1 MB/s eta 0:00:05\n",
            "    --------------------------------------- 0.2/10.8 MB 1.5 MB/s eta 0:00:08\n",
            "    --------------------------------------- 0.2/10.8 MB 1.3 MB/s eta 0:00:09\n",
            "   - -------------------------------------- 0.3/10.8 MB 1.4 MB/s eta 0:00:08\n",
            "   - -------------------------------------- 0.4/10.8 MB 1.3 MB/s eta 0:00:09\n",
            "   - -------------------------------------- 0.4/10.8 MB 1.3 MB/s eta 0:00:08\n",
            "   - -------------------------------------- 0.5/10.8 MB 1.2 MB/s eta 0:00:09\n",
            "   - -------------------------------------- 0.5/10.8 MB 1.3 MB/s eta 0:00:08\n",
            "   -- ------------------------------------- 0.6/10.8 MB 1.2 MB/s eta 0:00:09\n",
            "   -- ------------------------------------- 0.6/10.8 MB 1.2 MB/s eta 0:00:09\n",
            "   -- ------------------------------------- 0.6/10.8 MB 1.1 MB/s eta 0:00:09\n",
            "   -- ------------------------------------- 0.7/10.8 MB 1.1 MB/s eta 0:00:10\n",
            "   -- ------------------------------------- 0.7/10.8 MB 1.1 MB/s eta 0:00:10\n",
            "   -- ------------------------------------- 0.7/10.8 MB 975.9 kB/s eta 0:00:11\n",
            "   -- ------------------------------------- 0.7/10.8 MB 969.4 kB/s eta 0:00:11\n",
            "   -- ------------------------------------- 0.7/10.8 MB 969.4 kB/s eta 0:00:11\n",
            "   -- ------------------------------------- 0.7/10.8 MB 873.6 kB/s eta 0:00:12\n",
            "   -- ------------------------------------- 0.8/10.8 MB 847.7 kB/s eta 0:00:12\n",
            "   -- ------------------------------------- 0.8/10.8 MB 841.5 kB/s eta 0:00:12\n",
            "   --- ------------------------------------ 0.8/10.8 MB 845.4 kB/s eta 0:00:12\n",
            "   --- ------------------------------------ 0.8/10.8 MB 814.4 kB/s eta 0:00:13\n",
            "   --- ------------------------------------ 0.9/10.8 MB 795.6 kB/s eta 0:00:13\n",
            "   --- ------------------------------------ 0.9/10.8 MB 795.6 kB/s eta 0:00:13\n",
            "   --- ------------------------------------ 0.9/10.8 MB 795.6 kB/s eta 0:00:13\n",
            "   --- ------------------------------------ 0.9/10.8 MB 795.6 kB/s eta 0:00:13\n",
            "   --- ------------------------------------ 0.9/10.8 MB 694.8 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 694.8 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 678.1 kB/s eta 0:00:15\n",
            "   --- ------------------------------------ 0.9/10.8 MB 142.7 kB/s eta 0:01:09\n",
            "   --- ------------------------------------ 1.0/10.8 MB 144.8 kB/s eta 0:01:08\n",
            "   --- ------------------------------------ 1.0/10.8 MB 147.2 kB/s eta 0:01:07\n",
            "   --- ------------------------------------ 1.0/10.8 MB 147.3 kB/s eta 0:01:07\n",
            "   --- ------------------------------------ 1.0/10.8 MB 150.9 kB/s eta 0:01:05\n",
            "   --- ------------------------------------ 1.0/10.8 MB 150.9 kB/s eta 0:01:05\n",
            "   --- ------------------------------------ 1.0/10.8 MB 152.2 kB/s eta 0:01:04\n",
            "   --- ------------------------------------ 1.1/10.8 MB 154.5 kB/s eta 0:01:03\n",
            "   --- ------------------------------------ 1.1/10.8 MB 154.5 kB/s eta 0:01:03\n",
            "   ---- ----------------------------------- 1.1/10.8 MB 156.8 kB/s eta 0:01:02\n",
            "   ---- ----------------------------------- 1.1/10.8 MB 156.8 kB/s eta 0:01:02\n",
            "   ---- ----------------------------------- 1.1/10.8 MB 156.8 kB/s eta 0:01:02\n",
            "   ---- ----------------------------------- 1.1/10.8 MB 156.8 kB/s eta 0:01:02\n",
            "   ---- ----------------------------------- 1.1/10.8 MB 156.0 kB/s eta 0:01:02\n",
            "   ---- ----------------------------------- 1.2/10.8 MB 160.3 kB/s eta 0:01:00\n",
            "   ---- ----------------------------------- 1.2/10.8 MB 166.3 kB/s eta 0:00:58\n",
            "   ---- ----------------------------------- 1.2/10.8 MB 166.3 kB/s eta 0:00:58\n",
            "   ---- ----------------------------------- 1.2/10.8 MB 166.3 kB/s eta 0:00:58\n",
            "   ---- ----------------------------------- 1.2/10.8 MB 166.3 kB/s eta 0:00:58\n",
            "   ---- ----------------------------------- 1.2/10.8 MB 166.3 kB/s eta 0:00:58\n",
            "   ---- ----------------------------------- 1.2/10.8 MB 166.3 kB/s eta 0:00:58\n",
            "   ---- ----------------------------------- 1.2/10.8 MB 166.3 kB/s eta 0:00:58\n",
            "   ---- ----------------------------------- 1.2/10.8 MB 166.3 kB/s eta 0:00:58\n",
            "   ---- ----------------------------------- 1.2/10.8 MB 166.3 kB/s eta 0:00:58\n",
            "   ---- ----------------------------------- 1.2/10.8 MB 159.2 kB/s eta 0:01:00\n",
            "   ---- ----------------------------------- 1.3/10.8 MB 162.5 kB/s eta 0:00:59\n",
            "   ---- ----------------------------------- 1.3/10.8 MB 165.8 kB/s eta 0:00:58\n",
            "   ----- ---------------------------------- 1.4/10.8 MB 175.9 kB/s eta 0:00:54\n",
            "   ----- ---------------------------------- 1.4/10.8 MB 180.4 kB/s eta 0:00:52\n",
            "   ----- ---------------------------------- 1.5/10.8 MB 190.6 kB/s eta 0:00:49\n",
            "   ----- ---------------------------------- 1.6/10.8 MB 198.8 kB/s eta 0:00:47\n",
            "   ------ --------------------------------- 1.7/10.8 MB 207.4 kB/s eta 0:00:44\n",
            "   ------ --------------------------------- 1.7/10.8 MB 213.4 kB/s eta 0:00:43\n",
            "   ------ --------------------------------- 1.8/10.8 MB 218.9 kB/s eta 0:00:42\n",
            "   ------ --------------------------------- 1.8/10.8 MB 219.7 kB/s eta 0:00:41\n",
            "   ------ --------------------------------- 1.8/10.8 MB 219.7 kB/s eta 0:00:41\n",
            "   ------ --------------------------------- 1.9/10.8 MB 222.2 kB/s eta 0:00:41\n",
            "   ------- -------------------------------- 1.9/10.8 MB 230.3 kB/s eta 0:00:39\n",
            "   ------- -------------------------------- 2.0/10.8 MB 233.5 kB/s eta 0:00:38\n",
            "   ------- -------------------------------- 2.1/10.8 MB 245.9 kB/s eta 0:00:36\n",
            "   -------- ------------------------------- 2.2/10.8 MB 254.2 kB/s eta 0:00:34\n",
            "   -------- ------------------------------- 2.3/10.8 MB 262.4 kB/s eta 0:00:33\n",
            "   -------- ------------------------------- 2.3/10.8 MB 266.2 kB/s eta 0:00:32\n",
            "   -------- ------------------------------- 2.4/10.8 MB 278.0 kB/s eta 0:00:31\n",
            "   --------- ------------------------------ 2.4/10.8 MB 281.0 kB/s eta 0:00:30\n",
            "   --------- ------------------------------ 2.5/10.8 MB 286.1 kB/s eta 0:00:29\n",
            "   --------- ------------------------------ 2.5/10.8 MB 286.9 kB/s eta 0:00:29\n",
            "   --------- ------------------------------ 2.6/10.8 MB 289.4 kB/s eta 0:00:29\n",
            "   --------- ------------------------------ 2.6/10.8 MB 290.8 kB/s eta 0:00:29\n",
            "   --------- ------------------------------ 2.6/10.8 MB 292.0 kB/s eta 0:00:28\n",
            "   --------- ------------------------------ 2.6/10.8 MB 292.9 kB/s eta 0:00:28\n",
            "   --------- ------------------------------ 2.7/10.8 MB 294.8 kB/s eta 0:00:28\n",
            "   ---------- ----------------------------- 2.7/10.8 MB 298.4 kB/s eta 0:00:27\n",
            "   ---------- ----------------------------- 2.7/10.8 MB 298.4 kB/s eta 0:00:27\n",
            "   ---------- ----------------------------- 2.8/10.8 MB 299.7 kB/s eta 0:00:27\n",
            "   ---------- ----------------------------- 2.8/10.8 MB 301.5 kB/s eta 0:00:27\n",
            "   ---------- ----------------------------- 2.8/10.8 MB 304.4 kB/s eta 0:00:27\n",
            "   ---------- ----------------------------- 2.8/10.8 MB 304.5 kB/s eta 0:00:27\n",
            "   ---------- ----------------------------- 2.9/10.8 MB 307.5 kB/s eta 0:00:26\n",
            "   ---------- ----------------------------- 2.9/10.8 MB 309.1 kB/s eta 0:00:26\n",
            "   ---------- ----------------------------- 2.9/10.8 MB 310.9 kB/s eta 0:00:26\n",
            "   ----------- ---------------------------- 3.0/10.8 MB 314.2 kB/s eta 0:00:25\n",
            "   ----------- ---------------------------- 3.0/10.8 MB 314.8 kB/s eta 0:00:25\n",
            "   ----------- ---------------------------- 3.0/10.8 MB 314.4 kB/s eta 0:00:25\n",
            "   ----------- ---------------------------- 3.0/10.8 MB 314.4 kB/s eta 0:00:25\n",
            "   ----------- ---------------------------- 3.1/10.8 MB 314.0 kB/s eta 0:00:25\n",
            "   ----------- ---------------------------- 3.1/10.8 MB 316.7 kB/s eta 0:00:25\n",
            "   ----------- ---------------------------- 3.2/10.8 MB 320.4 kB/s eta 0:00:24\n",
            "   ----------- ---------------------------- 3.2/10.8 MB 323.0 kB/s eta 0:00:24\n",
            "   ----------- ---------------------------- 3.2/10.8 MB 323.0 kB/s eta 0:00:24\n",
            "   ------------ --------------------------- 3.2/10.8 MB 324.6 kB/s eta 0:00:24\n",
            "   ------------ --------------------------- 3.2/10.8 MB 324.6 kB/s eta 0:00:24\n",
            "   ------------ --------------------------- 3.3/10.8 MB 324.6 kB/s eta 0:00:24\n",
            "   ------------ --------------------------- 3.3/10.8 MB 327.7 kB/s eta 0:00:23\n",
            "   ------------ --------------------------- 3.3/10.8 MB 328.2 kB/s eta 0:00:23\n",
            "   ------------ --------------------------- 3.4/10.8 MB 327.7 kB/s eta 0:00:23\n",
            "   ------------ --------------------------- 3.4/10.8 MB 330.7 kB/s eta 0:00:23\n",
            "   ------------ --------------------------- 3.4/10.8 MB 332.7 kB/s eta 0:00:23\n",
            "   ------------ --------------------------- 3.4/10.8 MB 332.7 kB/s eta 0:00:23\n",
            "   ------------ --------------------------- 3.4/10.8 MB 332.7 kB/s eta 0:00:23\n",
            "   ------------ --------------------------- 3.4/10.8 MB 332.7 kB/s eta 0:00:23\n",
            "   ------------- -------------------------- 3.6/10.8 MB 339.4 kB/s eta 0:00:22\n",
            "   ------------- -------------------------- 3.6/10.8 MB 340.3 kB/s eta 0:00:22\n",
            "   ------------- -------------------------- 3.7/10.8 MB 346.0 kB/s eta 0:00:21\n",
            "   ------------- -------------------------- 3.7/10.8 MB 350.3 kB/s eta 0:00:21\n",
            "   ------------- -------------------------- 3.8/10.8 MB 351.2 kB/s eta 0:00:20\n",
            "   -------------- ------------------------- 3.8/10.8 MB 356.3 kB/s eta 0:00:20\n",
            "   -------------- ------------------------- 3.9/10.8 MB 359.4 kB/s eta 0:00:20\n",
            "   -------------- ------------------------- 4.0/10.8 MB 363.6 kB/s eta 0:00:19\n",
            "   -------------- ------------------------- 4.0/10.8 MB 364.4 kB/s eta 0:00:19\n",
            "   -------------- ------------------------- 4.0/10.8 MB 367.4 kB/s eta 0:00:19\n",
            "   --------------- ------------------------ 4.1/10.8 MB 373.3 kB/s eta 0:00:18\n",
            "   --------------- ------------------------ 4.2/10.8 MB 376.3 kB/s eta 0:00:18\n",
            "   --------------- ------------------------ 4.2/10.8 MB 379.8 kB/s eta 0:00:18\n",
            "   --------------- ------------------------ 4.2/10.8 MB 381.1 kB/s eta 0:00:18\n",
            "   --------------- ------------------------ 4.3/10.8 MB 384.0 kB/s eta 0:00:17\n",
            "   ---------------- ----------------------- 4.3/10.8 MB 385.6 kB/s eta 0:00:17\n",
            "   ---------------- ----------------------- 4.4/10.8 MB 388.5 kB/s eta 0:00:17\n",
            "   ---------------- ----------------------- 4.5/10.8 MB 391.8 kB/s eta 0:00:17\n",
            "   ---------------- ----------------------- 4.5/10.8 MB 393.0 kB/s eta 0:00:17\n",
            "   ---------------- ----------------------- 4.5/10.8 MB 393.0 kB/s eta 0:00:17\n",
            "   ---------------- ----------------------- 4.5/10.8 MB 393.0 kB/s eta 0:00:17\n",
            "   ---------------- ----------------------- 4.5/10.8 MB 393.0 kB/s eta 0:00:17\n",
            "   ---------------- ----------------------- 4.5/10.8 MB 393.0 kB/s eta 0:00:17\n",
            "   ---------------- ----------------------- 4.5/10.8 MB 393.0 kB/s eta 0:00:17\n",
            "   ---------------- ----------------------- 4.5/10.8 MB 393.0 kB/s eta 0:00:17\n",
            "   ---------------- ----------------------- 4.5/10.8 MB 393.0 kB/s eta 0:00:17\n",
            "   ---------------- ----------------------- 4.5/10.8 MB 393.0 kB/s eta 0:00:17\n",
            "   ---------------- ----------------------- 4.5/10.8 MB 393.0 kB/s eta 0:00:17\n",
            "   ---------------- ----------------------- 4.5/10.8 MB 393.0 kB/s eta 0:00:17\n",
            "   ---------------- ----------------------- 4.5/10.8 MB 377.2 kB/s eta 0:00:17\n",
            "   ---------------- ----------------------- 4.5/10.8 MB 377.2 kB/s eta 0:00:17\n",
            "   ---------------- ----------------------- 4.5/10.8 MB 377.2 kB/s eta 0:00:17\n",
            "   ---------------- ----------------------- 4.5/10.8 MB 377.2 kB/s eta 0:00:17\n",
            "   ----------------- ---------------------- 4.6/10.8 MB 379.2 kB/s eta 0:00:17\n",
            "   ----------------- ---------------------- 4.6/10.8 MB 379.9 kB/s eta 0:00:17\n",
            "   ----------------- ---------------------- 4.7/10.8 MB 381.3 kB/s eta 0:00:17\n",
            "   ----------------- ---------------------- 4.7/10.8 MB 383.2 kB/s eta 0:00:16\n",
            "   ----------------- ---------------------- 4.8/10.8 MB 386.7 kB/s eta 0:00:16\n",
            "   ------------------ --------------------- 4.9/10.8 MB 391.4 kB/s eta 0:00:16\n",
            "   ------------------ --------------------- 4.9/10.8 MB 394.5 kB/s eta 0:00:15\n",
            "   ------------------ --------------------- 4.9/10.8 MB 394.5 kB/s eta 0:00:15\n",
            "   ------------------ --------------------- 4.9/10.8 MB 394.0 kB/s eta 0:00:15\n",
            "   ------------------ --------------------- 5.0/10.8 MB 397.0 kB/s eta 0:00:15\n",
            "   ------------------ --------------------- 5.0/10.8 MB 398.8 kB/s eta 0:00:15\n",
            "   ------------------ --------------------- 5.1/10.8 MB 401.6 kB/s eta 0:00:15\n",
            "   ------------------- -------------------- 5.2/10.8 MB 404.7 kB/s eta 0:00:14\n",
            "   ------------------- -------------------- 5.2/10.8 MB 406.1 kB/s eta 0:00:14\n",
            "   ------------------- -------------------- 5.3/10.8 MB 410.0 kB/s eta 0:00:14\n",
            "   ------------------- -------------------- 5.3/10.8 MB 412.5 kB/s eta 0:00:14\n",
            "   ------------------- -------------------- 5.3/10.8 MB 413.9 kB/s eta 0:00:14\n",
            "   ------------------- -------------------- 5.4/10.8 MB 414.8 kB/s eta 0:00:14\n",
            "   -------------------- ------------------- 5.4/10.8 MB 414.8 kB/s eta 0:00:13\n",
            "   -------------------- ------------------- 5.4/10.8 MB 415.7 kB/s eta 0:00:13\n",
            "   -------------------- ------------------- 5.4/10.8 MB 415.7 kB/s eta 0:00:13\n",
            "   -------------------- ------------------- 5.5/10.8 MB 414.6 kB/s eta 0:00:13\n",
            "   -------------------- ------------------- 5.5/10.8 MB 415.4 kB/s eta 0:00:13\n",
            "   -------------------- ------------------- 5.5/10.8 MB 415.4 kB/s eta 0:00:13\n",
            "   -------------------- ------------------- 5.5/10.8 MB 415.4 kB/s eta 0:00:13\n",
            "   -------------------- ------------------- 5.5/10.8 MB 415.4 kB/s eta 0:00:13\n",
            "   -------------------- ------------------- 5.5/10.8 MB 415.4 kB/s eta 0:00:13\n",
            "   -------------------- ------------------- 5.5/10.8 MB 415.4 kB/s eta 0:00:13\n",
            "   -------------------- ------------------- 5.5/10.8 MB 415.4 kB/s eta 0:00:13\n",
            "   -------------------- ------------------- 5.5/10.8 MB 415.4 kB/s eta 0:00:13\n",
            "   -------------------- ------------------- 5.5/10.8 MB 415.4 kB/s eta 0:00:13\n",
            "   -------------------- ------------------- 5.5/10.8 MB 415.4 kB/s eta 0:00:13\n",
            "   -------------------- ------------------- 5.5/10.8 MB 415.4 kB/s eta 0:00:13\n",
            "   -------------------- ------------------- 5.5/10.8 MB 415.4 kB/s eta 0:00:13\n",
            "   -------------------- ------------------- 5.5/10.8 MB 415.4 kB/s eta 0:00:13\n",
            "   -------------------- ------------------- 5.5/10.8 MB 397.7 kB/s eta 0:00:14\n",
            "   -------------------- ------------------- 5.5/10.8 MB 398.2 kB/s eta 0:00:14\n",
            "   -------------------- ------------------- 5.6/10.8 MB 398.7 kB/s eta 0:00:14\n",
            "   -------------------- ------------------- 5.6/10.8 MB 400.1 kB/s eta 0:00:13\n",
            "   -------------------- ------------------- 5.6/10.8 MB 399.9 kB/s eta 0:00:13\n",
            "   -------------------- ------------------- 5.6/10.8 MB 400.1 kB/s eta 0:00:13\n",
            "   -------------------- ------------------- 5.7/10.8 MB 399.9 kB/s eta 0:00:13\n",
            "   --------------------- ------------------ 5.7/10.8 MB 401.0 kB/s eta 0:00:13\n",
            "   --------------------- ------------------ 5.7/10.8 MB 401.0 kB/s eta 0:00:13\n",
            "   --------------------- ------------------ 5.7/10.8 MB 400.8 kB/s eta 0:00:13\n",
            "   --------------------- ------------------ 5.8/10.8 MB 401.4 kB/s eta 0:00:13\n",
            "   --------------------- ------------------ 5.8/10.8 MB 401.1 kB/s eta 0:00:13\n",
            "   --------------------- ------------------ 5.8/10.8 MB 401.1 kB/s eta 0:00:13\n",
            "   --------------------- ------------------ 5.8/10.8 MB 400.0 kB/s eta 0:00:13\n",
            "   --------------------- ------------------ 5.8/10.8 MB 400.0 kB/s eta 0:00:13\n",
            "   --------------------- ------------------ 5.8/10.8 MB 400.0 kB/s eta 0:00:13\n",
            "   --------------------- ------------------ 5.8/10.8 MB 398.3 kB/s eta 0:00:13\n",
            "   --------------------- ------------------ 5.9/10.8 MB 399.4 kB/s eta 0:00:13\n",
            "   --------------------- ------------------ 5.9/10.8 MB 399.8 kB/s eta 0:00:13\n",
            "   --------------------- ------------------ 5.9/10.8 MB 399.2 kB/s eta 0:00:13\n",
            "   ---------------------- ----------------- 5.9/10.8 MB 400.3 kB/s eta 0:00:13\n",
            "   ---------------------- ----------------- 5.9/10.8 MB 400.3 kB/s eta 0:00:13\n",
            "   ---------------------- ----------------- 5.9/10.8 MB 399.3 kB/s eta 0:00:13\n",
            "   ---------------------- ----------------- 6.0/10.8 MB 399.4 kB/s eta 0:00:13\n",
            "   ---------------------- ----------------- 6.0/10.8 MB 399.4 kB/s eta 0:00:13\n",
            "   ---------------------- ----------------- 6.0/10.8 MB 399.4 kB/s eta 0:00:13\n",
            "   ---------------------- ----------------- 6.0/10.8 MB 399.4 kB/s eta 0:00:13\n",
            "   ---------------------- ----------------- 6.0/10.8 MB 399.4 kB/s eta 0:00:13\n",
            "   ---------------------- ----------------- 6.0/10.8 MB 395.0 kB/s eta 0:00:13\n",
            "   ---------------------- ----------------- 6.1/10.8 MB 395.8 kB/s eta 0:00:12\n",
            "   ---------------------- ----------------- 6.1/10.8 MB 395.6 kB/s eta 0:00:12\n",
            "   ---------------------- ----------------- 6.1/10.8 MB 395.6 kB/s eta 0:00:12\n",
            "   ---------------------- ----------------- 6.1/10.8 MB 395.6 kB/s eta 0:00:12\n",
            "   ---------------------- ----------------- 6.1/10.8 MB 395.6 kB/s eta 0:00:12\n",
            "   ---------------------- ----------------- 6.1/10.8 MB 395.6 kB/s eta 0:00:12\n",
            "   ---------------------- ----------------- 6.1/10.8 MB 395.6 kB/s eta 0:00:12\n",
            "   ---------------------- ----------------- 6.1/10.8 MB 395.6 kB/s eta 0:00:12\n",
            "   ---------------------- ----------------- 6.1/10.8 MB 395.6 kB/s eta 0:00:12\n",
            "   ---------------------- ----------------- 6.1/10.8 MB 386.7 kB/s eta 0:00:13\n",
            "   ---------------------- ----------------- 6.1/10.8 MB 386.7 kB/s eta 0:00:13\n",
            "   ---------------------- ----------------- 6.1/10.8 MB 386.3 kB/s eta 0:00:13\n",
            "   ---------------------- ----------------- 6.1/10.8 MB 387.1 kB/s eta 0:00:12\n",
            "   ---------------------- ----------------- 6.2/10.8 MB 389.0 kB/s eta 0:00:12\n",
            "   ----------------------- ---------------- 6.2/10.8 MB 389.0 kB/s eta 0:00:12\n",
            "   ----------------------- ---------------- 6.2/10.8 MB 389.0 kB/s eta 0:00:12\n",
            "   ----------------------- ---------------- 6.2/10.8 MB 387.3 kB/s eta 0:00:12\n",
            "   ----------------------- ---------------- 6.3/10.8 MB 388.8 kB/s eta 0:00:12\n",
            "   ----------------------- ---------------- 6.3/10.8 MB 390.4 kB/s eta 0:00:12\n",
            "   ----------------------- ---------------- 6.3/10.8 MB 391.1 kB/s eta 0:00:12\n",
            "   ----------------------- ---------------- 6.3/10.8 MB 391.1 kB/s eta 0:00:12\n",
            "   ----------------------- ---------------- 6.3/10.8 MB 391.1 kB/s eta 0:00:12\n",
            "   ----------------------- ---------------- 6.3/10.8 MB 391.1 kB/s eta 0:00:12\n",
            "   ----------------------- ---------------- 6.3/10.8 MB 391.1 kB/s eta 0:00:12\n",
            "   ----------------------- ---------------- 6.3/10.8 MB 391.1 kB/s eta 0:00:12\n",
            "   ----------------------- ---------------- 6.3/10.8 MB 391.1 kB/s eta 0:00:12\n",
            "   ----------------------- ---------------- 6.3/10.8 MB 383.4 kB/s eta 0:00:12\n",
            "   ----------------------- ---------------- 6.4/10.8 MB 383.0 kB/s eta 0:00:12\n",
            "   ----------------------- ---------------- 6.4/10.8 MB 383.0 kB/s eta 0:00:12\n",
            "   ----------------------- ---------------- 6.4/10.8 MB 383.9 kB/s eta 0:00:12\n",
            "   ----------------------- ---------------- 6.4/10.8 MB 383.9 kB/s eta 0:00:12\n",
            "   ----------------------- ---------------- 6.4/10.8 MB 383.9 kB/s eta 0:00:12\n",
            "   ------------------------ --------------- 6.5/10.8 MB 384.7 kB/s eta 0:00:12\n",
            "   ------------------------ --------------- 6.5/10.8 MB 384.7 kB/s eta 0:00:12\n",
            "   ------------------------ --------------- 6.5/10.8 MB 384.7 kB/s eta 0:00:12\n",
            "   ------------------------ --------------- 6.5/10.8 MB 384.7 kB/s eta 0:00:12\n",
            "   ------------------------ --------------- 6.5/10.8 MB 384.7 kB/s eta 0:00:12\n",
            "   ------------------------ --------------- 6.5/10.8 MB 384.7 kB/s eta 0:00:12\n",
            "   ------------------------ --------------- 6.5/10.8 MB 384.7 kB/s eta 0:00:12\n",
            "   ------------------------ --------------- 6.5/10.8 MB 384.7 kB/s eta 0:00:12\n",
            "   ------------------------ --------------- 6.5/10.8 MB 384.7 kB/s eta 0:00:12\n",
            "   ------------------------ --------------- 6.5/10.8 MB 376.1 kB/s eta 0:00:12\n",
            "   ------------------------ --------------- 6.5/10.8 MB 376.3 kB/s eta 0:00:12\n",
            "   ------------------------ --------------- 6.6/10.8 MB 377.3 kB/s eta 0:00:12\n",
            "   ------------------------ --------------- 6.6/10.8 MB 377.1 kB/s eta 0:00:12\n",
            "   ------------------------ --------------- 6.6/10.8 MB 380.0 kB/s eta 0:00:11\n",
            "   ------------------------ --------------- 6.7/10.8 MB 381.2 kB/s eta 0:00:11\n",
            "   ------------------------ --------------- 6.7/10.8 MB 381.2 kB/s eta 0:00:11\n",
            "   ------------------------ --------------- 6.7/10.8 MB 381.2 kB/s eta 0:00:11\n",
            "   ------------------------ --------------- 6.7/10.8 MB 381.2 kB/s eta 0:00:11\n",
            "   ------------------------ --------------- 6.7/10.8 MB 381.2 kB/s eta 0:00:11\n",
            "   ------------------------ --------------- 6.7/10.8 MB 381.2 kB/s eta 0:00:11\n",
            "   ------------------------ --------------- 6.7/10.8 MB 381.2 kB/s eta 0:00:11\n",
            "   ------------------------ --------------- 6.7/10.8 MB 381.2 kB/s eta 0:00:11\n",
            "   ------------------------ --------------- 6.7/10.8 MB 381.2 kB/s eta 0:00:11\n",
            "   ------------------------ --------------- 6.7/10.8 MB 381.2 kB/s eta 0:00:11\n",
            "   ------------------------- -------------- 6.7/10.8 MB 373.4 kB/s eta 0:00:11\n",
            "   ------------------------- -------------- 6.8/10.8 MB 375.9 kB/s eta 0:00:11\n",
            "   ------------------------- -------------- 6.9/10.8 MB 378.9 kB/s eta 0:00:11\n",
            "   ------------------------- -------------- 6.9/10.8 MB 379.8 kB/s eta 0:00:11\n",
            "   ------------------------- -------------- 6.9/10.8 MB 380.6 kB/s eta 0:00:11\n",
            "   ------------------------- -------------- 7.0/10.8 MB 382.9 kB/s eta 0:00:10\n",
            "   -------------------------- ------------- 7.0/10.8 MB 384.2 kB/s eta 0:00:10\n",
            "   -------------------------- ------------- 7.1/10.8 MB 387.1 kB/s eta 0:00:10\n",
            "   -------------------------- ------------- 7.2/10.8 MB 389.8 kB/s eta 0:00:10\n",
            "   --------------------------- ------------ 7.3/10.8 MB 393.9 kB/s eta 0:00:09\n",
            "   --------------------------- ------------ 7.3/10.8 MB 395.7 kB/s eta 0:00:09\n",
            "   --------------------------- ------------ 7.4/10.8 MB 399.1 kB/s eta 0:00:09\n",
            "   --------------------------- ------------ 7.5/10.8 MB 401.9 kB/s eta 0:00:09\n",
            "   ---------------------------- ----------- 7.6/10.8 MB 405.3 kB/s eta 0:00:08\n",
            "   ---------------------------- ----------- 7.6/10.8 MB 405.9 kB/s eta 0:00:08\n",
            "   ---------------------------- ----------- 7.6/10.8 MB 405.9 kB/s eta 0:00:08\n",
            "   ---------------------------- ----------- 7.6/10.8 MB 405.9 kB/s eta 0:00:08\n",
            "   ---------------------------- ----------- 7.6/10.8 MB 405.9 kB/s eta 0:00:08\n",
            "   ---------------------------- ----------- 7.6/10.8 MB 405.9 kB/s eta 0:00:08\n",
            "   ---------------------------- ----------- 7.6/10.8 MB 405.9 kB/s eta 0:00:08\n",
            "   ---------------------------- ----------- 7.6/10.8 MB 405.9 kB/s eta 0:00:08\n",
            "   ---------------------------- ----------- 7.6/10.8 MB 405.9 kB/s eta 0:00:08\n",
            "   ---------------------------- ----------- 7.6/10.8 MB 405.9 kB/s eta 0:00:08\n",
            "   ---------------------------- ----------- 7.6/10.8 MB 405.9 kB/s eta 0:00:08\n",
            "   ---------------------------- ----------- 7.6/10.8 MB 405.9 kB/s eta 0:00:08\n",
            "   ---------------------------- ----------- 7.6/10.8 MB 405.9 kB/s eta 0:00:08\n",
            "   ---------------------------- ----------- 7.6/10.8 MB 405.9 kB/s eta 0:00:08\n",
            "   ---------------------------- ----------- 7.6/10.8 MB 405.9 kB/s eta 0:00:08\n",
            "   ---------------------------- ----------- 7.6/10.8 MB 405.9 kB/s eta 0:00:08\n",
            "   ---------------------------- ----------- 7.7/10.8 MB 397.8 kB/s eta 0:00:08\n",
            "   ---------------------------- ----------- 7.7/10.8 MB 397.8 kB/s eta 0:00:08\n",
            "   ---------------------------- ----------- 7.8/10.8 MB 396.4 kB/s eta 0:00:08\n",
            "   ---------------------------- ----------- 7.8/10.8 MB 396.5 kB/s eta 0:00:08\n",
            "   ----------------------------- ---------- 7.8/10.8 MB 397.5 kB/s eta 0:00:08\n",
            "   ----------------------------- ---------- 7.9/10.8 MB 398.4 kB/s eta 0:00:08\n",
            "   ----------------------------- ---------- 7.9/10.8 MB 398.4 kB/s eta 0:00:08\n",
            "   ----------------------------- ---------- 7.9/10.8 MB 398.5 kB/s eta 0:00:08\n",
            "   ----------------------------- ---------- 7.9/10.8 MB 399.4 kB/s eta 0:00:08\n",
            "   ----------------------------- ---------- 7.9/10.8 MB 399.4 kB/s eta 0:00:08\n",
            "   ----------------------------- ---------- 7.9/10.8 MB 399.4 kB/s eta 0:00:08\n",
            "   ----------------------------- ---------- 7.9/10.8 MB 399.4 kB/s eta 0:00:08\n",
            "   ----------------------------- ---------- 7.9/10.8 MB 399.4 kB/s eta 0:00:08\n",
            "   ----------------------------- ---------- 7.9/10.8 MB 399.4 kB/s eta 0:00:08\n",
            "   ----------------------------- ---------- 7.9/10.8 MB 399.4 kB/s eta 0:00:08\n",
            "   ----------------------------- ---------- 7.9/10.8 MB 399.4 kB/s eta 0:00:08\n",
            "   ----------------------------- ---------- 7.9/10.8 MB 399.4 kB/s eta 0:00:08\n",
            "   ----------------------------- ---------- 7.9/10.8 MB 399.4 kB/s eta 0:00:08\n",
            "   ----------------------------- ---------- 7.9/10.8 MB 390.4 kB/s eta 0:00:08\n",
            "   ----------------------------- ---------- 8.0/10.8 MB 390.9 kB/s eta 0:00:08\n",
            "   ----------------------------- ---------- 8.0/10.8 MB 393.3 kB/s eta 0:00:07\n",
            "   ------------------------------ --------- 8.1/10.8 MB 396.1 kB/s eta 0:00:07\n",
            "   ------------------------------ --------- 8.2/10.8 MB 398.9 kB/s eta 0:00:07\n",
            "   ------------------------------ --------- 8.3/10.8 MB 401.3 kB/s eta 0:00:07\n",
            "   ------------------------------- -------- 8.4/10.8 MB 405.3 kB/s eta 0:00:06\n",
            "   ------------------------------- -------- 8.5/10.8 MB 409.7 kB/s eta 0:00:06\n",
            "   ------------------------------- -------- 8.5/10.8 MB 411.7 kB/s eta 0:00:06\n",
            "   ------------------------------- -------- 8.6/10.8 MB 413.7 kB/s eta 0:00:06\n",
            "   -------------------------------- ------- 8.6/10.8 MB 415.1 kB/s eta 0:00:06\n",
            "   -------------------------------- ------- 8.7/10.8 MB 417.4 kB/s eta 0:00:05\n",
            "   -------------------------------- ------- 8.7/10.8 MB 417.4 kB/s eta 0:00:05\n",
            "   -------------------------------- ------- 8.7/10.8 MB 417.4 kB/s eta 0:00:05\n",
            "   -------------------------------- ------- 8.7/10.8 MB 417.4 kB/s eta 0:00:05\n",
            "   -------------------------------- ------- 8.7/10.8 MB 417.4 kB/s eta 0:00:05\n",
            "   -------------------------------- ------- 8.7/10.8 MB 417.4 kB/s eta 0:00:05\n",
            "   -------------------------------- ------- 8.7/10.8 MB 417.4 kB/s eta 0:00:05\n",
            "   -------------------------------- ------- 8.7/10.8 MB 417.4 kB/s eta 0:00:05\n",
            "   -------------------------------- ------- 8.7/10.8 MB 417.4 kB/s eta 0:00:05\n",
            "   -------------------------------- ------- 8.7/10.8 MB 417.4 kB/s eta 0:00:05\n",
            "   -------------------------------- ------- 8.7/10.8 MB 408.2 kB/s eta 0:00:06\n",
            "   -------------------------------- ------- 8.8/10.8 MB 408.4 kB/s eta 0:00:05\n",
            "   -------------------------------- ------- 8.8/10.8 MB 408.4 kB/s eta 0:00:05\n",
            "   -------------------------------- ------- 8.9/10.8 MB 412.3 kB/s eta 0:00:05\n",
            "   --------------------------------- ------ 9.0/10.8 MB 416.4 kB/s eta 0:00:05\n",
            "   --------------------------------- ------ 9.1/10.8 MB 419.7 kB/s eta 0:00:05\n",
            "   ---------------------------------- ----- 9.2/10.8 MB 425.0 kB/s eta 0:00:04\n",
            "   ---------------------------------- ----- 9.3/10.8 MB 427.8 kB/s eta 0:00:04\n",
            "   ----------------------------------- ---- 9.5/10.8 MB 434.4 kB/s eta 0:00:04\n",
            "   ----------------------------------- ---- 9.5/10.8 MB 436.8 kB/s eta 0:00:03\n",
            "   ----------------------------------- ---- 9.7/10.8 MB 442.4 kB/s eta 0:00:03\n",
            "   ------------------------------------ --- 9.7/10.8 MB 444.2 kB/s eta 0:00:03\n",
            "   ------------------------------------ --- 9.8/10.8 MB 446.9 kB/s eta 0:00:03\n",
            "   ------------------------------------ --- 10.0/10.8 MB 451.6 kB/s eta 0:00:02\n",
            "   ------------------------------------- -- 10.1/10.8 MB 456.3 kB/s eta 0:00:02\n",
            "   ------------------------------------- -- 10.2/10.8 MB 459.0 kB/s eta 0:00:02\n",
            "   ------------------------------------- -- 10.2/10.8 MB 459.0 kB/s eta 0:00:02\n",
            "   -------------------------------------- - 10.3/10.8 MB 461.7 kB/s eta 0:00:02\n",
            "   -------------------------------------- - 10.4/10.8 MB 461.7 kB/s eta 0:00:01\n",
            "   ---------------------------------------  10.6/10.8 MB 464.0 kB/s eta 0:00:01\n",
            "   ---------------------------------------  10.7/10.8 MB 465.0 kB/s eta 0:00:01\n",
            "   ---------------------------------------- 10.8/10.8 MB 465.1 kB/s eta 0:00:00\n",
            "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "   ---------------------------------------- 0.0/345.4 kB ? eta -:--:--\n",
            "   --------- ------------------------------ 81.9/345.4 kB 4.5 MB/s eta 0:00:01\n",
            "   -------------------- ------------------- 174.1/345.4 kB 2.1 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 266.2/345.4 kB 2.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 345.4/345.4 kB 1.9 MB/s eta 0:00:00\n",
            "Installing collected packages: tzdata, pandas\n",
            "Successfully installed pandas-2.0.3 tzdata-2024.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pds\n",
        "\n",
        "# function for loading data\n",
        "def dt_ld(path):\n",
        "  with open(path) as fil :\n",
        "    dt = pds.read_csv(fil,sep=',',header=None,names=[\"eng\",\"hin\",\"\"],skip_blank_lines=True,index_col=None)\n",
        "  word_data = dt[dt['eng'].notna()]\n",
        "  word_data = dt[dt['hin'].notna()]\n",
        "  word_data = dt[['eng', 'hin']]\n",
        "  return word_data\n",
        "\n",
        "\n",
        "# Define the file paths for train, valid, and test data on your local machine\n",
        "train_file_path = r\"C:\\Users\\ASL 5\\Downloads\\aksharantar_sampled\\hin\\hin_train.csv\"\n",
        "valid_file_path = r\"C:\\Users\\ASL 5\\Downloads\\aksharantar_sampled\\hin\\hin_valid.csv\"\n",
        "test_file_path = r\"C:\\Users\\ASL 5\\Downloads\\aksharantar_sampled\\hin\\hin_test.csv\"\n",
        "\n",
        "# Load the data using the defined function\n",
        "train_data = dt_ld(train_file_path)\n",
        "valid_data = dt_ld(valid_file_path)\n",
        "test_data = dt_ld(test_file_path)\n",
        "\n",
        "# Display test_data\n",
        "print(test_data)\n",
        "\n",
        "# Extracting 'eng' and 'hin' columns into lists\n",
        "test_hin = list(test_data['hin'])\n",
        "test_eng = list(test_data['eng'])\n",
        "\n",
        "# Some visualization of data\n",
        "print(test_eng)\n",
        "print(test_hin)\n",
        "print(len(train_data))\n",
        "print(len(valid_data))\n",
        "print(len(test_data))"
      ],
      "metadata": {
        "id": "1d_5GXyE-dLF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0a600b37-6d75-4333-abe0-caf8077e6e38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnicodeDecodeError",
          "evalue": "'charmap' codec can't decode byte 0x8d in position 20: character maps to <undefined>",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[20], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m test_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mASL 5\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124maksharantar_sampled\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhin\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhin_test.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Load the data using the defined function\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mdt_ld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m valid_data \u001b[38;5;241m=\u001b[39m dt_ld(valid_file_path)\n\u001b[0;32m     21\u001b[0m test_data \u001b[38;5;241m=\u001b[39m dt_ld(test_file_path)\n",
            "Cell \u001b[1;32mIn[20], line 6\u001b[0m, in \u001b[0;36mdt_ld\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdt_ld\u001b[39m(path):\n\u001b[0;32m      5\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path) \u001b[38;5;28;01mas\u001b[39;00m fil :\n\u001b[1;32m----> 6\u001b[0m     dt \u001b[38;5;241m=\u001b[39m \u001b[43mpds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfil\u001b[49m\u001b[43m,\u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mskip_blank_lines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m   word_data \u001b[38;5;241m=\u001b[39m dt[dt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotna()]\n\u001b[0;32m      8\u001b[0m   word_data \u001b[38;5;241m=\u001b[39m dt[dt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhin\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotna()]\n",
            "File \u001b[1;32m~\\.conda\\envs\\Cuda121_pytorch222\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\.conda\\envs\\Cuda121_pytorch222\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32m~\\.conda\\envs\\Cuda121_pytorch222\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\.conda\\envs\\Cuda121_pytorch222\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1679\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1676\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1678\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1679\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1680\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32m~\\.conda\\envs\\Cuda121_pytorch222\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[43mparsers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
            "File \u001b[1;32m~\\.conda\\envs\\Cuda121_pytorch222\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:550\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32m~\\.conda\\envs\\Cuda121_pytorch222\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:742\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32m~\\.conda\\envs\\Cuda121_pytorch222\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:850\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32m~\\.conda\\envs\\Cuda121_pytorch222\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32m~\\.conda\\envs\\Cuda121_pytorch222\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:2021\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x8d in position 20: character maps to <undefined>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# You'll need to change the path based on the plce you have saved the files on your directory\n",
        "train_data = dt_ld(r\"C:\\Users\\ASL 5\\Downloads\\aksharantar_sampled\\hin\\hin_train.csv\")\n",
        "valid_data = dt_ld(r\"C:\\Users\\ASL 5\\Downloads\\aksharantar_sampled\\hin\\hin_valid.csv\")\n",
        "test_data = dt_ld(r\"C:\\Users\\ASL 5\\Downloads\\aksharantar_sampled\\hin\\hin_test.csv\")\n",
        "\n",
        "\n",
        "print(test_data)\n",
        "# Saving the data in CSV's again in list form\n",
        "test_hin = list(test_data['hin'])\n",
        "test_eng = list(test_data['eng'])\n",
        "\n",
        "# Some visualization of data\n",
        "print(test_eng)\n",
        "print(test_hin)\n",
        "print(len(train_data))\n",
        "print(len(valid_data))\n",
        "print(len(test_data))\n",
        "#print(\"test_hindi: \", test_hin)\n",
        "#print(\"test_english: \", test_eng)\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "train_data = dt_ld(\"/content/drive/MyDrive/aksharantar_sampled/hin/hin_train.csv\")\n",
        "valid_data = dt_ld(\"/content/drive/MyDrive/aksharantar_sampled/hin/hin_valid.csv\")\n",
        "test_data = dt_ld(\"/content/drive/MyDrive/aksharantar_sampled/hin/hin_test.csv\")\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "3QWSRb3k9TRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the function for loading data\n",
        "def dt_ld(path):\n",
        "    # Load data from the CSV file using pandas\n",
        "    dt = pd.read_csv(path, sep=',', header=None, names=[\"eng\", \"hin\", \"\"], skip_blank_lines=True, index_col=None, encoding='utf-8')\n",
        "\n",
        "    # Filter out rows where either 'eng' or 'hin' column is NaN\n",
        "    word_data = dt.dropna(subset=['eng', 'hin'])\n",
        "\n",
        "    # Select only 'eng' and 'hin' columns\n",
        "    word_data = word_data[['eng', 'hin']]\n",
        "\n",
        "    return word_data\n",
        "\n",
        "# Define the file paths for train, valid, and test data on your local machine\n",
        "train_file_path = r\"C:\\Users\\ASL 5\\Downloads\\aksharantar_sampled\\hin\\hin_train.csv\"\n",
        "valid_file_path = r\"C:\\Users\\ASL 5\\Downloads\\aksharantar_sampled\\hin\\hin_valid.csv\"\n",
        "test_file_path = r\"C:\\Users\\ASL 5\\Downloads\\aksharantar_sampled\\hin\\hin_test.csv\"\n",
        "\n",
        "# Load the data using the defined function\n",
        "train_data = dt_ld(train_file_path)\n",
        "valid_data = dt_ld(valid_file_path)\n",
        "test_data = dt_ld(test_file_path)\n",
        "\n",
        "# Display test_data\n",
        "print(test_data)\n",
        "\n",
        "# Extracting 'eng' and 'hin' columns into lists\n",
        "test_hin = list(test_data['hin'])\n",
        "test_eng = list(test_data['eng'])\n",
        "\n",
        "# Some visualization of data\n",
        "print(test_eng)\n",
        "print(test_hin)\n",
        "print(len(train_data))\n",
        "print(len(valid_data))\n",
        "print(len(test_data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mM37DYXfEbLZ",
        "outputId": "0dc8e573-d4c6-4a25-dc3f-d7d7dd4d572f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               eng          hin\n",
            "0          thermax      थरमैक्स\n",
            "1        sikhaaega      सिखाएगा\n",
            "2            learn         लर्न\n",
            "3         twitters     ट्विटर्स\n",
            "4      tirunelveli  तिरुनेलवेली\n",
            "...            ...          ...\n",
            "4091       saflata       सफ़लता\n",
            "4092        shbana        शबाना\n",
            "4093  khaatootolaa     खातूटोला\n",
            "4094    shivastava     शिवास्तव\n",
            "4095  preranapuree  प्रेरणापुरी\n",
            "\n",
            "[4096 rows x 2 columns]\n",
            "['thermax', 'sikhaaega', 'learn', 'twitters', 'tirunelveli', 'independence', 'speshiyon', 'shurooh', 'kolhapur', 'ajhar', 'karaar', 'anka', 'wpd', 'haashie', 'glendale', 'udhed', 'ekthi', 'idea', 'ambikapur', 'makerere', 'saboodaane', 'foohadta', 'sequent', 'shueb', 'panihati', 'sametati', 'ukhrul', 'brahmlin', 'utaraadhikaaree', 'iqbal', 'dayaalapuraa', 'sohrai', 'takreeban', 'farrukhnagar', 'theinga', 'tyoiharon', 'karneshvardhaam', 'umanath', 'daanshil', 'saahityotsav', 'shantiniketan', 'shikayatkarta', 'andarkhane', 'panter', 'leedaron', 'galgand', 'kaarniyaan', 'murgipaalan', 'mushahid', 'modules', 'rajouri', 'sushrushaa', 'shringaar', 'holt', 'laigikata', 'ijaajat', 'vankshetra', 'bhutal', 'swaadpremiyon', 'nineteez', 'frektar', 'likhkar', 'eyarkandeeshnar', 'nabz', 'quess', 'bouni', 'kaaragujaariyaan', 'gaangnam', 'tapia', 'tezpur', 'talve', 'seemaai', 'darshnaarthi', 'rivas', 'tarkvaad', 'anusaarakaa', 'coachella', 'latakakar', 'patravaliyan', 'parishad', 'spinj', 'anshida', 'dejesus', 'saraaymohiuddinpur', 'lowell', 'capacitor', 'passengerjind', 'granthiyon', 'buena', 'canterbury', 'kaathiyavadi', 'tekchandani', 'fisad', 'beraharamee', 'nishkarshah', 'activities', 'rikailleebreshan', 'shasanadhikaariyon', 'fijoolkharchi', 'dablyoopeedee', 'pace', 'dastar', 'catlin', 'joddta', 'killat', 'gruhnagar', 'wonder', 'vatar', 'shving', 'pashtun', 'farm', 'dibanu', 'pashchamee', 'uthapatak', 'nilaabh', 'laxmeeniyaan', 'mahaanagarawaasiyon', 'upneta', 'convention', 'sharp', 'kaaryayojana', 'maas', 'westing', 'kurvetee', 'jyaada', 'mukeshvari', 'shrimati', 'vivekadhikaron', 'loksabhavalee', 'kabahaa', 'bhraantiyon', 'vivekahin', 'balmiki', 'haryana', 'jivraj', 'flynn', 'rana', 'vishnupura', 'ghotaalebaajon', 'hairatangenz', 'takaleephadeh', 'peepaadh', 'dhabhaashaaraa', 'antdiyan', 'robin', 'singar', 'gumshudagi', 'balkrishna', 'phabti', 'palatne', 'lahlahaati', 'nagaada', 'udanen', 'klein', 'juloos', 'karyabhar', 'manto', 'paimaish', 'covina', 'penshan', 'ogastaavestalaind', 'centreeng', 'activa', 'barker', 'valkan', 'vruton', 'kabaddi', 'raunakh', 'caitlyn', 'phoos', 'jangadnaa', 'upakhyaanon', 'sundram', 'cochin', 'neko', 'kaushal', 'phaliya', 'acevedo', 'kottayam', 'dilaaega', 'kurvi', 'saunpengi', 'lekhan', 'gudepu', 'pharase', 'nubiya', 'taja', 'aantrit', 'qazi', 'murgipalan', 'eddy', 'nagine', 'subha', 'luis', 'vijayapuram', 'bataao', 'ochoa', 'science', 'sarkarein', 'bremerton', 'gurupado', 'sanyukt', 'raalod', 'baadhaon', 'gaumutra', 'sabhaen', 'tani', 'delhi', 'suken', 'vineet', 'chimate', 'kikiyana', 'rocket', 'maxwell', 'hippo', 'deepan', 'arymaa', 'bhulata', 'karmaacharee', 'durgapur', 'tribhaashaa', 'soodkhoron', 'prastaavon', 'survin', 'prapti', 'girivaasiyon', 'siducing', 'welwet', 'muqarrar', 'baxter', 'denier', 'cw', 'uthani', 'ghasi', 'ikattha', 'bhupsingh', 'dabochne', 'crosby', 'naameegiraamee', 'hurley', 'jarda', 'liepradhanmantri', 'bhranti', 'agencyyon', 'bago', 'forcee', 'bosaan', 'karki', 'ginate', 'manokaamnaaon', 'sammpattiyaan', 'politheenon', 'mtake', 'parichar', 'badabadee', 'crane', 'laamiyaan', 'ulhasnagar', 'prabhanmantri', 'shiwalapurwa', 'ferth', 'suhagin', 'saraikela', 'romeoville', 'raajsthanvasiyon', 'pratirodhaatmak', 'svarnikaa', 'vyavasthapana', 'tel', 'galatfahmi', 'takeinsider', 'microfiber', 'shreemahapoorn', 'fallujaa', 'donaldson', 'chadhne', 'jeevvigyaaniyon', 'cricketing', 'reduction', 'awaazen', 'wlaad', 'prathmik', 'thenga', 'excel', 'chatakaate', 'kubuddin', 'taaza', 'padani', 'nichaai', 'wausau', 'aalochakon', 'jaljale', 'surat', 'jeevati', 'prahaarak', 'shreesadguru', 'sanchalanon', 'bhal', 'tughlaq', 'uthaapatak', 'hastaantaraneey', 'utsaahawarddhan', 'sangoshtree', 'shaasanadhikariyon', 'mahadhipatiyon', 'fatima', 'fode', 'kantinyoo', 'kaamanaen', 'chutile', 'sankhyaen', 'kranj', 'barsata', 'parikalpit', 'harpal', 'maaoont', 'grover', 'biolozis', 'halisahar', 'angelo', 'janeudharee', 'bichbachaav', 'pokar', 'apvartit', 'aastin', 'pratishthaavaale', 'buenaventura', 'deccan', 'seriw', 'pardaa', 'emile', 'shaili', 'eastvale', 'chhallaa', 'lakshyon', 'hoaf', 'jarurih', 'rahya', 'mahkane', 'devi', 'nielsen', 'bhira', 'chabutare', 'bhushan', 'rukte', 'aamdani', 'talkshow', 'junagadh', 'padhata', 'odhakar', 'broke', 'talaasha', 'parivaarwaale', 'trubyunal', 'brock', 'yallaappaa', 'tasvaron', 'tugalaki', 'pick', 'circulation', 'jvar', 'kanindham', 'kush', 'properfacebuk', 'ashrafi', 'chadhen', 'vangchuk', 'honeywell', 'radiumdharmee', 'ladhege', 'sachan', 'arthshastriyon', 'canton', 'aatmamugdha', 'pontiac', 'lopez', 'ghontanaa', 'ambani', 'maryadaon', 'ratlam', 'hercules', 'akola', 'sakshan', 'notbandeeshuda', 'lagavaatee', 'alive', 'jivant', 'foda', 'fatahee', 'noobiyaa', 'lalmanee', 'faisala', 'krutyaa', 'dhuan', 'ahuja', 'pratipaalpur', 'namkeen', 'manjilen', 'laffaajee', 'juraab', 'fulae', 'castalloy', 'black', 'sooraj', 'bronch', 'avarnataa', 'johari', 'tevree', 'sanders', 'welder', 'eneeyoo', 'bharashtachaariyon', 'laalmanee', 'khaatedaar', 'aazmaanaa', 'aavrittiyon', 'kullawee', 'bahawalpur', 'prathmikta', 'mobile', 'katihar', 'swecha', 'haamidan', 'samdharshni', 'dridh', 'gond', 'wishesh', 'kaabilegour', 'laurense', 'hisham', 'chausinga', 'pafin', 'mate', 'buildcon', 'teekon', 'athak', 'jindagee', 'chayal', 'maap', 'last', 'gajra', 'ratrichar', 'kaathalaa', 'sahuuliyata', 'pattnaik', 'nyayalayeen', 'mukhyamantriyon', 'jeetanewalon', 'swaphoto', 'clifton', 'doda', 'pendulum', 'chipakane', 'nalakasa', 'chhah', 'gond', 'sameekshaakartaa', 'mantripad', 'liberation', 'asamaany', 'chungiyon', 'arica', 'balot', 'thin', 'formic', 'yuddhak', 'vegas', 'las', 'chitranshi', 'avranta', 'wasting', 'vitark', 'mukabaale', 'dharmapoorwee', 'ambaani', 'ibija', 'mahamedia', 'suzlon', 'varnit', 'jhuthlane', 'madurai', 'kaundal', 'lapatta', 'kshin', 'tewaree', 'raichur', 'lindon', 'pulama', 'olraunder', 'garibon', 'callahan', 'wabag', 'kaipdhari', 'atta', 'bareli', 'jing', 'jivan', 'reddy', 'pehni', 'tanu', 'deepika', 'lohati', 'kakkad', 'maulviyon', 'dungarpur', 'zaalaanaa', 'lakme', 'prospectus', 'westinghouse', 'bawara', 'thakkr', 'ichchhaachaaree', 'triya', 'dhavakon', 'damle', 'shravanabelagola', 'nilkamal', 'karmacharee', 'poorwottar', 'lehrayi', 'haito', 'prakaandh', 'khelmantree', 'bhavishya', 'egmor', 'shringar', 'saupengee', 'knoxville', 'bender', 'sundaram', 'pradesh', 'samvedikaran', 'laguna', 'bhisham', 'yemmiganur', 'huhtamaki', 'vadli', 'gail', 'race', 'salazar', 'diphtheria', 'dradh', 'shadadhi', 'prabodhini', 'lokpratinidhiyon', 'jatati', 'mangla', 'berwyn', 'mum', 'udaygadhi', 'akapulko', 'vaidhruti', 'charanbaddh', 'mandadi', 'euclid', 'paarampariktaa', 'hafate', 'sathiya', 'sanghiyataa', 'mukhyaatithiyon', 'vyavasthavirodhi', 'raktadaataaon', 'baramade', 'tarutal', 'kutta', 'jhaadaa', 'kishun', 'schaeffler', 'amrohi', 'raidical', 'jenner', 'varshiya', 'hasino', 'shaavakon', 'rupa', 'swaarthparak', 'weronika', 'webb', 'mahapatra', 'chenkein', 'agra', 'jiyaangkou', 'westwork', 'janaganna', 'pasco', 'jadhav', 'enterprise', 'sanshayon', 'varnavyavasthaavaadiyon', 'upasthiyon', 'mudichu', 'parnstaron', 'ia', 'baila', 'livaal', 'hillsboro', 'rashtriyadhyaksha', 'peedablyootee', 'thousand', 'shaakir', 'salahkaar', 'vishwakarma', 'ridge', 'swaasthyaheenataa', 'rishvatkhor', 'praavinses', 'daftarvaale', 'physician', 'log', 'jodhika', 'sevalaa', 'doobat', 'sipah', 'bharamaa', 'prtigyaa', 'meghwal', 'nandoi', 'aurora', 'formuley', 'durghtna', 'swatantrasingh', 'monterey', 'baalti', 'columbia', 'whittier', 'dukke', 'cubeck', 'chamakna', 'sheelbhag', 'bistagond', 'findlay', 'bapaa', 'dehra', 'aise', 'shrankhala', 'hastaaksharon', 'tirupati', 'mangalmoortih', 'kursiyon', 'mithaiyaan', 'pahno', 'halebid', 'bangsh', 'officially', 'sevai', 'gurjar', 'samanvayaka', 'parnel', 'sunsan', 'cusex', 'madhya', 'yudhrat', 'urbandale', 'briggs', 'error', 'chikhali', 'waan', 'adhikaariyaan', 'roanoke', 'haokip', 'poorvapekshaaon', 'masheenawat', 'kadmo', 'kurami', 'vidyaathyon', 'simtataa', 'sangrur', 'strongsville', 'agvaai', 'jangan', 'nagraj', 'yariyan', 'bhagyeshwar', 'jivati', 'sudkhoron', 'rukwaakar', 'brahmvarta', 'gray', 'bhraanti', 'purooshottamapur', 'teji', 'svaatan', 'mantarimandaliya', 'ashley', 'mathews', 'moolon', 'akzo', 'hamirpur', 'pokhriyal', 'bolateen', 'pratishthavale', 'dabangata', 'dhuriya', 'teap', 'gazi', 'ijajat', 'mejbani', 'toledo', 'mohadhaa', 'putli', 'sanchari', 'taapanee', 'little', 'narnaari', 'dhaniye', 'gadhoonga', 'faadi', 'gammat', 'tuberculosis', 'nagarjuna', 'raajneechi', 'medizensar', 'laphphaajee', 'commerce', 'maathaloo', 'chatagaon', 'hilig', 'isnpector', 'testing', 'naushad', 'falluja', 'pik', 'jiwan', 'katal', 'dablyooeeef', 'besil', 'slidon', 'saindan', 'jeremy', 'gaanv', 'todenge', 'udaan', 'saptkraanti', 'miranda', 'vyapak', 'maddy', 'sabhasadon', 'nauvahan', 'atmaen', 'rosa', 'damaae', 'midwest', 'trelarah', 'marlborough', 'waco', 'vimarshon', 'khan', 'difarard', 'sarsaa', 'hester', 'uttar', 'kasera', 'kuraaane', 'dayitvon', 'chayaniton', 'morales', 'heros', 'premamoolak', 'moran', 'zydus', 'nelson', 'amarpal', 'phatne', 'tinka', 'gaayikaao', 'pakayen', 'bhrashtachariyon', 'chalit', 'affle', 'mod', 'rajnitikaaron', 'arthon', 'gaaligalauj', 'anyonyashritata', 'udaya', 'cutlery', 'pratibandhah', 'neelaabh', 'bilae', 'khullamkhulla', 'swanson', 'anvaahaarya', 'rewari', 'sahkalakar', 'championship', 'bhadkaayaa', 'namdhari', 'alba', 'watanukoollan', 'khaatadhaarak', 'texas', 'special', 'harvansh', 'dinu', 'shaniwar', 'de', 'dabi', 'nahinkarvaaee', 'maarvaad', 'peediyon', 'brigton', 'mnaey', 'ligar', 'dilaega', 'aadhin', 'parwa', 'hempstead', 'mamooli', 'pradeshikaa', 'verification', 'fefada', 'wisangatiyaa', 'kachchhe', 'ghost', 'pipli', 'lovasa', 'helper', 'doobnewaale', 'bakhshane', 'indriyonke', 'barhad', 'risaalee', 'kaksheevati', 'vishvarakt', 'lodi', 'peachtree', 'ghumakkdon', 'ojha', 'ilaaj', 'arunai', 'ayodhyeanath', 'bhautikwadiyon', 'roket', 'nurochemistry', 'coldvel', 'aawaazen', 'mool', 'multiplexon', 'tyoihar', 'rotation', 'belacha', 'sahakalaakar', 'jadit', 'nagaaraa', 'barpaya', 'doongarpur', 'land', 'uchchhrunkhalataa', 'failaiya', 'suchi', 'noon', 'rp', 'shield', 'palanpur', 'electrosteel', 'obscura', 'cigretton', 'dikhaee', 'russell', 'nazarandaaz', 'kualalampoor', 'austin', 'raidcras', 'tcns', 'svaayattshasan', 'mood', 'daulatabad', 'bhulta', 'pratikaara', 'nights', 'nakam', 'shutting', 'raashtra', 'bechkar', 'stone', 'wardha', 'deedablyutee', 'desabathula', 'baapa', 'baghbaan', 'aadeshah', 'udelkar', 'tarko', 'yaaddaasht', 'inhalation', 'safradganj', 'roopak', 'scranton', 'varnavyavasthaawaadiyon', 'shikshakarmiyon', 'khandelwal', 'beverages', 'pidiya', 'nadaf', 'jehe', 'dhahaaenge', 'mastmaula', 'agartala', 'jamayaa', 'pardesi', 'arya', 'velvet', 'aapdaein', 'aagashe', 'achchi', 'udghosh', 'swabhawatah', 'bani', 'raykar', 'pidilite', 'dual', 'bheera', 'silva', 'adhikaran', 'rangkata', 'srichakra', 'gowmutra', 'nichalaa', 'burhanpur', 'sahooliyata', 'labdh', 'poole', 'strasion', 'picking', 'oditar', 'deniar', 'ajit', 'langdon', 'avashist', 'jha', 'prashasnik', 'bossier', 'badhachadhakar', 'giridih', 'bhuj', 'reading', 'fawaare', 'advait', 'rukate', 'anonditaa', 'fontana', 'nyutriyo', 'pailoton', 'jaden', 'boriwali', 'ilaichi', 'alliance', 'dhammaa', 'nahargadh', 'nsiu', 'sapaat', 'lengdan', 'panama', 'putle', 'aasaapaas', 'alwadhi', 'mufalisi', 'sansathaan', 'darshnaarthee', 'lokotsav', 'graahakonne', 'uchchaadhikaareeyo', 'bhav', 'reja', 'motherson', 'kauplaiks', 'aaburod', 'heidelbergceat', 'chimati', 'surfactants', 'mitao', 'kailana', 'tankar', 'odhkar', 'merta', 'megavaal', 'rasyanik', 'soochnah', 'sugamata', 'jockey', 'munaf', 'niswarth', 'kshetradwaaraa', 'mahawar', 'buldhana', 'dhamkata', 'bhusvami', 'vigyan', 'quete', 'bevkufana', 'jajmau', 'beltran', 'vilas', 'makhdumpur', 'kolorado', 'blackburn', 'suniti', 'ghigghee', 'flavonoids', 'chahunmukhi', 'supachye', 'siratee', 'vishnu', 'chaudahavan', 'chaudhari', 'aabru', 'balurak', 'davangere', 'anurit', 'shipping', 'patiala', 'jaanam', 'financial', 'damae', 'policy', 'icc', 'kuchchh', 'cheekhna', 'reliance', 'urvarakon', 'ravael', 'ladhkiyon', 'mukeshwaree', 'wankshetra', 'ummeede', 'kahaavah', 'kaantipoorn', 'badaaen', 'enseeaardablyusee', 'pratibaddhataa', 'follow', 'sevamukta', 'evanston', 'charas', 'hills', 'robertsan', 'bhadauriya', 'glaxosmithkline', 'producton', 'guevara', 'vigyaanon', 'jarvis', 'laphz', 'font', 'paradheen', 'shak', 'ganjhoo', 'dit', 'danptiyon', 'maadhikhedhaa', 'pratishthaanon', 'soond', 'ginte', 'alagalag', 'swastikakaar', 'pratikaraa', 'aastik', 'niveshkartaa', 'saval', 'sanskritiyan', 'raubdar', 'raghuram', 'intaravyu', 'chharhari', 'sawyer', 'bhasapa', 'jvaaron', 'sansthita', 'parshdon', 'pulatskar', 'uthaaeange', 'laengee', 'oeeef', 'valsad', 'mulon', 'putliyan', 'shmil', 'riggs', 'camarillo', 'saflataa', 'vinasht', 'kping', 'jayalalithaa', 'items', 'soccer', 'asphalt', 'mehrotra', 'chune', 'zarakh', 'mejbaani', 'muflisi', 'luna', 'warnavyavasthaavaadiyon', 'lipaaee', 'uthni', 'bajaj', 'hisarah', 'dampatiyon', 'watson', 'augustustine', 'pataakshep', 'dhandhekhoree', 'ubhregaa', 'anton', 'apardarshi', 'nihlaani', 'tivolee', 'hogis', 'winter', 'badalavaakar', 'ghumaee', 'petaluma', 'beeemdablyooem', 'bakhshate', 'sanvedikaran', 'telon', 'ghummakkadon', 'haanfte', 'farheen', 'james', 'kiratpur', 'redding', 'shaq', 'surprise', 'kisanon', 'chalenge', 'yoder', 'stein', 'paithelojist', 'labeling', 'ikthiyosis', 'liberation', 'phoodon', 'nanhein', 'bhadauria', 'jatilaa', 'pahunchanee', 'raashtron', 'blossom', 'tandon', 'gadbadbadee', 'sanasthita', 'yatraen', 'aadan', 'javate', 'niyuttiyon', 'bhishm', 'hundiya', 'murgeepaalan', 'malekar', 'loveland', 'mavey', 'vikram', 'hanfte', 'barrackpore', 'ghaziabad', 'tarkon', 'spf', 'artemis', 'aipp', 'jaiban', 'gairairaadatan', 'vivekadhin', 'sabajooniyar', 'faliya', 'prekshakganon', 'purvaasiyon', 'vipannata', 'maanga', 'ordanens', 'pradhan', 'abhiyuktonke', 'viratkhand', 'hijbul', 'vidyaon', 'manju', 'chhawindra', 'chhupkar', 'doranda', 'saym', 'mithhaiyaan', 'jeevvigyaniyon', 'pashtuun', 'brahraachaarinee', 'jerusalem', 'altamonte', 'sihuntaa', 'hemwati', 'koshadhikaaree', 'ashanka', 'bean', 'vaigyanikata', 'jheelon', 'robarto', 'shrirampur', 'manchiya', 'vasoolataa', 'morrison', 'mhagranth', 'transistor', 'sarvjaatiya', 'patotsav', 'houkee', 'medithsan', 'udana', 'saraaymohiuddeenpur', 'petersburg', 'ranjkatha', 'diya', 'mohindar', 'mastek', 'nirbadh', 'ehsaas', 'avrutiyon', 'eshiyavan', 'thki', 'turbine', 'dimaak', 'jodhpur', 'durdhara', 'khaastaur', 'makrani', 'high', 'fatahi', 'mariya', 'ganv', 'pendulam', 'aavishakaar', 'natijeh', 'jeffersonville', 'brahmasiddhi', 'tulshidas', 'reeta', 'charchaamanch', 'pratikaaraa', 'tarkwaad', 'dabangon', 'hichkicha', 'sheershakon', 'dam', 'dviarthee', 'jawabah', 'bahumaan', 'jaanchkarata', 'vandemaataram', 'should', 'agsta', 'neu', 'dastakhatshuda', 'surinama', 'kingkhan', 'taras', 'rekannecting', 'phaibrik', 'clair', 'chhejat', 'mominatolaa', 'virodh', 'arena', 'unionwaadi', 'bamleshvaree', 'boca', 'immaturity', 'sansthaan', 'jin', 'dadrewa', 'kide', 'karawanou', 'putin', 'tankaar', 'khatakati', 'jadd', 'pushpa', 'gm', 'yusugi', 'korola', 'pyade', 'karavaayegee', 'balaatkaariyon', 'jatatee', 'gurdaspur', 'shreshthaswaroop', 'shubhprabhaa', 'europlast', 'rashtrabhakton', 'canterbari', 'communicators', 'mahamanch', 'conway', 'dwf', 'reeves', 'dabhoi', 'bhootal', 'insaano', 'emily', 'vigyaanam', 'sapatey', 'atwaal', 'hindan', 'aaufisaree', 'montclair', 'purnsveekrit', 'richardson', 'sandrbh', 'fargo', 'aleem', 'saptakranti', 'hr', 'imaandaari', 'kontrekting', 'gangajal', 'gaur', 'adhikariyon', 'bandhan', 'sendha', 'dablyoopidi', 'gravita', 'lincoln', 'pravrittivigyanon', 'cementation', 'bagad', 'gentry', 'datson', 'montebello', 'renewables', 'naksalwad', 'aitraz', 'itibhagwatee', 'niveshkarta', 'patkathayen', 'kaabiletaarif', 'bhaadas', 'bhogte', 'holding', 'dhatta', 'dhoron', 'upakhyanon', 'fayetteville', 'stockton', 'brijesh', 'pratigya', 'badhaati', 'then', 'thomas', 'dhyeywadi', 'tuesday', 'wgpl', 'ovum', 'gati', 'nucleus', 'kraar', 'purooshottamaachary', 'manchanda', 'lahsun', 'naqaab', 'suja', 'mckenzie', 'purzon', 'bahunt', 'bravo', 'amaanat', 'jhuthla', 'bush', 'chaukhate', 'apar', 'asthetic', 'kshetradwara', 'sajja', 'dhahaane', 'nariyalyukt', 'jealous', 'kursiyo', 'singhaadey', 'amy', 'antarmukh', 'thakkar', 'badbolepan', 'naxaliyon', 'manner', 'himali', 'naksalavaad', 'half', 'mahaadharmaadhyaksha', 'parmoujood', 'tippanikar', 'perels', 'bhapaee', 'beetaane', 'valve', 'dwirookta', 'eddie', 'jivaniyaan', 'panghal', 'khand', 'urvarkon', 'besin', 'giriwasiyon', 'paradhin', 'pukhtaa', 'achnera', 'carson', 'delta', 'tripura', 'alaymani', 'kheda', 'nahargarh', 'shalimar', 'immaichyority', 'elendt', 'properphasebuk', 'udanon', 'mhajan', 'moses', 'bataayaaki', 'alai', 'ilectromeetar', 'amod', 'rookenge', 'maariya', 'raagon', 'aaipief', 'phalitartha', 'supachy', 'awashist', 'ishat', 'rate', 'aata', 'mahalon', 'warishthon', 'jalapot', 'katrina', 'jismafaroshee', 'salary', 'raza', 'rectare', 'basil', 'badhaataa', 'charanbaddha', 'bhadkaya', 'sahityotsav', 'naraseepura', 'samjhunga', 'chandrapur', 'sarkaa', 'dhaah', 'praudh', 'ahitakaaree', 'darawani', 'belinda', 'alayamanee', 'datsun', 'ate', 'fasteners', 'bangravala', 'saira', 'atthas', 'nirdal', 'mahbubnagar', 'daratey', 'valkkan', 'khastaur', 'barsaai', 'ananddaayak', 'banbi', 'toh', 'asmanye', 'wipannta', 'spast', 'amzera', 'bechakar', 'ghatabadh', 'kaushalta', 'machine', 'wireless', 'fainn', 'gaano', 'khambhat', 'kyooaaeepeees', 'dublin', 'mta', 'samruddhiyon', 'radhakrushnadas', 'kaansting', 'idukki', 'industrial', 'bharatwanshee', 'maangi', 'robins', 'vladimir', 'pehowa', 'bagh', 'ummidwaaree', 'saafgoi', 'koottaa', 'adain', 'grenite', 'ustara', 'dhundhta', 'sangheeyataa', 'kumari', 'depthiriya', 'adchane', 'koriyaah', 'prapat', 'chhudawaaya', 'suiyan', 'veronika', 'schaeffler', 'jyaadaa', 'potter', 'media', 'yarushalem', 'pichde', 'letaseng', 'arthavyawasthataaon', 'kakoo', 'nirdeshika', 'seto', 'navate', 'samvedansheelata', 'roadrej', 'chhahon', 'laphj', 'vanshvad', 'rohtak', 'atakta', 'baawaraa', 'kribarabh', 'prakashakah', 'styrolution', 'apaardarshi', 'bengaluru', 'andhapan', 'mainan', 'kyaah', 'formulae', 'hamalavar', 'amavasya', 'purvapekshaaon', 'daishawaalaa', 'oklahoma', 'darmait', 'sahakalakar', 'fatma', 'khalati', 'dayitva', 'kyusaiks', 'tolakarmee', 'version', 'parisamvad', 'immune', 'bachti', 'utilities', 'malmaas', 'cadmium', 'antioch', 'khatedaar', 'mohini', 'vishwasniiyataa', 'rehman', 'kanblon', 'aaryika', 'marrej', 'chheenk', 'phalata', 'baagoraa', 'pakaude', 'lucie', 'fatehgadh', 'grahanakaal', 'jobs', 'sadanand', 'dutt', 'murgeepalan', 'lurhakate', 'palmonari', 'win', 'ubhaara', 'beck', 'padaraunaa', 'bandhate', 'kapoor', 'sevaala', 'vershan', 'chidhate', 'thane', 'nikalogi', 'mogali', 'dredger', 'nagarik', 'gajipur', 'vadak', 'mitchell', 'gyatvy', 'standhaari', 'dhoraaji', 'abdunnaasir', 'vishvwandhya', 'satyaarthprakash', 'shivamogga', 'ghumakkdi', 'gayen', 'chee', 'theateron', 'anadhikaarik', 'shasak', 'hines', 'bettiah', 'dhatna', 'rahamat', 'motihari', 'pearson', 'ujback', 'wheeling', 'pythogaras', 'wipro', 'kaabiletaareef', 'jamaate', 'pulam', 'daubaaraa', 'portillo', 'adhik', 'dhumrapaan', 'daampatya', 'jamudiya', 'pedoo', 'pipra', 'blair', 'communications', 'alayans', 'aradas', 'gudna', 'just', 'aawajon', 'benvar', 'amarillo', 'bramhaand', 'dikhai', 'tantro', 'aasan', 'tuglakabad', 'sutton', 'kandrour', 'khanna', 'nikalani', 'dibanoo', 'immachyoritee', 'tolaasan', 'jaanaakaree', 'liwaal', 'engeline', 'rushitaa', 'flint', 'vrishchikahsaptah', 'aasmatee', 'girkar', 'vaigyaanik', 'bishadhee', 'phoolatee', 'punahsthapana', 'badh', 'gandha', 'chakshu', 'miktaam', 'liidaron', 'zabardast', 'stuti', 'aurato', 'heblikar', 'rattebaajee', 'francisca', 'mumba', 'pratiyukti', 'darati', 'pranon', 'madison', 'nibhaaegee', 'myers', 'kashyap', 'brigadier', 'ambikaaon', 'hogaah', 'ishaak', 'sumi', 'deshbhaktimaya', 'dharmapatriyaan', 'krishnanagar', 'ea', 'aayudhnirmaanee', 'taaja', 'ajasra', 'fijulkharchi', 'mantrayon', 'tanta', 'dealership', 'chapel', 'dhwanimikon', 'education', 'jarakh', 'neet', 'jilawaasiyon', 'samprabhuta', 'kasegaa', 'pakanevala', 'deepn', 'kalasaanaa', 'mugaalataa', 'tokne', 'falibhoot', 'gyonth', 'dikhaai', 'shaamjeebhaaee', 'pahnaakar', 'kisaani', 'udhaaradaataaon', 'ramtek', 'wyaakhyaatmaktaa', 'somvaar', 'vista', 'polimer', 'raktaabh', 'bhugta', 'bhrashtachareeyon', 'khatakti', 'mukhyamantriyon', 'mad', 'kakshaang', 'jain', 'mahin', 'survana', 'baangarotiya', 'rasaayanik', 'aurora', 'chamchagiree', 'ncrwc', 'ainthey', 'essel', 'deshsewa', 'ilectrotecs', 'workcharge', 'kaarwaai', 'jhanktaa', 'urgent', 'sapraman', 'maurya', 'jini', 'jagadeeshachandra', 'asurakshit', 'kaavyoktiyaan', 'alnkaar', 'svadpremiyon', 'jaatak', 'rollers', 'ashaktataa', 'kaathiyavadee', 'aavriti', 'vidyaayein', 'vidhivat', 'raadhe', 'mukhyamantrisamvaaddaata', 'praansangalee', 'kanalog', 'pudukkottai', 'nicky', 'fuhadtaa', 'patachep', 'retreate', 'manovaigyaaniyon', 'stanadhari', 'mukhyopadhyaay', 'nirbaadh', 'todne', 'avuti', 'parikshankartaon', 'extactor', 'nashik', 'rasayanon', 'vaitravati', 'ogrenaaij', 'chausingha', 'phalodi', 'skhalan', 'panaamaa', 'nigar', 'monte', 'suneeti', 'shrabon', 'ambikaon', 'gujara', 'photofrem', 'prahlaad', 'beesavaan', 'dvivedi', 'denewaali', 'burleson', 'bharadwaj', 'jataati', 'malegaon', 'rahugaan', 'mahamantra', 'beast', 'divyata', 'sanjivan', 'kuposhit', 'eksclation', 'chadhega', 'texarkana', 'dungerpur', 'sarahi', 'laalaparee', 'aeronautics', 'worth', 'aasteen', 'svapnika', 'upakaaryaalayon', 'mimicry', 'ballabh', 'veriphication', 'hackensack', 'aakaash', 'bona', 'clock', 'daphan', 'pegav', 'kahlaya', 'madheekhedha', 'teleebag', 'dhaarak', 'nikaalani', 'kanghe', 'prashnottari', 'kakinada', 'bhaagyoday', 'singer', 'machaye', 'lekhakganon', 'uchhalne', 'dharmarajne', 'ainjal', 'bantata', 'pharm', 'ravel', 'hanumangarh', 'veeraangnaaon', 'gaytri', 'venkatraman', 'dibnoo', 'purooshottamachaary', 'sanyojakon', 'jhaauganj', 'sarkaren', 'newtest', 'shrikar', 'mitaao', 'diyotsiddh', 'bhoopsingh', 'charchaaen', 'prasarakon', 'nishpaap', 'flin', 'ranneetibanaa', 'eeaarjee', 'dhaagaa', 'gomukh', 'jud', 'khanikarmi', 'sharabh', 'arellano', 'ukhadhakar', 'lenevali', 'kumar', 'singhde', 'toncil', 'davindarpal', 'singaar', 'khisakate', 'enid', 'megapixal', 'digvijay', 'fazalon', 'doge', 'labelon', 'munafa', 'badhane', 'very', 'saatsera', 'ortega', 'rowe', 'bhatia', 'raajsthanwasiyon', 'baagbageechon', 'wilkinson', 'daraati', 'atke', 'pramukhataapoorwak', 'yatna', 'nitin', 'city', 'radico', 'dukanon', 'jalsansadhan', 'masyendranath', 'behar', 'barsheey', 'avru', 'daw', 'naqab', 'saregama', 'hugli', 'satti', 'neg', 'mahabaleshwar', 'placentia', 'varsaache', 'kumau', 'emi', 'theatrs', 'erika', 'khinchakar', 'raubadar', 'alto', 'kavyavidhaaon', 'coon', 'akron', 'tahkhaana', 'samajjanon', 'machaaye', 'suryadev', 'prathamik', 'pravritriyon', 'taajaa', 'jivanshaili', 'raktdaataaon', 'baleshwar', 'bhautikwaadiyon', 'lagaateen', 'jhaiyaan', 'vanshvaad', 'navanagar', 'najarandaaz', 'anshaankan', 'funkane', 'matpatron', 'module', 'farms', 'pahunchogee', 'maidi', 'thief', 'pfaudler', 'amit', 'poorvabhadrapad', 'landara', 'gonpo', 'vesle', 'shaao', 'hamidan', 'weeks', 'mineral', 'centennial', 'bastiyo', 'bagbagichon', 'pranit', 'bhedabhaavon', 'karaahanaa', 'greenville', 'sherawat', 'ralaud', 'jatakon', 'rishte', 'bentonville', 'najibabaad', 'financiers', 'phatahee', 'kerala', 'ladaaiyon', 'harijan', 'whitaker', 'vidisha', 'paul', 'aryon', 'khilana', 'chhutane', 'dukhiyon', 'poorneshwari', 'visabal', 'daramyanee', 'yari', 'vidhamaan', 'yatraein', 'sunteck', 'gujarata', 'niyanta', 'dum', 'awasthi', 'plus', 'bhen', 'stops', 'dhakelte', 'kpo', 'damghontu', 'insano', 'merraige', 'asfalt', 'laundry', 'ratnaabhooshan', 'ski', 'dushwaariyon', 'anupryogon', 'deshseva', 'lela', 'jagaragallu', 'mejbani', 'dehri', 'chkkar', 'crawford', 'guduri', 'dvc', 'prakriyagat', 'nag', 'matsyavatar', 'scootaron', 'ardhavishvas', 'daramyaanee', 'survanaa', 'sthitiyan', 'dharmaanand', 'sofner', 'squash', 'vidhansabhaen', 'randolph', 'mezbaan', 'sprit', 'sheelabhang', 'kalmein', 'swarnikaa', 'mandi', 'arthawyavasthataaon', 'kundaliya', 'nimkathana', 'farm', 'hatyaaropit', 'putta', 'faurensis', 'purooshottamachary', 'bonds', 'shikaayatkartaa', 'cronfrencing', 'ubal', 'baabaao', 'halmatpura', 'haqeeqat', 'barman', 'vartmaan', 'baantin', 'achanbha', 'jiwanparyant', 'wadara', 'sadaqen', 'aisa', 'jyotishyshastron', 'pythagoras', 'engelin', 'kapolkalpana', 'dropadiyon', 'rozlyn', 'sriram', 'gopaalak', 'bangbandhu', 'mistriyan', 'usay', 'mercado', 'maisore', 'offshor', 'kapurthala', 'sahovaliya', 'maladahiya', 'hymen', 'indaurnagar', 'visheshagyataon', 'usaki', 'caplin', 'mahapran', 'rupesh', 'reno', 'sudeepton', 'swamy', 'amara', 'vyavasthaamoolak', 'sensing', 'tyler', 'sangareddi', 'pehno', 'mardani', 'bamleshwaree', 'deewani', 'fincorp', 'navaa', 'shimat', 'sohawal', 'banaam', 'prawrutriyon', 'xiong', 'varsted', 'raajon', 'cheekhana', 'naimul', 'badhotri', 'antony', 'chhanyasa', 'nirdeshikaa', 'niptaaraa', 'judne', 'sujhati', 'pathalogist', 'tide', 'shrungar', 'braandes', 'parmeshvarpur', 'jedateeisaaft', 'uddhaatan', 'stan', 'aadivaadiyon', 'julaahon', 'maharaja', 'gatishilata', 'shipra', 'tribunal', 'khyber', 'wanvibhag', 'ghataatop', 'dharmagranthon', 'prawrittiyon', 'gaanth', 'mysore', 'sehgal', 'namkin', 'vaidh', 'vanaspatiyaan', 'jiangkou', 'pakhandi', 'protekts', 'elbaino', 'linden', 'sohaval', 'bhurbhura', 'gastrology', 'widroop', 'sajsajja', 'raatrichar', 'rojana', 'jalbhrav', 'montgomery', 'sev', 'bhrastrachariyon', 'dwn', 'streshan', 'ganthe', 'gehlot', 'chhateni', 'vishwasniiya', 'jivaniyan', 'dastaanen', 'dhona', 'kharuwaar', 'suriname', 'mangalsinh', 'anyonyashritta', 'ninties', 'paancholaas', 'reson', 'vaataanukooliton', 'chatushkoniya', 'aamdi', 'dushtaapurvak', 'bechate', 'chuka', 'mizoram', 'torrance', 'anuchit', 'avarodhak', 'ross', 'achyut', 'oodhami', 'haraval', 'gould', 'daaw', 'srijanvigyanee', 'nextgen', 'rukavaton', 'bhavanaon', 'dehdhaari', 'parikhaen', 'utaney', 'sanskrition', 'prospex', 'naeedilli', 'saayn', 'geneva', 'rasad', 'baramula', 'vandemataram', 'safari', 'chamba', 'sawal', 'bannari', 'fatehpur', 'pehnate', 'spray', 'normal', 'allout', 'manassas', 'mantriyonke', 'karyakaryakartaon', 'phaadanhe', 'greg', 'baitool', 'kushan', 'subbanee', 'infibeam', 'khatakhataakar', 'chachaji', 'chandrabali', 'baripada', 'roohelkhand', 'ghairakaanoonee', 'aarekhah', 'pramukhkarmiyon', 'lee', 'thiyeters', 'assam', 'faanon', 'jyada', 'theateron', 'safaikarmi', 'bieseses', 'cronfrensing', 'jeevraaj', 'thirake', 'shaksubahey', 'paratrooper', 'dabhara', 'usi', 'nihsandeh', 'mahanatam', 'banthia', 'anam', 'kashmir', 'baavadee', 'bhutto', 'maarake', 'kaaryayojna', 'francisko', 'adani', 'dhuriyaa', 'mhavidya', 'megapixel', 'cryptocurrencyon', 'muth', 'authoritee', 'aparivartanshil', 'pradhanmantriki', 'aagaashe', 'navjaagaran', 'attraa', 'ubala', 'amanati', 'khammam', 'haaranaa', 'bhavabhivyaktiyon', 'pushkar', 'shaantiyon', 'nerolac', 'chauka', 'siddhalingaa', 'bharatnatyam', 'javabah', 'dushwariyon', 'manchiy', 'jiyo', 'sapramaan', 'sim', 'peeechdablyooseees', 'bahav', 'tik', 'agavai', 'higman', 'qiwi', 'agyat', 'agende', 'lynchburg', 'maangeena', 'khatakhataaegee', 'jodhikaa', 'srujanvigyaani', 'detasan', 'badalwa', 'urf', 'chhaapemaar', 'lux', 'bhopal', 'phalibhoot', 'paithelaujist', 'paryaptta', 'furti', 'mrutyuniwaarak', 'maruti', 'uthaakar', 'alo', 'pegaw', 'pilibhit', 'somi', 'sanchalnon', 'kanchipuram', 'daraatee', 'yaddasht', 'sabudana', 'welding', 'veronica', 'stimberwala', 'mayajaal', 'pes', 'atul', 'outomaitically', 'jaanchana', 'mithilanchal', 'phiksingah', 'sajetee', 'plano', 'visangatiyaa', 'khhomche', 'lagna', 'mukeshwari', 'tasvaaron', 'dev', 'vesh', 'jyothy', 'landal', 'viraangnaaon', 'yanit', 'purnia', 'chauk', 'ladeen', 'chest', 'kasega', 'abut', 'renuka', 'loowe', 'gulaabaag', 'lajjalu', 'sabhaar', 'gairarashtravaadee', 'dhaavakon', 'lim', 'vidhaaein', 'svayamsveekrat', 'electrotex', 'ramraj', 'janbhavna', 'yauniktaa', 'haathe', 'dune', 'protects', 'vareinye', 'mazboori', 'praveenchand', 'vaigyanik', 'torrent', 'aatmayen', 'samprati', 'matthe', 'savita', 'atlantic', 'jalgti', 'chacchaa', 'afreen', 'bazaru', 'chauki', 'pharse', 'tuning', 'nodaraanee', 'maum', 'vidhaanee', 'gujar', 'pakadkar', 'aankhen', 'aapka', 'warner', 'anvaharya', 'likhehain', 'paathyakram', 'shavkon', 'yarooshaleim', 'mandalaayukto', 'naino', 'jhaaiyaan', 'simferopol', 'dhamm', 'nikharegaa', 'ghumaan', 'hounga', 'dhakal', 'sagarika', 'bernard', 'yogabal', 'breweries', 'dish', 'aithan', 'vartamaan', 'tremasik', 'tasvire', 'vyvhargat', 'maratha', 'banvaa', 'svarnika', 'prasath', 'overall', 'purwafalguni', 'properphasebook', 'suven', 'sapate', 'jh', 'karghe', 'deshkaal', 'nathdwara', 'thanvi', 'oran', 'serrano', 'ear', 'submission', 'dharak', 'tadad', 'greenwood', 'haute', 'behuria', 'niyantaaon', 'churu', 'missouri', 'anyaya', 'generat', 'nyutest', 'garud', 'swaastikakaar', 'shaie', 'siddhantavaadiyon', 'anawashyak', 'seaten', 'gulshan', 'riya', 'firmian', 'tyre', 'chi', 'badlapur', 'yuddhanaukaa', 'nbcc', 'shreeganganagarvaasiyon', 'udaa', 'cambridge', 'airway', 'idol', 'calumet', 'aajmaanaa', 'tantrikao', 'jonesboro', 'buddhijeewon', 'klozup', 'nmdc', 'raashtrapit', 'kamarhati', 'asphault', 'fransisko', 'bhalla', 'maulvidon', 'narwar', 'lahlahati', 'byaawa', 'ghataaegi', 'naamajadagee', 'takah', 'sevagram', 'laamiyan', 'gin', 'swechha', 'antadiyaan', 'arya', 'polishing', 'jokhimabharaa', 'umadatee', 'tantra', 'samoa', 'csi', 'mandya', 'lawrie', 'pahante', 'ankor', 'nimnavat', 'rapping', 'roopesh', 'pratibaddhata', 'nadep', 'sailaaneepan', 'menrajya', 'daav', 'aaboorod', 'pathyakramon', 'nividaataaon', 'gandhipura', 'phwcs', 'narayangadh', 'jaylalita', 'susanskrut', 'masood', 'woonsocket', 'sanskrutiyan', 'urff', 'theratipally', 'pratinirdesh', 'ulhaaspur', 'pahanate', 'dhawakon', 'bhagedh', 'pransangali', 'jalvayu', 'bhijvaai', 'sayra', 'krendron', 'maujud', 'siddhaant', 'kamyuniketars', 'chidchidapan', 'muthoot', 'wiwekadhikaron', 'maloun', 'cincinnati', 'registan', 'parosne', 'vichaarakon', 'janbhawna', 'andaman', 'badyal', 'morepen', 'beard', 'nodarani', 'dikhayee', 'chink', 'wyakhyatmakta', 'shaishav', 'aainthoo', 'ahemdabadah', 'jaayke', 'cigniti', 'kurukshetra', 'pravritteeyon', 'charcha', 'lakshmeechandra', 'hammond', 'nibhaegi', 'dhunai', 'janbhaavna', 'cant', 'melaghaat', 'mue', 'shwing', 'dampatya', 'kpada', 'santati', 'maanavtarhit', 'anuprayogi', 'harvey', 'kaju', 'cerritos', 'texmaco', 'sanchar', 'tuth', 'lozano', 'ropaney', 'hollywood', 'chhinke', 'dhamma', 'technoplast', 'pujapath', 'chanan', 'shrankhalaaon', 'chhednaa', 'carbogen', 'vyavadhan', 'schultz', 'istrailiyon', 'squash', 'danville', 'prana', 'thaakurvaadee', 'prayogshaastra', 'wyakteeyon', 'metrologist', 'madhura', 'paliyon', 'denver', 'apj', 'beni', 'pratisthaan', 'bhrashtaachaariyon', 'lakeer', 'sudhaargrah', 'sandali', 'jagriti', 'talwar', 'janashiksha', 'tapuwo', 'bulletin', 'ballebaajee', 'maadheekhedhaa', 'arthshaastriyon', 'scaining', 'mehman', 'rahegi', 'jamshedpur', 'tyauharon', 'darshaana', 'beechbachaav', 'sulati', 'varshan', 'sudhaaratee', 'wasaamukt', 'patil', 'jewaab', 'soto', 'dhtuen', 'dose', 'bhaagadaud', 'pagabadha', 'arushi', 'agusta', 'titan', 'equities', 'airtel', 'alaps', 'naksali', 'achivement', 'galaega', 'foodon', 'rajnichi', 'arya', 'streamwood', 'ghot', 'music', 'purkayastha', 'nora', 'tonic', 'gujaarne', 'water', 'sunsaan', 'sirsa', 'tangirala', 'hanson', 'varun', 'dreijer', 'doudaate', 'sharabon', 'vyakteeyon', 'saatseraa', 'darjano', 'agniyaan', 'dhonaa', 'karyakartriyon', 'awasthaen', 'himamaanav', 'two', 'ail', 'bandhuon', 'shraddhavanon', 'mariyo', 'vyaghat', 'michael', 'adrgh', 'vitthal', 'prarup', 'dhoondhti', 'dubana', 'ladne', 'form', 'zuari', 'pariwarwale', 'peranormal', 'bhuvneshvaprasad', 'iris', 'pratigyapoorn', 'lebalon', 'shreekrushnan', 'snikarse', 'kain', 'bhooswaami', 'karta', 'anyay', 'nokari', 'precision', 'chrom', 'jue', 'bowling', 'taapti', 'catholicon', 'nazarandaz', 'mulchand', 'sweccha', 'nanyaulaa', 'ghontana', 'advaitwad', 'underwood', 'lubhaavna', 'petroselee', 'amdi', 'ropane', 'daisy', 'jababee', 'cup', 'phaade', 'ulahna', 'unnatiyon', 'molina', 'gaandchubhonachoosnachhote', 'han', 'pradarshan', 'sarjuga', 'bidar', 'amargad', 'juye', 'tonk', 'devaapur', 'intelligence', 'neetiyon', 'khanaudaa', 'porbandar', 'sim', 'lagnesh', 'gaayikao', 'prishthabhoomiyon', 'moolchand', 'silchar', 'margarita', 'udakishuganj', 'sirtee', 'yamala', 'prashikshu', 'sierra', 'aalhaa', 'peck', 'taskhir', 'daka', 'nominate', 'sapat', 'coimbatore', 'koraput', 'svayattshasan', 'vidyutikrit', 'kikiyaanaa', 'arunaai', 'rigal', 'diamond', 'mridubhaashee', 'walters', 'sutrapada', 'keeti', 'zilaadhikaari', 'mangesh', 'pension', 'laganewale', 'jilavasiyon', 'ploskee', 'eksath', 'sekhar', 'dow', 'ardhawishwaas', 'rajasthan', 'vikaskhand', 'samshayon', 'badhanaa', 'classon', 'ikhrul', 'furaame', 'ebaz', 'baataaya', 'jushantan', 'strong', 'rajnitikaron', 'panipat', 'blankaard', 'jhabua', 'jacinto', 'barahsinga', 'suchnah', 'electromagic', 'lalmani', 'bhaaulaal', 'kathua', 'palaari', 'amitao', 'tadanrustee', 'vaabastaa', 'vlad', 'slash', 'waterbury', 'selfie', 'luis', 'panchasootra', 'aryama', 'vaadak', 'junction', 'generic', 'jiya', 'aden', 'sophner', 'qwvga', 'dhvanimikon', 'feeds', 'sukadiyaal', 'angadh', 'bavji', 'chhodiye', 'cipla', 'vigyanon', 'dhasmaanaa', 'longewal', 'badam', 'atraikt', 'saraaha', 'nrityashaili', 'sanvari', 'yakshadhipati', 'arabpatiyon', 'mukaddamon', 'phode', 'sihunta', 'jeewan', 'dhoondhata', 'cruces', 'kaaryakartriyon', 'pratibaddhtaaen', 'dlw', 'plan', 'pailot', 'adhiwas', 'phainn', 'favvara', 'halchal', 'wishvaweer', 'crest', 'brahmleen', 'virechan', 'yaaddaashta', 'ujjain', 'sahyaatre', 'jimme', 'sarawagi', 'dekhiyegaa', 'wajood', 'kundal', 'ria', 'slider', 'management', 'karyakaaryakartaon', 'cristis', 'ruktey', 'distrabyuters', 'spell', 'damapar', 'thikane', 'interactuality', 'cdyaan', 'south', 'aapkaa', 'nahinkarwaaee', 'jaagriti', 'choodhe', 'thirty', 'nadsa', 'gsm', 'gujarat', 'darshnarthee', 'nabha', 'dhokebaaj', 'lega', 'beeaaeeaaeeteeem', 'somwaar', 'wanon', 'audhyogikaran', 'agrahari', 'aafa', 'teemaardaron', 'misra', 'cerebra', 'naagrik', 'dastaar', 'makarh', 'gtor', 'ballistic', 'chadhegaa', 'maange', 'nilabh', 'mensharaab', 'singhade', 'hisaarah', 'ramkot', 'baithate', 'taskheer', 'ishaara', 'solapur', 'mejbaani', 'florence', 'paraamarshak', 'jhaadane', 'theaters', 'aadaan', 'ambience', 'surakshaah', 'hikaarico', 'baanyaa', 'rookvaai', 'mitravat', 'bokaro', 'maurya', 'pratinidhikaaree', 'chandramaon', 'parosane', 'dhaiya', 'spirits', 'leandro', 'sean', 'swarthparak', 'chuchiyaan', 'mahamidiya', 'poorwajanmon', 'shohadapantee', 'kushaan', 'jamloki', 'everest', 'taswaaron', 'advivas', 'premlata', 'murrieta', 'vaimanasya', 'kelly', 'tinplate', 'vaan', 'mahamantr', 'mezbaan', 'shumali', 'fulaaye', 'pruitt', 'rojvelt', 'prashasanik', 'ulazaanon', 'patrakaarvarta', 'duar', 'kathfodave', 'bipin', 'offerh', 'isayiyon', 'propellent', 'kansai', 'sikhin', 'cdcl', 'abbott', 'katlari', 'aadiwadiyon', 'chitrakathaa', 'avshisht', 'phyuchuristic', 'tereeh', 'nanhe', 'avery', 'suba', 'shakhayen', 'trikaldarshee', 'paalasaahee', 'failaiye', 'jhauvaa', 'jamati', 'janhani', 'ponding', 'taswaron', 'deshkal', 'hichkichaa', 'basteeh', 'garibi', 'phadphadaaen', 'sitaram', 'kmere', 'bairakpur', 'svayamswikrat', 'kaasovo', 'majboori', 'convocation', 'skipper', 'jaipur', 'prasthaanon', 'narm', 'radiopremi', 'titagarh', 'chico', 'rajyamantreesvatantra', 'mainval', 'gujarana', 'satluj', 'jatiyon', 'anhoni', 'telelinks', 'labs', 'harawal', 'marriage', 'maniya', 'tractors', 'kanchan', 'lairi', 'kaaryaawadhi', 'jalbharav', 'bhaadaa', 'baagora', 'piega', 'stephens', 'abhimat', 'accelya', 'wirerless', 'chauda', 'parbhani', 'khaatedar', 'badhna', 'burch', 'upadrawon', 'tikiyon', 'milk', 'dubona', 'baker', 'sutali', 'buddharam', 'wealth', 'patrani', 'ardhavishwaas', 'paim', 'castaneda', 'baljit', 'bhatnagar', 'jaatakon', 'ecuador', 'swargdoot', 'rushikul', 'tate', 'kanthhar', 'beaulad', 'europea', 'gaye', 'dadreva', 'bikherane', 'hamlo', 'pakdaae', 'uplabdhiyon', 'colorado', 'packard', 'jagruti', 'andhra', 'chounkate', 'bekhvaabiyaan', 'naphaa', 'sinha', 'utpidan', 'saga', 'aarya', 'dikhaaiye', 'anishtata', 'udan', 'sanyuktawastha', 'shamtal', 'evava', 'adhiwaktaagan', 'ralhan', 'jhuthalane', 'purvaabhaas', 'bijendrasinh', 'chinmani', 'loksbhavaali', 'ladki', 'narsinghgarh', 'sanghathanamantriyon', 'roopi', 'karykartaon', 'augusta', 'manmarji', 'antrmukh', 'anumar', 'rishtanaataa', 'dviarthi', 'chootile', 'hattiesburg', 'yoojee', 'raaj', 'raigulization', 'vindhya', 'fixingah', 'kamjor', 'bhara', 'chaudhavan', 'falne', 'shrunkhla', 'vipannta', 'proofread', 'zamana', 'ghataaegee', 'danga', 'erica', 'bhola', 'vyakhyatmakta', 'yojnah', 'webuniyadee', 'rumani', 'sahu', 'pradhaannagar', 'seattle', 'stain', 'insaani', 'hamla', 'nutrio', 'ladadd', 'antadiyan', 'kushwaha', 'kochchih', 'ganapathy', 'farmic', 'padengee', 'arth', 'mukarrar', 'niptakar', 'holidays', 'cooch', 'utthak', 'sulkhan', 'kamere', 'jagayega', 'santree', 'shakhsiyaten', 'panchang', 'zalana', 'nitya', 'ichchhee', 'habra', 'paaliyon', 'azoospermia', 'taavij', 'foodworks', 'graham', 'prabhaanmantree', 'seth', 'jagtap', 'harshit', 'dubna', 'raktadataon', 'mexico', 'tasir', 'eyarkandishnar', 'eddi', 'macon', 'israni', 'ainth', 'shreemahapurn', 'dork', 'jeenon', 'ghareebon', 'taraashakar', 'observer', 'aarya', 'ukhad', 'saathsaath', 'packagon', 'hindon', 'aprihary', 'manzil', 'lx', 'karvi', 'dubhashiyon', 'rikannekting', 'wind', 'client', 'shararat', 'ventura', 'rollins', 'haynes', 'niketan', 'krantiyon', 'twin', 'divya', 'gidgidate', 'nigmaayukt', 'gabalee', 'novato', 'rishwatkhor', 'faansi', 'garjana', 'nihlani', 'pintaa', 'greer', 'lewisville', 'prakaashit', 'clariant', 'khaayal', 'dwiarthi', 'raakhe', 'bulandshahr', 'stafford', 'najariyon', 'world', 'jeevniyaan', 'parmeshwarpur', 'uthanee', 'nyootriyo', 'jetha', 'baagbagichon', 'suchikitsaa', 'nagmandal', 'pradadhikariyon', 'urvarta', 'neal', 'kriptocurrencyon', 'svaayattshaasan', 'zarda', 'uplakshya', 'chhudwaya', 'vidagdhaa', 'mukhyamantripatana', 'gene', 'ratanpur', 'mhantam', 'guna', 'mtech', 'denevali', 'naabhikund', 'visheshanon', 'langaron', 'polythenon', 'sambit', 'dhundh', 'haan', 'takra', 'dhandhekhori', 'pulinde', 'epoklips', 'vigyaanapeediyaa', 'mahoney', 'poonjitantra', 'khare', 'ekstactor', 'zunheboto', 'priyamani', 'sawaal', 'sukhakar', 'aalochak', 'phaans', 'jayalalitaa', 'amjhera', 'bombay', 'vyagra', 'apnani', 'risane', 'chhure', 'charlotte', 'jose', 'raileeh', 'mejbaan', 'dhandhanya', 'dabur', 'bsss', 'najib', 'avsthayen', 'jabalpur', 'dharmanirpekshtaake', 'farmer', 'nacl', 'somerville', 'bull', 'jhulae', 'khagyaar', 'meharaam', 'dhasmana', 'ripan', 'bhagdaud', 'mithya', 'lalaaniyaa', 'bhulon', 'vadali', 'nagappattinam', 'vaimanya', 'biggest', 'jodta', 'mahattaron', 'orchha', 'dhairyavaan', 'sund', 'prince', 'zuban', 'camstudio', 'yooropiyaa', 'meza', 'bhusawal', 'gayatri', 'ware', 'buddhizeevon', 'enth', 'radar', 'ilayachi', 'ubaal', 'shreeganganagarwaasiyon', 'fitzgerald', 'jeevanshaili', 'chart', 'sargi', 'vedon', 'murmur', 'bhaate', 'wipkha', 'bayaane', 'madanaganja', 'packageon', 'varnankartaaon', 'jyada', 'lokotsaw', 'tewree', 'jhaugunj', 'malwan', 'tadanrusti', 'el', 'qabzaa', 'susanskrit', 'sandhol', 'aamariyapadha', 'haabban', 'bowling', 'rasme', 'emdablyupiel', 'vidhaaon', 'bowie', 'chennai', 'kamaljeet', 'singha', 'pensiondhariyon', 'barah', 'dubana', 'esetal', 'chouhan', 'phalne', 'siddhaarthah', 'apex', 'dalton', 'shrikhand', 'textiles', 'agarwal', 'mithyaachariyon', 'cement', 'kraanfrensing', 'sanskrutiyon', 'dhankkar', 'nizamabad', 'chhatenee', 'dushkriyaa', 'sasaram', 'chidhte', 'lamba', 'lautis', 'khaen', 'dhndhe', 'antayant', 'mass', 'baraamad', 'kremistry', 'uthanevale', 'lehna', 'siragitti', 'control', 'andaajee', 'cateline', 'pakshpat', 'fodo', 'franciska', 'prayogaprushth', 'krantidhara', 'daishwala', 'khurasan', 'quarantine', 'fond', 'pakshapat', 'putla', 'truth', 'sathsath', 'mohim', 'johnson', 'cpm', 'bataaya', 'palmer', 'tughlaqabad', 'apcotex', 'hairam', 'sarebajar', 'jerusalem', 'mold', 'warnankartaaon', 'hooper', 'waters', 'lubhaate', 'fefda', 'kamottejna', 'dampati', 'soya', 'barbartapurna', 'tadipar', 'lutf', 'tariko', 'chataa', 'pittman', 'pahla', 'multimedia', 'tyohaar', 'label', 'le', 'tirthatan', 'satuaa', 'vargas', 'dabolim', 'soochnaah', 'labelling', 'roseville', 'phaaeebrets', 'aalto', 'partanee', 'asmitaon', 'want', 'tadpatee', 'patel', 'kaaji', 'dostanapurna', 'kshetron', 'lynch', 'state', 'ragon', 'malhotra', 'pragyatantra', 'duneerti', 'crosse', 'avyavasayi', 'dhiryawaan', 'time', 'ashariri', 'chandradas', 'jyotishi', 'alexandria', 'bewakoofaanaa', 'sirpur', 'uzbek', 'kharuvaar', 'dharmaviheenataa', 'surendranagar', 'aalha', 'arunachal', 'krueger', 'bagli', 'davindarpaal', 'chaplusi', 'sanskariyon', 'engines', 'mendez', 'siyah', 'gujaarane', 'gajara', 'kavi', 'midnapore', 'vrutton', 'sirmon', 'vartman', 'ubhrega', 'pilot', 'narbhakshi', 'entreeks', 'dayton', 'badoo', 'allrounder', 'nishra', 'wadhawan', 'jensen', 'pali', 'trimasik', 'attraikt', 'vavidyaalaya', 'chandan', 'mega', 'mansfield', 'mattancheri', 'navketan', 'kamtar', 'pityooniya', 'purooshottampur', 'tapan', 'jubaan', 'enseeaardablyoosee', 'haimbalin', 'aaraam', 'yashpal', 'wokha', 'chhetri', 'omaxe', 'parween', 'kukreja', 'premphalah', 'narmi', 'shrinkhalaon', 'avrodhak', 'teeron', 'ganesha', 'jhada', 'anupama', 'talabgaar', 'bindal', 'zavala', 'aamriyapada', 'pratinidhikaree', 'halmatpuraa', 'boodam', 'macias', 'medical', 'respecting', 'ranjkta', 'da', 'suction', 'bhumi', 'tyoharon', 'rangate', 'uttra', 'penshandhaariyon', 'karykartaaon', 'vidyaaon', 'dafan', 'sarhind', 'khaaskar', 'raith', 'gudagaunw', 'sahab', 'udaanon', 'majesco', 'pushpa', 'keshari', 'bombi', 'kargil', 'takara', 'biji', 'chrome', 'stithi', 'gulf', 'kaaloniwaasiyon', 'aavritiyon', 'suhanubhooti', 'chamach', 'virodhabhasi', 'saabhaar', 'allcargo', 'harana', 'avyavasayee', 'pravinses', 'chhetthari', 'pratishthi', 'sapa', 'patki', 'parchiyon', 'prativad', 'liphaaphaa', 'darshana', 'garrison', 'aakandon', 'dhandon', 'distreebyootaree', 'khatri', 'panjika', 'baatah', 'ravaley', 'kangan', 'premaatmak', 'sipahi', 'notebandishuda', 'devlaha', 'halla', 'jhamaaten', 'massey', 'usak', 'pitamah', 'vivaranahbhaarateey', 'nagercoil', 'lakhkhi', 'achhi', 'satin', 'nagpur', 'basirhat', 'chhelai', 'ubarkar', 'sanyuktavastha', 'suri', 'bhapaai', 'vyaktigat', 'mhathir', 'flesh', 'rashtrak', 'raajbhaaee', 'hong', 'langron', 'subhaay', 'fund', 'flowers', 'uthane', 'badaa', 'mishra', 'shat', 'manhattan', 'sarguja', 'evening', 'grahankaal', 'bagali', 'neeoo', 'mundwa', 'tolasan', 'jedateeisaft', 'naagmandal', 'kanaal', 'machilipatnam', 'felix', 'hastaksharon', 'bhilai', 'contracting', 'qraar', 'jaun', 'bhaloo', 'fortis', 'girijagharon', 'jainon', 'arthavyavasthaah', 'oxys', 'khitabon', 'enka', 'chashma', 'batao', 'ghrutakumaaree', 'pratestent', 'bauer', 'lakshmidhar', 'siyasi', 'upyogitawadiyon', 'toogaa', 'samadjiyon', 'khurpaka', 'kumavat', 'mwp', 'suraj', 'neuroscientists', 'chandreshwaranagar', 'tanish', 'farukhnagar', 'awaazon', 'najraane', 'pashuchaaraa', 'webuniyadi', 'danbury', 'naidillee', 'chhalla', 'rowan', 'sheopur', 'rawlani', 'sanvaree', 'dhaak', 'masse', 'insurance', 'samprbhuta', 'raashtraa', 'jauhari', 'judai', 'badamaashon', 'khitaabon', 'swayam', 'aagah', 'dhindhwal', 'ghise', 'sappaanwaalee', 'nikharen', 'baadhit', 'brahmapur', 'baytown', 'koling', 'samadhiyon', 'yooniyanwaadi', 'chhapemar', 'gareebon', 'thousand', 'dasila', 'kanjentevaaitis', 'badhaon', 'lagega', 'durghatna', 'nitiyon', 'capdhari', 'atri', 'singam', 'vastvik', 'substensis', 'peelepan', 'uthnee', 'handiyaa', 'pratirakshi', 'lalkarta', 'dukaanon', 'nividaataon', 'sarvjaateeya', 'narsanharon', 'neemkathana', 'herrera', 'junun', 'ikai', 'jagdalpur', 'swiftlet', 'jalagati', 'pitts', 'ropi', 'adanga', 'alasi', 'chaukiyan', 'layton', 'vakrangee', 'development', 'shawnee', 'pardesiyon', 'bhoogol', 'bagichi', 'sivan', 'stray', 'aalsi', 'view', 'vishhin', 'kissagoi', 'mahanideshak', 'chikitsaevam', 'bhattacharya', 'trenton', 'kanyaein', 'priyadarshini', 'hukhookh', 'shulkah', 'rane', 'mahavidya', 'sanshyon', 'shreneeh', 'odom', 'benitez', 'tyohar', 'matiyaanaa', 'shavyaatra', 'rishtey', 'rehaana', 'qss', 'anaavashyak', 'rijhaayaa', 'brigade', 'sapane', 'chuneen', 'koshadhikaari', 'karab', 'paltane', 'karneshwardham', 'aaryanas', 'pratishthanon', 'karaikal', 'uski', 'vipreetataa', 'parikshao', 'fyuji', 'laaminaar', 'jutati', 'kaushik', 'bekaaboo', 'nano', 'orissa', 'tomar', 'ropee', 'thappadhabaajhee', 'baabat', 'attahasa', 'colan', 'pratileetar', 'bhusi', 'haliyaa', 'utpeedan', 'pope', 'karkhele', 'bahulya', 'aswbhavik', 'kathhnaeeyon', 'ramjeelaal', 'vasulta', 'mukhyamantri', 'maria', 'satmev', 'baksa', 'udar', 'man', 'buddhijivon', 'sudip', 'jodo', 'tasdeek', 'nikaalni', 'bhatkaanaa', 'harna', 'dillon', 'registerd', 'bhandara', 'lalaniya', 'lima', 'lalkrishna', 'ratnabhooshan', 'sparivar', 'sah', 'sametti', 'pyria', 'maamalonmen', 'braat', 'vaiisan', 'villa', 'linda', 'khariya', 'chellani', 'electronics', 'rishiraj', 'udaipur', 'pagla', 'ritukaant', 'kurmi', 'dastaanaa', 'emrald', 'ghumaaee', 'updraviyon', 'oklahoma', 'dharmaraajne', 'jhaohuee', 'uppidan', 'khemik', 'tugalki', 'duar', 'avi', 'jadet', 'taiboo', 'programmers', 'taylorsville', 'chadron', 'racer', 'bhakaa', 'andhabhakto', 'obrayan', 'krutya', 'peeran', 'najriyon', 'mayur', 'chaudhawan', 'swargadoot', 'feka', 'independet', 'tinkaa', 'gurdon', 'jaatiyon', 'samanwayaka', 'sube', 'chandana', 'praarambhikataa', 'trap', 'udant', 'dynamatic', 'vidyuteekrit', 'lalaniyaa', 'wadaraa', 'ved', 'fadfadaen', 'traded', 'akhuaapaadaa', 'saraha', 'vigyaanvaadiyon', 'kamzor', 'youngstown', 'aaryam', 'patkathaein', 'bajpai', 'jassee', 'nau', 'evav', 'lagataar', 'suman', 'padanee', 'mindtree', 'distributary', 'jankaron', 'shankacharaachaarya', 'offshore', 'dukhon', 'nesco', 'phooltee', 'tools', 'verger', 'dumghontu', 'videoh', 'rajman', 'aatmamugdh', 'rockford', 'mitra', 'devnaar', 'ocoee', 'uttariya', 'kainawij', 'galaxion', 'jivaniya', 'hakikat', 'eliminator', 'augustine', 'kar', 'bitane', 'daftarwale', 'bairaadh', 'kambalon', 'jwar', 'fatama', 'vives', 'dwt', 'dhaatuein', 'siyaha', 'pitne', 'bichchon', 'jita', 'sevala', 'bataur', 'aditya', 'kshetren', 'ankeny', 'chheter', 'mukarte', 'enthe', 'balty', 'khangaali', 'beeeseses', 'banjajasam', 'pushpit', 'linmarga', 'pereddy', 'bodara', 'focus', 'dootaay', 'sreeleathers', 'mahankmadaan', 'ghunsa', 'kaavyavidhaaon', 'kshatriyaadi', 'jaankaaron', 'rakhna', 'rishtedaaro', 'shravani', 'kubuddeen', 'jewellers', 'mehaman', 'rojlin', 'jaikara', 'chabutre', 'haradil', 'truck', 'neurovascular', 'khelaane', 'stration', 'lakshayatirth', 'nations', 'paathshaalaayein', 'nivedanah', 'lidaron', 'tanla', 'sevakon', 'poorvapekshaon', 'mani', 'somvar', 'pran', 'avegyanik', 'aviation', 'brown', 'naakaam', 'adhivas', 'janjagran', 'rajnandgaon', 'larry', 'bhalu', 'tareeko', 'chicopee', 'refractories', 'baramad', 'kav', 'emerald', 'vivekaadheen', 'fadfadaaen', 'kaylana', 'paints', 'pittsburgh', 'hokhat', 'chaurasiya', 'sacchidanand', 'seide', 'charon', 'rizvi', 'clay', 'danpati', 'doorgadh', 'devapur', 'manwaayaa', 'latakkar', 'mehmaan', 'niya', 'udhampur', 'ataher', 'chhupata', 'tungnath', 'raghupati', 'prakandh', 'changed', 'gangtok', 'cricket', 'francisco', 'bhagane', 'adangaa', 'fixingh', 'kamau', 'tikone', 'pam', 'tarikon', 'aagaman', 'kidwai', 'aashriton', 'raghavan', 'janeudhari', 'davenport', 'preranaapuree', 'mahasinh', 'lordaa', 'introduction', 'swabhavatah', 'grishmotsav', 'talaashegaa', 'saharsa', 'mckay', 'moshe', 'granthiyan', 'lohaati', 'aliance', 'tagde', 'chinke', 'siwan', 'thaki', 'letakar', 'hikariko', 'tyres', 'nrutyon', 'deerfield', 'charit', 'bethlehem', 'fineotex', 'asahi', 'pehan', 'dhanshyaam', 'faarensis', 'lahanaa', 'dwarikesh', 'dubaana', 'karaboriyon', 'golamuree', 'raakhnau', 'vipanak', 'punchang', 'breed', 'gullaravaalaa', 'awp', 'baji', 'harpaal', 'premeshwar', 'prapt', 'naksalwaad', 'kanthahar', 'oxide', 'khairati', 'deshke', 'sunaseer', 'aphasaron', 'seho', 'chabate', 'miti', 'belcha', 'saflata', 'shbana', 'khaatootolaa', 'shivastava', 'preranapuree']\n",
            "['थरमैक्स', 'सिखाएगा', 'लर्न', 'ट्विटर्स', 'तिरुनेलवेली', 'इंडिपेंडेंस', 'स्पेशियों', 'शुरूः', 'कोल्हापुर', 'अजहर', 'क़रार', 'अंक', 'डब्ल्यूपीडी', 'हाशिए', 'ग्लेंडल', 'उधेड़', 'इकठ्ठी', 'आईडिया', 'अम्बिकापुर', 'माकेरेरे', 'साबूदाने', 'फूहड़ता', 'सेक्वेंट', 'शुऐब', 'पानीहाटी', 'समेटती', 'उखरुल', 'ब्रह्मलीन', 'उतराधिकारी', 'इक़बाल', 'दयालपुरा', 'सोहराई', 'तक़रीबन', 'फर्रूखनगर', 'ठेंगा', 'त्यौहारों', 'कर्णेश्वरधाम', 'उमानाथ', 'दानशील', 'साहित्योत्सव', 'शांतिनिकेतन', 'शिकायतकर्ता', 'अंदरखाने', 'पंटर', 'लीडरों', 'गलगंड', 'कार्नियां', 'मुर्गीपालन', 'मुशाहिद', 'मॉड्यूल्स', 'रजौरी', 'सुश्रुषा', 'शृंगार', 'होल्ट', 'लैंगिकता', 'इजाजत', 'वनक्षेत्र', 'भूतल', 'स्वादप्रेमियों', 'नाइनटीज', 'फ्रेक्टर', 'लिखकर', 'एयरकंडीशनर', 'नब्ज़', 'कुएस', 'बौनी', 'कारगुजारियां', 'गांगनाम', 'तापीया', 'तेज़पुर', 'तलवे', 'सीमाई', 'दर्शनार्थी', 'रिवास', 'तर्कवाद', 'अनुसारका', 'कोचेला', 'लटककर', 'पत्रावलियां', 'परिषद', 'स्पिन्ज', 'अनशिदा', 'डिजीसस', 'सरायमोहिउद्दीनपुर', 'लॉवेल', 'कैपेसिटर', 'पैसेंजरजींद', 'ग्रंथियों', 'बुएना', 'कैंटरबरी', 'काठियावड़ी', 'टेकचंदानी', 'फ़ीसद', 'बेरहरमी', 'निष्कर्षः', 'ऐक्टिविटीज', 'रिकैलीब्रेशन', 'शासनाधिकारियों', 'फिजूलखर्ची', 'डब्ल्यूपीडी', 'पेस', 'दस्तार', 'कैटलिन', 'जोड़ता', 'किल्लत', 'गृहनगर', 'वंडर', 'वाटर', 'श्विंग', 'पश्तून', 'फार्म', 'डिबनू', 'पश्चमी', 'उठापटक', 'नीलाभ', 'लक्ष्मीनियां', 'महानगरवासियों', 'उपनेता', 'कन्वेंशन', 'शाॅर्प', 'कार्ययोजना', 'मास', 'वेस्टिंग', 'कुर्वेती', 'ज़यादा', 'मुकेश्वरी', 'श्रीमति', 'विवेकाधिकारों', 'लोकसभावाली', 'कबहा', 'भ्रांतियों', 'विवेकहीन', 'बाल्मीकि', 'हरयाणा', 'जीवराज', 'फ्लिन', 'राणा', 'विष्णुपुरा', 'घोटालेबाजों', 'हैरतअंगेज़', 'तकलीफ़देह', 'पीपाड़', 'धभाशारा', 'अंतडियां', 'राबिन', 'सिंगार', 'गुमशुदगी', 'बालकृष्ण', 'फब्ती', 'पलटने', 'लहलहाती', 'नगाड़ा', 'उड़ानें', 'क्लेन', 'जूलूस', 'कार्यभार', 'मंटो', 'पैमाइश', 'कोविना', 'पेंषन', 'ऑगस्टावेस्टलैंड', 'सैंट्रींग', 'ऐक्टिवा', 'बार्कर', 'वल्कन', 'वृत्तों', 'कबड्डी', 'रौनक़', 'कैटलिन', 'फूस', 'जनगणना', 'उपाख्यानों', 'सुंदरम', 'कोचीन', 'नेको', 'कौशल', 'फालिया', 'एस्वेडो', 'कोट्टयम', 'दिलाएगा', 'कर्वी', 'सौंपेंगी', 'लेख़न', 'गुडेपु', 'फरसे', 'नूबिया', 'ताजा', 'आंत्रित', 'काजी', 'मुर्गीपालन', 'एड्डी', 'नगीने', 'सुब्हा', 'लुइस', 'विजयापुरम', 'बताअाे', 'ओकोआ', 'साइंस', 'सरकारें', 'ब्रेमटन', 'गुरुपदो', 'संयुक्त', 'रालोद', 'बाधाओं', 'गौमूत्र', 'सभाएं', 'तनी', 'दिल्ली', 'सुजेन', 'विनीत', 'चिमाते', 'किकियाना', 'रॊकेट', 'मैक्सवेल', 'हिप्पो', 'दीपन', 'अर्यमा', 'भूलता', 'कर्माचारी', 'दुर्गापुर', 'त्रिभाषा', 'सूदखोरों', 'प्रस्तावों', 'सुरवीन', 'प्राप्ती', 'गिरिवासियों', 'सिडयूसिंग', 'वेलवेट', 'मुक़र्रर', 'बैक्सटर', 'डेनिअर', 'सीडब्ल्यू', 'उठनी', 'घासी', 'इकट्ठा', 'भूपसिंह', 'दबोचने', 'क्रॉस्बी', 'नामीगिरामी', 'हर्ले', 'जर्दा', 'लिएप्रधानमंत्री', 'भ्रांति', 'ऐजेंसियों', 'बागो', 'फारसी', 'बोसान', 'कार्की', 'गिनते', 'मनोकामनाओं', 'संम्पत्तियां', 'पॉलिथीनों', 'एमटेक', 'परिचर', 'बडबडी', 'क्रेन', 'लामियां', 'उल्हासनगर', 'प्रभानमंत्री', 'शिवालापुरवा', 'फर्थ', 'सुहागिन', 'सरायकेला', 'रोमियोविल', 'राजस्थानवासियों', 'प्रतिरोधात्मक', 'स्वर्णिका', 'व्यवस्थापना', 'तेल', 'ग़लतफ़हमी', 'टेकइनसाइडर', 'माइक्रोफाइबर', 'श्रीमहापूर्ण', 'फ़ल्लूजा', 'डोनल्डसन', 'चढ़ने', 'जीवविज्ञानियों', 'क्रिकेटिंग', 'रिडक्शन', 'आवाज़ें', 'व्लाद', 'प्राथमिक', 'ठेंगा', 'एक्सेल', 'चटकाते', 'कुबुद्दीन', 'ताजा', 'पड़नी', 'नीचाई', 'वौसौ', 'आलोचकों', 'ज़लज़ले', 'सूरत', 'जीवति', 'प्रहारक', 'श्रीसद्गुरु', 'संचालनों', 'भाल', 'तुगलक', 'उठापटक', 'हस्तांतरणीय', 'उत्साहवर्द्धन', 'संगोष्ट्री', 'शासनाधिकारियों', 'महाधिपतियों', 'फातिमा', 'फोड़े', 'कंटिन्यू', 'कामानाएं', 'चुटीले', 'संख्याएं', 'करंज', 'बरसाता', 'परिकल्पित', 'हरपाल', 'माऊंट', 'ग्रोवर', 'बायोलॉजिस्', 'हालिशहर', 'एंजेलो', 'जनेऊधारी', 'बीचबचाव', 'पोकर', 'अपवर्तित', 'आस्तीन', 'प्रतिष्ठावाले', 'ब्युनावेंचुरा', 'डेक्कन', 'सेरिव', 'पर्दा', 'एमिल', 'शैली', 'ईस्टवेल', 'छल्ला', 'लक्ष्यों', 'हॉफ', 'जरूरीः', 'रह्या', 'महकने', 'देवी', 'नील्सन', 'भीरा', 'चबूतरे', 'भूषण', 'रुकते', 'आमदनी', 'टॉकशो', 'जूनागढ़', 'पढ़ाता', 'ओढ़कर', 'ब्रोक', 'तलाशा', 'परिवारवाले', 'ट्रिब्यूनल', 'ब्रोक', 'यल्लाप्पा', 'तस्वारों', 'तुगलकी', 'पिक', 'सर्किलेशन', 'ज्वार', 'कनिंघम', 'कुश', 'प्रॉपरफेसबुक', 'अशरफी', 'चढ़ें', 'वांगचुक', 'हनीवेल', 'रेडियमधर्मी', 'लड़ेगे', 'सचन', 'अर्थशास्त्रीयों', 'कैंटन', 'आत्ममुग्ध', 'पॉन्टिएक', 'लोपेज़', 'घोंटना', 'अम्बानी', 'मर्यादाओं', 'रतलाम', 'हरक्यूलिस', 'अकोला', 'सक्शन', 'नोटबंदीशुदा', 'लगवाती', 'अलाइव', 'जीवंत', 'फोड़ा', 'फटही', 'नूबिया', 'लालमणी', 'फ़ैसला', 'कृत्या', 'धुआं', 'आहूजा', 'प्रतिपालपुर', 'नमकीन', 'मंजिलें', 'लफ्फाजी', 'जुराब', 'फुलाए', 'केस्टालॉय', 'ब्लैक', 'सूरज', 'ब्रॉन्च', 'अवर्णता', 'जोहरी', 'तेवरी', 'सेंडर्स', 'वेल्डर', 'एनईयू', 'भरष्टाचारियों', 'लालमणी', 'खातेदार', 'आजमाना', 'आवृत्तियों', 'कुल्लवी', 'बहावलपुर', 'प्राथमिकता', 'मोबाइल', 'कटिहार', 'स्वेच्छा', 'हामिदन', 'समदर्शिनी', 'दृढ़', 'गोंद', 'विशेश', 'काबिलेगौर', 'लौरेंस', 'हिशाम', 'चौसिंगा', 'पफिन', 'मेट', 'बिल्डकॉन', 'टीकों', 'अथक', 'जिदंगी', 'चायल', 'माप', 'लास्ट', 'गजरा', 'रात्रिचर', 'काथला', 'सहूलियत', 'पटनायक', 'न्यायालयीन', 'मुख्यमंत्रियाें', 'जीतनेवालों', 'स्वफ़ोटो', 'क्लिफ्टन', 'डोडा', 'पेंडुलम', 'चिपकने', 'नलकसा', 'छह', 'गोंड', 'समीक्षाकर्ता', 'मंत्रीपद', 'लिब्रेशन', 'असमान्य', 'चुंगियों', 'एरिका', 'बेलोट', 'थींं', 'फार्मिक', 'युद्धक', 'वेगास', 'लास्ट', 'चित्रांशी', 'अवर्णता', 'वेस्टिंग', 'वितर्क', 'मुकबाले', 'धर्मपूर्वी', 'अंबानी', 'इबीजा', 'महामीडिया', 'सुज़लोन', 'वर्णित', 'झुठलाने', 'मदुरई', 'कौण्डल', 'लापत्ता', 'क्षीण', 'तेवरी', 'रायचूर', 'लिंडन', 'पुलमा', 'ऑलराउंडर', 'ग़रीबों', 'कालाहान', 'वाबाग', 'कैपधारी', 'आटा', 'बरेली', 'जिंग', 'जीवन', 'रेड्डी', 'पहनी', 'तनु', 'दीपिका', 'लोहाती', 'कक्कड़', 'मौलवियों', 'डूंगरपुर', 'झालाना', 'लक्मे', 'प्रोस्पैक्ट्स', 'वेस्टिंगहाउस', 'बावरा', 'ठक्कर', 'इच्छाचारी', 'त्रिया', 'धावकों', 'दामले', 'श्रवणाबेलागोला', 'नीलकमल', 'कर्माचारी', 'पूर्वाेत्तर', 'लहराई', 'हैतो', 'प्रकाण्ड़', 'खेलमंत्री', 'भविष्य', 'एगमोर', 'शृंगार', 'सौंपेंगी', 'नॉक्सविल', 'बेंडर', 'सुंदरम', 'प्रदेश', 'संवेदीकरण', 'लगुना', 'भीष्म', 'येम्मिगनुर', 'हुहतमाकी', 'वडाली', 'गेल', 'रेस', 'सालाज़र', 'डिप्थीरिया', 'दृढ़', 'शदधि', 'प्रबोधिनी', 'लोकप्रतिनिधियों', 'जताती', 'मंगला', 'बर्विन', 'मम', 'उदयगढ़ी', 'अकापुल्को', 'वैधृति', 'चरणबद्घ', 'मनदड़ी', 'यूक्लिड', 'पारंपरिकता', 'हांफते', 'साथिया', 'संघीयता', 'मुख्यअतिथियों', 'व्यवस्थाविरोधी', 'रक्तदाताओं', 'बरामदे', 'तरुतल', 'कुत्ता', 'झाड़ा', 'किशुन', 'स्कैफ़लर', 'अमरोही', 'रैडिकल', 'जेनर', 'वर्षिय', 'हसीनों', 'शावकों', 'रूपा', 'स्वार्थपरक', 'वेरोनिका', 'वेब', 'महापात्रा', 'छींके', 'अग्र', 'जियांगकोऊ', 'वेस्टवर्क', 'जनगणना', 'पास्को', 'जाधव', 'एंटरप्राइज', 'संशयों', 'वर्णव्यवस्थावादियों', 'उपस्थियों', 'मुडिचु', 'पर्नस्टारों', 'ईए', 'बैला', 'लिवाल', 'हिल्सबोरो', 'राष्ट्रियाध्यक्ष', 'पीडब्ल्यूटी', 'थाउजेंड', 'शाकिर', 'सलाहकार', 'विश्वकर्मा', 'रिज', 'स्वास्थ्यहीनता', 'रिश्वतखोर', 'प्राविंसेस', 'दफ्तरवाले', 'फिजिशियन', 'लोग', 'जोधिका', 'सेवाला', 'डूबत', 'सिपाह', 'भरमा', 'प्रतिज्ञा', 'मेघवाल', 'नंदोई', 'ऑरोरा', 'फार्मूले', 'दुर्घटना', 'स्वतंत्रसिंह', 'मोंटेरे', 'बाल्टी', 'कोलंबिया', 'व्हिटियर', 'दुक्के', 'क्यूबेक', 'चमकना', 'शीलभंग', 'बिस्तागोंड', 'फाइंडले', 'बापा', 'देहरा', 'ऐसे', 'श्रंखला', 'हस्ताक्षरों', 'तिरुपति', 'मंगलमूर्तिः', 'कुर्सियों', 'मिठाइयाँ', 'पहनो', 'हैलबिड', 'बंगश', 'ऑफिशियली', 'सेंवई', 'गुर्जर', 'समन्वयक', 'पार्नेल', 'सूनसान', 'क्यूसैक्स', 'मध्य', 'युद्धरत', 'अर्बनडेल', 'ब्रिग्स', 'एरर', 'चिखली', 'वाण', 'अधिकारियां', 'रोनोक', 'हाओकिप', 'पूर्वापेक्षाओं', 'मशीनवत', 'कदमो', 'कुरमी', 'विद्याथयों', 'सिमटता', 'संगरूर', 'स्ट्रोंगस्विल', 'अगवाई', 'जनगन', 'नागराज', 'यारियां', 'भाग्येष्वर', 'जीवति', 'सूदखोरों', 'रुकवाकर', 'ब्रह्मवर्ता', 'ग्रे', 'भ्रांति', 'पुरूषोत्तमपुर', 'तेजी', 'स्वातं', 'मंत्रिमंडलीय', 'एशले', 'मेथिव्स', 'मूलों', 'एक्ज़ो', 'हमीरपुर', 'पोखरियाल', 'बोलतीं', 'प्रतिष्ठावाले', 'दबंगता', 'धुरिया', 'टिप', 'गाज़ी', 'इजाजत', 'मेज़बानी', 'टोलेडो', 'मोहड़ा', 'पुतली', 'संचारी', 'टापनी', 'लिटिल', 'नरनारी', 'धनिये', 'गाड़ूँगा', 'फाड़ी', 'गम्मत', 'ट्यूबरक्यूलोसिस', 'नागार्जुन', 'राजनीचि', 'मेडिजेन्सर', 'लफ्फाजी', 'कॉमर्स', 'माथलू', 'चटगांव', 'हीलिग', 'इस्न्पेक्टोर', 'टेस्टिंग', 'नौशाद', 'फ़ल्लूजा', 'पिक', 'जीवन', 'कताल', 'डब्ल्यूईएफ', 'बेसिल', 'स्लाइडों', 'सैंदान', 'जेरेमी', 'गॉंव', 'तोड़ेंगे', 'उड़ान', 'सप्तक्रांति', 'मिरांडा', 'व्यापक', 'मैडी', 'सभासदों', 'नौवहन', 'आत्माएं', 'रोज़ा', 'दमाए', 'मिडवेस्ट', 'ट्रेलरः', 'मालबर', 'वाको', 'विमर्शों', 'खान', 'डिफरर्ड', 'सरसा', 'हेस्टर', 'उत्तर', 'कसेरा', 'कुरआने', 'दायित्वों', 'चयनितों', 'मोराल्स', 'हीरोज', 'प्रेममूलक', 'मोरन', 'ज़ाइडस', 'नेल्सन', 'अमरपाल', 'फटने', 'टिंका', 'गायिकाओ', 'पकाएं', 'भ्रष्टाचारीयों', 'चालित', 'एफल', 'मॉड', 'राजनीतिकारों', 'अर्थों', 'गालीगलौज', 'अन्योन्याश्रितता', 'उडाया', 'कटलरी', 'प्रतिबन्धः', 'नीलाभ', 'बिलाई', 'खुल्लमखुल्ला', 'स्वानसन', 'अन्वाहार्य', 'रेवाड़ी', 'सहकलाकार', 'चैंपियनशिप', 'भड़काया', 'नामधारी', 'अल्बा', 'वातानुकूलन', 'खाताधारक', 'टेक्सस', 'स्पेशल', 'हरवंश', 'दीनु', 'शनिवार', 'डीई', 'डाबी', 'नहींकरवाई', 'मारवाड़', 'पीड़ियों', 'ब्रिगटन', 'मनाए', 'लिगर', 'दिलाएगा', 'आधीन', 'परवा', 'हेम्प्सटेड', 'मामूली', 'प्रदेशिका', 'वैरीफ़िकेशन', 'फेफड़ा', 'विसंगतिया', 'कच्छे', 'घोस्ट', 'पिपली', 'लवासा', 'हेल्पर', 'डूबनेवाले', 'बख्शने', 'इन्द्रियोंके', 'बरहद', 'रिसाली', 'काक्षीवती', 'विश्वरक्त', 'लोदी', 'पीचट्री', 'घुमक्कड़ों', 'ओझा', 'इलाज़', 'अरुणाई', 'अयोध्यानाथ', 'भौतिकवादियों', 'रॊकेट', 'न्यूरोकेमिस्ट्री', 'काल्डवेल', 'आवाज़ें', 'मूल', 'मल्टिप्लेक्सों', 'त्यौहार', 'रोटेशन', 'बेलचा', 'सहकलाकार', 'जड़ित', 'नगाड़ा', 'बरपाया', 'डूंगरपुर', 'लैंड', 'उच्छृंखलता', 'फैलाइए', 'सूची', 'नून', 'आरपी', 'सील्ड', 'पालनपुर', 'इलेक्ट्रोस्टील', 'ऑब्स्क्योरा', 'सिगरेटों', 'दिखाईं', 'रसल', 'नजरंदाज', 'कुआलालंपूर', 'ऑस्टिन', 'रैडक्रास', 'टीसीएनएस', 'स्वायत्तशासन', 'मूड', 'दौलताबाद', 'भूलता', 'प्रतिकारा', 'नाइट्रस', 'नाकाम', 'शुटिंग', 'राष्ट्रा', 'बेचकर', 'स्टोन', 'वर्धा', 'डीडब्ल्यूटी', 'देसबथुला', 'बापा', 'बाघबान', 'आदेशः', 'उड़ेलकर', 'तर्कों', 'याद्दाश्त', 'इनहेलेशन', 'सफरदगंज', 'रूपक', 'स्क्रेनटन', 'वर्णव्यवस्थावादियों', 'शिक्षाकार्मियों', 'खंडेलवाल', 'बेवरेजेस', 'पीडिया', 'नदफ', 'जेहे', 'ढहाएँगे', 'मस्तमौला', 'अगरतला', 'जमाया', 'परदेसी', 'आर्यों', 'वेलवेट', 'आपदाएं', 'आगाशे', 'अच्छी', 'उदघोष', 'स्वभावतः', 'बानी', 'राइकर', 'पीडीलाइट', 'ड्युअल', 'भीरा', 'सिल्वा', 'अधिकरन', 'रंजकता', 'श्रीचक्र', 'गौमूत्र', 'निचला', 'बुरहानपुर', 'सहूलियत', 'लब्ध', 'पूल', 'स्ट्रेशन', 'पीकिंग', 'ऑडिटर', 'डेनिअर', 'अजित', 'लैंगडन', 'अवशिष्ट', 'झ', 'प्रशासनिक', 'बोसीयर', 'बढ़ाचढ़ाकर', 'गिरिडीह', 'भुज', 'रीडिंग', 'फव्वारे', 'अद्वैत', 'रुकते', 'अनोंदिता', 'फोंटाना', 'न्यूट्रियो', 'पायलटों', 'जड़ें', 'बोरीवली', 'इलाइची', 'एलियंस', 'धम्मा', 'नाहरगढ', 'एनएसआईयू', 'सपाट', 'लैंगडन', 'पनामा', 'पुतले', 'आसापास', 'अल्वधि', 'मुफलिसी', 'संसथान', 'दर्शनार्थी', 'लोकोत्सव', 'ग्राहकोंने', 'उच्चअधिकारीयो', 'बहाव', 'रेजा', 'मदरसन', 'काॅप्लेक्स', 'आबूरोड', 'हैडलबेर्गसिएट', 'चिमटी', 'सर्फेकटेंट्स', 'मिटाओ', 'कायलाना', 'टंकार', 'ओढ़कर', 'मेड़ता', 'मेगवाल', 'रसायनिक', 'सूचनाः', 'सुगमता', 'जोकि', 'मुनाफ', 'निस्वार्थ', 'क्षेत्रद्वारा', 'महावर', 'बुलढाना', 'धमकाता', 'भूस्वामी', 'विज्ञान', 'क्यूट', 'बेवकूफाना', 'जाजमऊ', 'बेल्ट्रान', 'विलास', 'मखदुमपुर', 'कोलोराडो', 'ब्लैकबर्न', 'सुनीति', 'घिग्घी', 'फ्लेवनाइड्स', 'चहुंमुखी', 'सुपाच्य', 'सिरती', 'विष्णु', 'चौदहवां', 'चौधरी', 'आबरू', 'बलुरक', 'दावणगेरे', 'अनुरीत', 'शिपिंग', 'पटियाला', 'जानम', 'फाइनेंसियल', 'दमाए', 'पालिसी', 'आइसीसी', 'कुच्छ', 'चीखना', 'रिलायंस', 'उर्वरकों', 'रवैल', 'लड़कियो', 'मुकेश्वरी', 'वनक्षेत्र', 'उम्मीदे', 'कहावह', 'कांतिपूर्ण', 'बड़ाएँ', 'एनसीआरडब्ल्यूसी', 'प्रतिबद्धाता', 'फ़ॉलो', 'सेवामुक्त', 'इवान्स्टन', 'चरस', 'हील्स', 'रॉबर्टसन', 'भदौरिया', 'ग्लैक्सोस्मिथक्लीन', 'प्रॉडक्टों', 'गेवारा', 'विज्ञानों', 'जार्विस', 'लफ्ज', 'फॉन्ट', 'पराधीन', 'शक़', 'गंझू', 'डिट', 'दंपतियों', 'माड़ीखेड़ा', 'प्रतिष्ठानोंं', 'सूंड़', 'गिनते', 'अलगअलग', 'स्वास्तिकाकार', 'प्रतिकारा', 'आस्तिक', 'निवेशकर्ता', 'सवाल', 'संस्कृतियां', 'रौबदार', 'रघुराम', 'इंटरव्यु', 'छरहरी', 'सॉयर', 'भासपा', 'ज्वारों', 'संस्थिता', 'पार्षदों', 'पुलत्स्कर', 'उठाएँगे', 'लाएंगी', 'ओईएफ', 'वलसाड', 'मूलों', 'पुतलियां', 'शमिल', 'रिग्स', 'कैमेरिलो', 'सफ़लता', 'विनष्ट', 'कपिंग', 'जयललिता', 'आइटम्स', 'सॉकर', 'एस्फाल्ट', 'मेहरोत्रा', 'चुने', 'जरख', 'मेज़बानी', 'मुफलिसी', 'लूना', 'वर्णव्यवस्थावादियों', 'लिपाई', 'उठनी', 'बजाज', 'हिसारः', 'दंपतियों', 'वॉटसन', 'अगस्टाइन', 'पटाक्षेप', 'धंधेखोरी', 'उभरेगा', 'एंटोन', 'अपारदर्शी', 'निहलानी', 'टिवोली', 'होगिस', 'विंटर', 'बदलवाकर', 'घुमाई', 'पेटालुमा', 'बीएमडब्ल्यूएम', 'बख्शते', 'संवेदीकरण', 'तेलों', 'घुमक्कड़ों', 'हांफते', 'फरहीन', 'जेम्स', 'कीरतपुर', 'रेडिंग', 'शक़', 'सरप्राइज़', 'किसानों', 'चलेंगे', 'योडेर', 'स्टीन', 'पैथेलॉजिस्ट', 'लेबलिंग', 'इक्थियोसिस', 'लिबरेशन', 'फूडॉन', 'नन्हें', 'भदौरिया', 'जटिला', 'पहुंचनी', 'राष्ट्रोंं', 'ब्लॉसम', 'टंडन', 'गड़बड़बड़ी', 'संस्थिता', 'यात्राएं', 'आदान', 'जावते', 'नियुत्तियों', 'भीष्म', 'हंडिया', 'मुर्गीपालन', 'मालेकर', 'लवलैंड', 'मावे', 'विक्रम', 'हांफते', 'बैरकपुर', 'ग़ाज़ियाबाद', 'तर्कों', 'एसपीएफ', 'आर्टेमिस', 'ऐप्प', 'जयबाण', 'गैरइरादतन', 'विवेकाधीन', 'सबजूनियर', 'फालिया', 'प्रेक्षकगणों', 'पुरवासियों', 'विपन्नता', 'मांगा', 'ऑर्डनेंस', 'प्रधान', 'अभियुक्तोंके', 'विराटखंड', 'हिजबुल', 'विद्याओं', 'मंजू', 'छविंद्र', 'छुपकर', 'डोरंडा', 'सायं', 'मिठाइयाँ', 'जीवविज्ञानियों', 'पश्तून', 'ब्रह्राचारिणी', 'यरूशलेम', 'एल्टामोंटे', 'सिहुंता', 'हेमवती', 'कोषाधिकारी', 'आशंका', 'बीन', 'वैज्ञानिकता', 'झीलों', 'रोबर्तो', 'श्रीरामपुर', 'मंचीय', 'वसूलता', 'मोरीसन', 'महाग्रंथ', 'ट्रांजिस्टर', 'सर्वजातीय', 'पाटोत्सव', 'हाॅकी', 'मेडिथ्सन', 'उड़ाना', 'सरायमोहिउद्दीनपुर', 'पीटर्सबर्ग', 'रंजकता', 'दीया', 'माेहिंदर', 'मस्टेक', 'निर्बाध', 'एहसास', 'आवृत्तियों', 'एशियवन', 'थकी', 'टरबाइन', 'दिमाक', 'जोधपुर', 'दरदरा', 'ख़ासतौर', 'मकरानी', 'हाई', 'फटही', 'मारिया', 'गॉंव', 'पेंडुलम', 'आविष्कार', 'नतीजेः', 'जेफरसनविल', 'ब्रह्मसिद्धि', 'तुलसीदास', 'रीता', 'चर्चामंच', 'प्रतिकारा', 'तर्कवाद', 'दबंगों', 'हिचकिचा', 'शीर्षकों', 'डम', 'द्विअर्थी', 'जवाबः', 'बहुमान', 'जांचकर्ता', 'वन्देमातरम्', 'शुड', 'अगस्ता', 'एनईयू', 'दस्तखतशुदा', 'सूरीनाम', 'किंगखान', 'तरस', 'रिकनेक्टिंग', 'फाइब्रिक', 'क्लेयर', 'छीजत', 'मोमिनटोला', 'विरोध', 'अरेना', 'यूनियनवादी', 'बम्लेश्वरी', 'बोका', 'इम्मैच्योरिटी', 'संसथान', 'जीन', 'ददरेवा', 'कीड़े', 'करावणौ', 'पुतिन', 'टंकार', 'खटकती', 'जड़', 'पुष्प', 'जीएम', 'युसूगी', 'कोरोला', 'प्यादे', 'करवायेगी', 'बलात्कारियों', 'जताती', 'गुरदासपुर', 'श्रेष्ठस्वरूप', 'शुभप्रभा', 'यूरोप्लास्ट', 'राष्ट्रभक्तों', 'कैंटरबरी', 'कम्युनिकेटर्स', 'महामंच', 'कॉन्वे', 'डीडब्ल्यूएफ', 'रीव्स', 'डभोई', 'भूतल', 'इंसानो', 'एमिल', 'विज्ञानम', 'सपाटे', 'अटवाल', 'हिंडन', 'ऑफिसरी', 'मोंटक्लेयर', 'पुर्नस्वीकृत', 'रिचर्डसन', 'संदर्भ', 'फार्गो', 'अलीम', 'सप्तक्रांति', 'एचआर', 'इमानदारी', 'कॉन्ट्रेक्टिंग', 'गंगाजल', 'गौर', 'अधिकरियों', 'बंधान', 'सेंधा', 'डब्ल्यूपीडी', 'ग्रविटा', 'लिंगकन', 'प्रवृत्तिविज्ञानों', 'सीमेंटेशन', 'बगड़', 'जेन्ट्री', 'डैटसन', 'मोंटेबेल्लो', 'रिन्यूएबल्स', 'नक्सलवाद', 'ऐतराज़', 'इतिभगवती', 'निवेशकर्ता', 'पटकथाएं', 'काबिलेतारीफ', 'भादस', 'भोगते', 'होल्डिंग', 'धत्ता', 'धोरों', 'उपाख्यानों', 'फयेत्तेविल्ले', 'स्टॉकटन', 'ब्रजेश', 'प्रतिज्ञा', 'बढ़ाती', 'थेन', 'थॉमस', 'ध्येयवादी', 'ट्यूजडे', 'डब्ल्यूजीपीएल', 'ओवम', 'गति', 'न्यूक्लियस', 'क़रार', 'पुरूषोत्तमाचार्य', 'मनचंदा', 'लहसुन', 'नक़ाब', 'सूजा', 'मैकेंज़ी', 'पुर्जों', 'बहुंत', 'ब्रावो', 'अमानत', 'झुठला', 'बुश', 'चौखटे', 'अपर', 'एस्थेटिक', 'क्षेत्रद्वारा', 'सज्जा', 'ढहाने', 'नारियलयुक्त', 'जूलूस', 'कुर्सियॉ', 'सिंघाड़े', 'एमी', 'अंतर्मुख', 'ठक्कर', 'बड़बोलेपन', 'नक्सलियों', 'मैनर', 'हिमाली', 'नक्सलवाद', 'हॉफ', 'महाधर्माध्यक्ष', 'परमौजूद', 'टिप्पणीकार', 'पेरेल्स', 'भपाई', 'बीताने', 'वाल्व', 'द्विरुक्त', 'एड्डी', 'जीवनियां', 'पंघाल', 'खंडा', 'उर्वरकों', 'बेसिन', 'गिरिवासियों', 'पराधीन', 'पुख़्ता', 'अछनेरा', 'कार्सन', 'डेल्टा', 'त्रिपुरा', 'अलयमनी', 'खेड़ा', 'नाहरगढ', 'शालीमार', 'इम्मैच्योरिटी', 'एलएंडटी', 'प्रॉपरफेसबुक', 'उड़ानों', 'महाजन', 'मोसेस', 'बतायाकि', 'अली', 'इलेक्ट्रोमीटर', 'आमोद', 'रूकेंगे', 'मारिया', 'रागों', 'आइपीएफ', 'फलितार्थ', 'सुपाच्य', 'अवशिष्ट', 'ईष्ट', 'रेट', 'आटा', 'महलों', 'वरिष्ठों', 'जलपोत', 'कैटरीना', 'जिस्मफरोशी', 'सैलरी', 'रज़ा', 'रैकेटियर', 'बेसिल', 'बढ़ाता', 'चरणबद्घ', 'भड़काया', 'साहित्योत्सव', 'नरसीपुरा', 'समझूंगा', 'चंद्रपुर', 'सरका', 'ढाह', 'प्रौढ', 'अहितकारी', 'डरावनी', 'बेलिंडा', 'अलयमनी', 'डैटसन', 'अते', 'फास्नर्स', 'बंगरावाला', 'सायरा', 'अट्टहास', 'निर्दल', 'महबूबनगर', 'डराते', 'वल्कन', 'ख़ासतौर', 'बरसाई', 'आनंददायक', 'बांबी', 'तो', 'असमान्य', 'विपन्नता', 'स्पस्ट', 'अमझेरा', 'बेचकर', 'घटबढ़', 'कौशलता', 'मशीन', 'वायरलेस', 'फैंन', 'गानो', 'खंभात', 'क्यूआईपीएस', 'डबलिन', 'एमटीए', 'समृद्धियों', 'राधाकृष्णदास', 'कांस्टिंग', 'इड्डुक्कि', 'इंडस्ट्रियल', 'भारतवंशी', 'मांगी', 'रॉबिंस', 'व्लादिमीर', 'पेहोवा', 'बाग', 'उम्मीदवारी', 'साफगोई', 'कूत्ता', 'एडेन', 'ग्रेनाइट', 'उस्तरा', 'ढूंढता', 'संघीयता', 'कुमारी', 'डिप्थीरिया', 'अड़चने', 'कोरियाः', 'प्रपात', 'छुड़वाया', 'सूइयां', 'वेरोनिका', 'स्कैफलर', 'ज़यादा', 'पॉटर', 'मीडिया', 'यरूशलेम', 'पिछड़े', 'लेटसेंग', 'अर्थव्यवस्थताओं', 'काकू', 'निर्देशिका', 'सेटो', 'नवाते', 'संवेदन्शीलता', 'रोडरेज', 'छहों', 'लफ्ज', 'वंशवाद', 'रोहतक', 'अटकता', 'बावरा', 'कृबरभ', 'प्रकाशकः', 'स्टायरोल्यूशन', 'अपारदर्शी', 'बेंगलुरु', 'अंधापन', 'मैनन', 'क्याः', 'फार्मूले', 'हमलावर', 'अमावस्या', 'पूर्वापेक्षाओं', 'डैशवाला', 'ओकलाहोमा', 'डारमैट', 'सहकलाकार', 'फातमा', 'खलती', 'दायित्व', 'क्यूसैक्स', 'टोलकर्मी', 'वर्शन', 'परिसंवाद', 'इम्युन', 'बचती', 'यूटिलिटीज', 'मलमास', 'कैडमियम', 'एन्टीओक', 'खातेदार', 'मोहिनी', 'विश्वसनीयता', 'रहमान', 'कंबलों', 'आर्यिका', 'मैरेज', 'छींक', 'फलता', 'बागोरा', 'पकौड़े', 'लूसी', 'फतेहगढ़', 'ग्रहणकाल', 'जॉब्स', 'सदानंद', 'दत्त', 'मुर्गीपालन', 'लुढ़कते', 'पल्मोनरी', 'डब्ल्यूआईएन', 'उभारा', 'बेक', 'पडरौना', 'बांधते', 'कपूर', 'सेवाला', 'वर्शन', 'चिढ़ते', 'थाणे', 'निकलेगी', 'मोगली', 'ड्रेजर', 'नागारिक', 'गाजीपुर', 'वादक', 'मिचेल', 'ज्ञातव्य', 'स्तनधारी', 'धोराजी', 'अब्दुन्नासिर', 'विश्ववंद्या', 'सत्यार्थप्रकाश', 'शिवमोगा', 'घुमक्कड़ी', 'गाएं', 'ची', 'थिएटरों', 'अनाधिकारिक', 'शासक', 'हाइंस', 'बेतिया', 'धटना', 'रहमत', 'मोतिहारी', 'पियरसन', 'उज़्बेक', 'व्हीलिंग', 'पाइथागोरस', 'विप्रो', 'काबिलेतारीफ', 'जमाती', 'पुलम', 'दौबारा', 'पोर्टिलो', 'अधीक', 'धुम्रपान', 'दांपत्य', 'जामुड़िया', 'पेडू', 'पिपरा', 'ब्लेयर', 'कम्यूनिकेशन्स', 'अलायंस', 'अरदास', 'गुदना', 'जस्ट', 'आवाज़ों', 'बेंवर', 'अमारिलो', 'ब्रह्माण्ड़', 'दिखार्इ', 'तंत्रों', 'आसान', 'तुगलकाबाद', 'सट्टन', 'कंदरौर', 'खन्ना', 'निकालनी', 'डिबनू', 'इम्मैच्योरिटी', 'तोलासन', 'जानाकरी', 'लिवाल', 'एंजेलिन', 'ऋषिता', 'फ्लिंट', 'वृश्चिकःसप्ताह', 'आसमती', 'गिरकर', 'वैज्ञानिक', 'बिशड़ी', 'फूलती', 'पुनःस्थापना', 'बाध', 'गंध', 'चक्षु', 'मिकटॉम', 'लीडरों', 'ज़बर्दस्त', 'स्तुति', 'औरतो', 'हेब्लिकर', 'रट्टेबाजी', 'फ्रांसिस्का', 'बंबा', 'प्रतियुक्ति', 'डराती', 'प्राणों', 'मेडिसन', 'निभाएगी', 'मयर्स', 'कश्यप', 'ब्रिगेडियर', 'अम्बिकाओं', 'होगाः', 'इशाक', 'सुमि', 'देशभक्तिमय', 'धर्मपत्रियां', 'कृष्णानगर', 'ईए', 'आयुधनिर्माणी', 'ताजा', 'अजस्र', 'फिजूलखर्ची', 'मंत्रयों', 'तांता', 'डीलरशिप', 'चैपल', 'ध्वनिमिकों', 'एजुकेशन', 'जरख', 'नीट', 'जिलावासियों', 'संप्रभुता', 'कसेगा', 'पकानेवाला', 'दीपन', 'कलसाना', 'मुगालता', 'टोकने', 'फलीभूत', 'ग्योंठ', 'दिखार्इ', 'शामजीभाई', 'पहनाकर', 'किसानी', 'उधारदाताओं', 'रामटेक', 'व्याख्यात्मकता', 'साेमवार', 'विस्टा', 'पॉलिमर', 'रक्ताभ', 'भुगता', 'भ्रष्टाचारीयों', 'खटकती', 'मुख्यमन्त्रियों', 'मैड', 'कक्षांग', 'जैन', 'महीन', 'सुर्वणा', 'बांगरोटिया', 'रसायनिक', 'औरोरा', 'चमचागिरी', 'एनसीआरडब्ल्यूसी', 'ऐंठे', 'एस्सेल', 'देशसेवा', 'इलेक्ट्रोटेक्स', 'वर्कचार्ज', 'कार्वाई', 'झांकता', 'अर्जेंट', 'सप्रमाण', 'मौर्यों', 'जिनी', 'जगदीशचंद्र', 'असुरक्षित', 'काव्योक्तियां', 'अलंकार', 'स्वादप्रेमियों', 'जातक', 'रोलर्स', 'अशक्तता', 'काठियावड़ी', 'आवृत्ति', 'विद्याएं', 'विधिवत', 'राधे', 'मुख्यमंत्रीसंवाददाता', 'प्राणसंगली', 'कनलोग', 'पुदुकोट्टई', 'निकी', 'फूहड़ता', 'पटाक्षेप', 'रीट्वीट', 'मनोवैज्ञानियों', 'स्तनधारी', 'मुखोपाध्याय', 'निर्बाध', 'तोडऩे', 'आवृत्ति', 'परीक्षणकर्ताओं', 'एक्सटेक्टर', 'नाशिक', 'रसायनों', 'वैत्रवती', 'ऑग्रेनाइज', 'चौसिंगा', 'फलोदी', 'स्खलन', 'पनामा', 'निगर', 'मोंटे', 'सुनीति', 'शराबों', 'अम्बिकाओं', 'गुजारा', 'फोटोफ्रेम', 'प्रहलाद', 'बीसवां', 'द्विवेदी', 'देनेवाली', 'बर्ल्सन', 'भारद्वाज', 'जताती', 'मालेगांव', 'रहुगाँ', 'महामंत्र', 'बीस्ट', 'दिव्यता', 'संजीवन', 'कुपोषित', 'एक्सक्लेशन', 'चढ़ेगा', 'टेक्सरकाना', 'डूंगरपुर', 'सराही', 'लालपरी', 'एरोनॉटिक्स', 'वर्थ', 'आस्तीन', 'स्वप्निका', 'उपकार्यालयों', 'मिमिक्री', 'बल्लभ', 'वैरीफ़िकेशन', 'हैकेंसैक', 'आकाश', 'बोना', 'क्लाक', 'द़फन', 'पेगव', 'कहलाया', 'माड़ीखेड़ा', 'तेलीबाग', 'धारक', 'निकालनी', 'कंघे', 'प्रश्नोत्तरी', 'काकीनाड़ा', 'भाग्योदय', 'सिंगार', 'मचाए', 'लेखकगणों', 'उछालने', 'धर्मराजने', 'ऐंजल', 'बंटता', 'फाॅर्म', 'रवैल', 'हनुमानगढ़', 'वीरांगनाओं', 'गायत्री', 'वेंकटरमन', 'डिबनू', 'पुरूषोत्तमाचार्य', 'संयोजकों', 'झाउगंज', 'सरकारें', 'न्यूटेस्ट', 'श्रीकर', 'मिटाओ', 'दियोटसिद्ध', 'भूपसिंह', 'चर्चाएँ', 'प्रसारकों', 'निष्पाप', 'फ्लिन', 'रणनीतिबना', 'ईआरजी', 'धागा', 'गौमुख', 'जूड', 'खनिकर्म', 'शरभ', 'अरेलानो', 'उखड़कर', 'लेनेवाली', 'कुमार', 'सिंघाड़े', 'टोंसिल', 'दविन्दरपाल', 'सिंगार', 'खिसकते', 'एनिड', 'मेगापिक्सल', 'दिग्विजय', 'फजलों', 'दोगे', 'लेबलों', 'मुनाफा', 'बड़ने', 'वैरी', 'सातसेरा', 'ओर्टेगा', 'रोवे', 'भाटिया', 'राजस्थानवासियों', 'बागबगीचों', 'विल्किंसन', 'डराती', 'अटके', 'प्रमुखतापूर्वक', 'यत्न', 'नितिन', 'सिटी', 'रेडिको', 'दुकानों', 'जलसंसाधन', 'मत्स्येंद्रनाथ', 'बिहार', 'बर्षीय', 'अवरु', 'दाव', 'नक़ाब', 'सारेगामा', 'हुगली', 'सत्ती', 'नेग', 'महाबलेश्वर', 'प्लेसेंटिया', 'वर्साचे', 'कुमाऊ', 'एमी', 'थियेटर्स', 'एरिका', 'खिंचकर', 'रौबदार', 'ऑल्टो', 'काव्यविधाओं', 'कून', 'अक्रोन', 'तहखाना', 'समाजजनों', 'मचाए', 'सूर्यदेव', 'प्राथमिक', 'प्रवृत्रियों', 'ताजा', 'जीवनशैली', 'रक्तदाताओं', 'बालेश्वर', 'भौतिकवादियों', 'लगातीं', 'झाइयां', 'वंशवाद', 'नवानगर', 'नजरंदाज', 'अंशांकन', 'फुंकने', 'मतपत्रों', 'मॉड्यूल', 'फार्म्स', 'पहुंचोगी', 'मैडी', 'थीफ', 'फाउडलर', 'अमित', 'पूर्वाभाद्रपद', 'लंगड़ा', 'गोंपो', 'वेस्ले', 'शाओ', 'हामिदन', 'वीक्स', 'मिनरल', 'सेंटेंनियल', 'बस्तियो', 'बागबगीचों', 'प्रनीत', 'भेदभावों', 'कराहना', 'ग्रीनविल', 'सहरावत', 'रालोद', 'जातकों', 'रिश्ते', 'बेंटनविल', 'नजीबाबाद', 'फाइनेंसर्स', 'फटही', 'केरला', 'लड़ाईयों', 'हरिजन', 'वाईटेकर', 'विदिशा', 'पॉल', 'आर्यों', 'खिलाना', 'छूटने', 'दुखियों', 'पूर्णेश्वरी', 'विसबल', 'दरम्यानी', 'यारी', 'विधमान', 'यात्राएं', 'सनटेक', 'गुजारता', 'नियंता', 'डम', 'अवस्थी', 'पल्स', 'भें', 'स्टॉप्स', 'धकेलते', 'केपीओ', 'दमघोंटू', 'इंसानो', 'मैरेज', 'एस्फाल्ट', 'लॉन्ड्री', 'रत्नाभूषण', 'स्की', 'दुश्वारियों', 'अनुप्रयोगों', 'देशसेवा', 'लेलऽ', 'जगारागल्लू', 'मेजबानी', 'डेहरी', 'चक्कर', 'क्रोफोर्ड', 'गुदुरी', 'डीवीसी', 'प्रक्रियागत', 'नग', 'मत्स्यावतार', 'स्कूटरों', 'अर्धविश्वास', 'दरम्यानी', 'सुर्वणा', 'स्थितियां', 'धर्मानंद', 'सॉफ़्नर', 'स्क्वैश', 'विधानसभाएं', 'रैंडोल्फ', 'मेज़बान', 'स्प्रिट', 'शीलभंग', 'कलमें', 'स्वर्णिका', 'मंडी', 'अर्थव्यवस्थताओं', 'कुंडलियाँ', 'नीमकाथाना', 'फाॅर्म', 'हत्यारोपित', 'पुट्टा', 'फारेंसिस', 'पुरूषोत्तमाचार्य', 'बॉंन्ड्स', 'शिकायतकर्ता', 'क्रान्फ्रेंसिंग', 'उबाल', 'बाबाओ', 'हलमतपुरा', 'हकीकत', 'बर्मन', 'वर्तमान', 'बांटीं', 'अचंभा', 'जीवनपर्यंत', 'वदरा', 'सडक़ें', 'एेसा', 'ज्योतिष्यशास्त्रों', 'पाइथागोरस', 'एंजेलिन', 'कपोलकल्पना', 'द्रोपदियों', 'रोजलिन', 'श्रीराम', 'गोपालक', 'बंगबंधु', 'मिस्त्रियां', 'उसेे', 'मर्काडो', 'मैसोर', 'ऑफशोर', 'कपूरथला', 'साहोवालिया', 'मलदहिया', 'हाइमन', 'इंदौरनगर', 'विशेषज्ञताओं', 'उसकी', 'कैपलिन', 'महाप्राण', 'रुपेश', 'रिनो', 'सुदीप्तों', 'स्वामी', 'अमारा', 'व्यवस्थामूलक', 'सेंसिंग', 'टाइलर', 'संगारेड्डी', 'पहनो', 'मरदानी', 'बम्लेश्वरी', 'दिवानी', 'फिनकॉर्प', 'नवा', 'शिमट', 'सोहावल', 'बनाम', 'प्रवृत्रियों', 'शियोंग', 'वर्स्टेड', 'राजों', 'चीखना', 'नैमुल', 'बढ़ोतरी', 'एंटोनी', 'छांयसा', 'निर्देशिका', 'निपटारा', 'जुडने', 'सुझाती', 'पैथेलॉजिस्ट', 'टाइड', 'शृंगार', 'ब्रान्डेस', 'परमेश्वरपुर', 'जेडटीईसाफ्ट', 'उद्धाटन', 'स्टैन', 'आदिवादियों', 'जुलाहों', 'महाराजा', 'गतिशीलता', 'शिप्रा', 'ट्रिब्युनल', 'ख़ैबर', 'वनविभाग', 'घटाटोप', 'धर्मग्रंथों', 'प्रवृत्तीयों', 'गांठ', 'मैसोर', 'सहगल', 'नमकीन', 'वैध्', 'वनस्पतियाँ', 'जियांगकोऊ', 'पाखंडी', 'प्रोटेक्ट्स', 'एल्बाइनो', 'लिंडेन', 'सोहावल', 'भुरभुरा', 'गैस्ट्रोलॉजी', 'विद्रूप', 'साजसज्जा', 'रात्रिचर', 'रोजना', 'जलभराव', 'मोंटगोमरी', 'सेव', 'भ्रष्ट्राचारियों', 'डीडब्ल्यूएन', 'स्ट्रेशन', 'गांठे', 'गहलोत', 'छतेनी', 'विश्वसनीय', 'जीवनियां', 'दस्तानें', 'धोना', 'खरुवार', 'सूरीनाम', 'मंगलसिंह', 'अन्योन्याश्रितता', 'नाइनटीज', 'पांचोलास', 'रेसों', 'वातानुकूलितों', 'चतुष्कोणीय', 'आमदी', 'दुष्टतापूर्वक', 'बेचते', 'चौका', 'मिज़ोरम', 'टोरेंस', 'अनुचित', 'अवरोधक', 'रॉस', 'अच्युत', 'ऊधामी', 'हरावल', 'गोल्ड', 'दाव', 'सृजनविज्ञानी', 'नेक्स्टजेन', 'रूकावटों', 'भावनाओं', 'देहधारी', 'परीक्षाएं', 'उतने', 'संस्कृतिओं', 'प्रॉस्पेक्स', 'नईदिल्ली', 'सायं', 'जिनीवा', 'रसद', 'बारामुला', 'वन्देमातरम्', 'सफारी', 'चम्बा', 'सवाल', 'बन्नारी', 'फ़तेहपुर', 'पहनता', 'स्प्रे', 'नॉर्मल', 'ऑलआउट', 'मनासस', 'मंत्रियोंके', 'कार्यकार्यकर्ताओं', 'फाडऩे', 'ग्रेग', 'बैतूल', 'कुषाण', 'सुब्बनी', 'इन्फिबीम', 'खटखटाकर', 'चाचाजी', 'चंद्रबली', 'बारिपदा', 'रूहेलखंड', 'ग़ैरकानूनी', 'आरेखः', 'प्रमुखकर्मियों', 'ली', 'थियेटर्स', 'असम', 'फानों', 'ज़्यादा', 'थियेटरों', 'सफाईकर्मी', 'बीएसएसएस', 'क्रान्फ्रेंसिंग', 'जीवराज', 'थिरके', 'शकसुबहे', 'पैराट्रूपर', 'डभरा', 'उसी', 'निःसंदेह', 'महानतम', 'बांठिया', 'अनम', 'कश्मीर', 'बावडी', 'भुट्टो', 'मारके', 'कार्ययोजना', 'फ्रांसिस्को', 'अदाणी', 'धुरिया', 'महाविद्या', 'मेगापिक्सल', 'क्रिप्टोकरेंसियों', 'मूठ', 'ऑथोरिटी', 'अपरिवर्तनशील', 'प्रधानमंत्रीकी', 'आगाशे', 'नवजागरण', 'अट्टरा', 'उबाला', 'अमानती', 'खम्मम', 'हारना', 'भावाभिव्यक्तियों', 'पुष्कर', 'शांतियों', 'नेरोलेक', 'चौका', 'सिद्दालिंगा', 'भरतनाट्यम्', 'जवाबः', 'दुश्वारियों', 'मंचीय', 'जीयो', 'सप्रमाण', 'सीम', 'पीएचडब्ल्यूसीएस', 'बहाव', 'टिक', 'अगवाई', 'हाइमन', 'क्यूआईडब्ल्यूआई', 'अज्ञात', 'एजेंडे', 'लिंचबर्ग', 'मांगीना', 'खटखटाएगी', 'जोधिका', 'सृजनविज्ञानी', 'डेटसन', 'बदलवा', 'उर्फ', 'छापेमार', 'लक्स', 'भोपाल', 'फलीभूत', 'पैथेलॉजिस्ट', 'पर्याप्तता', 'फूर्ति', 'मृत्युनिवारक', 'मारुति', 'उठाकर', 'एएलओ', 'पेगव', 'पीलीभीत', 'सोमी', 'संचालनों', 'कांचीपुरम', 'डराती', 'याद्दाश्त', 'साबुदाना', 'वेल्डिंग', 'वेरोनिका', 'स्टिम्बेरवाला', 'मायाजाल', 'पेस', 'अतुल', 'औटोमैटिकली', 'जांचना', 'मिथिलांचल', 'फिक्सिंगः', 'सजेती', 'प्लानो', 'विसंगतिया', 'खोमचे', 'लगना', 'मुकेश्वरी', 'तस्वारों', 'देव', 'वेश', 'ज्योथी', 'लेंडल', 'वीरांगनाओं', 'यनित', 'पूर्णिया', 'चौक', 'लड़ीं', 'चेस्ट', 'कसेगा', 'एबट', 'रेनुका', 'लूवे', 'गुलाबाग', 'लज्जालु', 'साभार', 'गैरराष्ट्रवादी', 'धावकों', 'लिम', 'विद्याएं', 'स्वयंस्वीकृत', 'इलेक्ट्रोटेक्स', 'रामराज', 'जनभावना', 'यौनिकता', 'हाथे', 'दूने', 'प्रोटेक्ट्स', 'वरेण्य', 'मज़बूरी', 'प्रवीनचंद', 'वैज्ञानिक', 'टोरेंट', 'आत्माएं', 'संप्रति', 'मत्थे', 'सविता', 'अटलांटिक', 'जलगति', 'चच्चा', 'आफरीन', 'बाजारू', 'चौकी', 'फरसे', 'ट्यूनिंग', 'नोडरानी', 'मौम', 'विधाणी', 'गुजार', 'पकडकर', 'ऑंखें', 'आपका', 'वार्नर', 'अन्वाहार्य', 'लिखेहैं', 'पाठ्यक्रम', 'शावकों', 'यरूशलेम', 'मण्डलायुक्तो', 'नैनो', 'झाइयां', 'सिम्फरपोल', 'धम्म', 'निखरेगा', 'घुमाण', 'होऊंगा', 'ढकाल', 'सागरिका', 'बर्नार्ड', 'योगबल', 'ब्रेवरीज', 'डिश', 'ऐठन', 'वर्तमान', 'त्रैमासिक', 'तस्वीरे', 'व्यवहारगत', 'मराठा', 'बनवा', 'स्वर्णिका', 'प्रसाथ', 'ओवरऑल', 'पूर्वाफाल्गुनी', 'प्रॉपरफेसबुक', 'सुवेन', 'सपाटे', 'झ', 'करघे', 'देशकाल', 'नाथवाड़ा', 'थानवी', 'ओरण', 'सेरानो', 'इअर', 'सबमिशन', 'धारक', 'तदाद', 'ग्रीनवुड', 'हाउते', 'बहुरिया', 'नियंताओं', 'चूरू', 'मिसौरी', 'अन्याय', 'जेनरेट', 'न्यूटेस्ट', 'गरुड़', 'स्वास्तिकाकार', 'शैइ', 'सिद्धांतवादियों', 'अनावश्यक', 'सीटें', 'गुलशन', 'रिया', 'फर्मिऑन', 'टायर', 'ची', 'बदलापुर', 'युद्धनौका', 'एनबीसीसी', 'श्रीगंगानगरवासियों', 'उदा', 'कैंब्रिज', 'एयरवे', 'आइडल', 'कैल्यूमेट', 'आजमाना', 'तंत्रिकाओं', 'जोन्सबोरो', 'बुद्धिजीवों', 'क्लोज़अप', 'एनएमडीसी', 'राष्ट्रपित', 'कमारहाटी', 'एस्फाल्ट', 'फ्रांसिस्को', 'भल्ला', 'मौलवियों', 'नरवर', 'लहलहाती', 'ब्यावर', 'घटाएगी', 'नामजदगी', 'तकः', 'सेवाग्राम', 'लामियां', 'जिन', 'स्वेच्छा', 'अंतडियां', 'आर्यो', 'पॉलिशिंग', 'जोखिमभरा', 'उमड़ती', 'तंत्र', 'सामोआ', 'सीएसआई', 'मांड्या', 'लॉरी', 'पहनते', 'अंकोर', 'निम्नवत्', 'रैपिंग', 'रुपेश', 'प्रतिबद्धाता', 'नाडेप', 'सैलानीपन', 'मेंराज्य', 'दाव', 'आबूरोड', 'पाठ्यक्रमों', 'निविदाताओं', 'गांधीपुरा', 'पीएचडब्ल्यूसीएस', 'नारायणगढ़', 'जयललिता', 'सुसंस्कृत', 'मसूद', 'वुनसोकेट', 'संस्कृतियां', 'उर्फ', 'थेराटीपल्ली', 'प्रतिनिर्देश', 'उल्हासपुर', 'पहनते', 'धावकों', 'भगेड़', 'प्राणसंगली', 'जलवायु', 'भिजवाई', 'सायरा', 'क्रेन्द्रों', 'मौजुद', 'सिद्घांत', 'कम्युनिकेटर्स', 'चिड़चिड़ापन', 'मुथूट', 'विवेकाधिकारों', 'मलौन', 'सिनसिनाटी', 'रेगिस्तान', 'परोसने', 'विचारकों', 'जनभावना', 'अंडमान', 'बडयाल', 'मोरपेन', 'बियर्ड', 'नोडरानी', 'दिखायेे', 'छींक', 'व्याख्यात्मकता', 'शैशव', 'आइंथू', 'अहमदाबादः', 'जायके', 'सिग्निटी', 'कुरुक्षेत्र', 'प्रवृत्तीयों', 'चर्चा', 'लक्ष्मीचन्द्र', 'हैमंड', 'निभाएगी', 'धुनाई', 'जनभावना', 'कांट', 'मेलघाट', 'मुऐ', 'श्विंग', 'दांपत्य', 'कपड़ा', 'संतति', 'मानवटरहित', 'अनुप्रयोगों', 'हार्वे', 'काजू', 'सेररितोस', 'टेक्समैको', 'संचार', 'ट्रुथ', 'लोज़ानों', 'रोपने', 'हॉलीवुड', 'छींके', 'धम्मा', 'टेक्नोप्लास्ट', 'पूजापाठ', 'चानन', 'श्रंखलाओं', 'छेड़ना', 'कार्बोजेन', 'व्यवधान', 'शुल्ट्ज', 'इस्त्राइलियों', 'स्क्वाश', 'डैनविल', 'प्राना', 'ठाकुरवादी', 'प्रयोगशास्त्र', 'व्यक्तीयों', 'मैट्रोलॉजिस्ट', 'मढ़ौरा', 'पालियों', 'डेनवर', 'एपीजे', 'बैनी', 'प्रतिस्थान', 'भ्रष्टाचारीयों', 'लकीर', 'सुधारगृह', 'संदली', 'जागृति', 'तलवार', 'जनशिक्षा', 'टापुओं', 'बुलेटिन', 'बल्लेबाज़ी', 'माड़ीखेड़ा', 'अर्थशास्त्रीयों', 'स्कैनिंग', 'मेहमान', 'रहेगी', 'जमशेदपुर', 'त्यौहारों', 'दर्शाना', 'बीचबचाव', 'सुलाती', 'वर्शन', 'सुधारती', 'वसामुक्त', 'पाटिल', 'जेवाब', 'सोटो', 'धातुएं', 'डोसे', 'भागदौड', 'पगबाधा', 'आरुषि', 'अगस्ता', 'टाइटन', 'इक्विटीज', 'एयरटेल', 'ऐल्प्स', 'नक्सली', 'अचीवमेंट', 'गलाएगा', 'फूडॉन', 'राजनीचि', 'आर्य', 'स्ट्रीमवुड', 'घोट', 'म्यूजिक', 'पुरकायस्थ', 'नोरा', 'टॉनिक', 'गुजारने', 'वाटर', 'सूनसान', 'सिरसा', 'टेंगीरला', 'हेनसन', 'वरुण', 'ड्रेजर', 'दौड़ाते', 'शराबों', 'व्यक्तीयों', 'सातसेरा', 'दर्जनों', 'अग्नियां', 'धोना', 'कार्यकर्त्रियों', 'अवस्थाएं', 'हिममानव', 'टु', 'ऐल', 'बंधुओं', 'श्रद्धावानों', 'मारियो', 'व्याघात', 'माईकल', 'अद्र्घ', 'विट्ठल', 'प्रारूप', 'ढूंढती', 'डुबाना', 'लडने', 'फार्म', 'जुवारी', 'परिवारवाले', 'पैरानॉर्मल', 'भुवनेश्वप्रसाद', 'आईरिस', 'प्रतिज्ञापूर्ण', 'लेबलों', 'श्रीकृष्णन', 'स्नीकर्स', 'कईं', 'भूस्वामी', 'कटरा', 'अन्याय', 'नोकरी', 'प्रिसिशन', 'क्रोम', 'जुए', 'बोलिंग', 'ताप्ती', 'कैथोलिकों', 'नजरंदाज', 'मूलचंद', 'स्वेच्छा', 'नन्यौला', 'घोंटना', 'अद्वैतवाद', 'अंडरवुड', 'लुभावना', 'पेट्रोसेली', 'आमदी', 'रोपने', 'डेजी', 'जबाबी', 'कप', 'फाड़े', 'उलाहना', 'उन्नतियों', 'मोलिना', 'गांडचुभोनाचूसनाछोटे', 'हां', 'प्रर्दशन', 'सरगुजा', 'बीदर', 'अमरगढ़', 'जुए', 'टोंक', 'देवापुर', 'इंटेलीजेंस', 'नीतियों', 'खनौदा', 'पोरबंदर', 'सिम', 'लग्नेश', 'गायिकाओ', 'पृष्ठभूमियों', 'मूलचंद', 'सिल्चर', 'मार्गरिटा', 'उदाकिशुनगंज', 'सिरती', 'यमला', 'प्रशिक्षु', 'सिएरा', 'आल्हा', 'पेक', 'तसखीर', 'डाका', 'नॉमिनेट', 'सपाट', 'कोयम्बटूर', 'कोरापुट', 'स्वायत्तशासन', 'विद्युतीकृत', 'किकियाना', 'अरुणाई', 'रीगल', 'डायमंड', 'मृदुभाषी', 'वाल्टर्स', 'सूत्रपाडा', 'कीति', 'ज़िलाधिकारी', 'मंगेश', 'पेंषन', 'लगनेवाले', 'जिलावासियों', 'प्लोस्की', 'एकसाथ', 'सेखर', 'डीओडब्ल्यू', 'अर्धविश्वास', 'राजस्थान', 'विकासखण्ड', 'संशयों', 'बढना', 'क्लासों', 'उखरुल', 'फुरामे', 'एबज', 'बाताया', 'जुशान्तान', 'स्ट्रॉन्ग', 'राजनीतिकारों', 'पानीपत', 'ब्लांकार्ड', 'झाबुआ', 'जकिंटो', 'बारहसिंगा', 'सूचनाः', 'इलेक्ट्रोमैजिक', 'लालमणी', 'भाऊलाल', 'कठुआ', 'पलारी', 'अमिताव', 'तदंरुस्ती', 'वाबस्ता', 'व्लाद', 'स्लैश', 'वाटरबरी', 'सेल्फी', 'लुईस', 'पंचसूत्र', 'अर्यमा', 'वादक', 'जंक्शन', 'जेनरिक', 'जिया', 'एडेन', 'सॉफ़्नर', 'क्यूडब्ल्यूवीजीए', 'ध्वनिमिकों', 'फीड्स', 'सुकडि़याल', 'अनगढ़', 'बावजी', 'छोडिये', 'सिप्ला', 'विज्ञानों', 'धस्माना', 'लोंगोवाल', 'बदाम', 'अट्रैक्ट', 'सराहा', 'नृत्यशैली', 'संवरी', 'यक्षाधिपति', 'अरबपतियों', 'मुकद्दमों', 'फोड़े', 'सिहुंता', 'जीवन', 'ढूंढता', 'क्रुसेस', 'कार्यकर्त्रियों', 'प्रतिबद्धताएं', 'डीएलडब्ल्यू', 'प्लेन', 'पायलट', 'अधिवास', 'फैंन', 'फव्वारा', 'हालचाल', 'विश्ववीर', 'क्रेस्ट', 'ब्रह्मलीन', 'विरेचन', 'याद्दाश्त', 'उज्जैन', 'सहयात्री', 'जिम्मे', 'सारावागी', 'देखियेगा', 'वजूद', 'कुंडल', 'रिया', 'स्लाइडर', 'मैनेजमेंट', 'कार्यकार्यकर्ताओं', 'क्रिस्टिस', 'रुकते', 'डिस्ट्रब्यूटर्स', 'स्पेल', 'दमपर', 'ठिकाने', 'इंटरटेक्चुअलिटी', 'सीडीयां', 'साउथ', 'आपका', 'नहींकरवाई', 'जागृति', 'चूड़े', 'थर्टी', 'नक्सल', 'जीएसएम', 'गुजरात', 'दर्शनार्थी', 'नाभा', 'धोखेबाज', 'लेगा', 'बीआईआईटीएम', 'साेमवार', 'वाणों', 'औद्योगिकरण', 'अग्रहरि', 'आफॅ', 'तीमारदारों', 'मिश्रा', 'सेरेब्रा', 'नागारिक', 'दस्तार', 'मकरः', 'जीतोड़', 'बैलिस्टिक', 'चढ़ेगा', 'मांगे', 'नीलाभ', 'मेंशराब', 'सिंघाड़े', 'हिसारः', 'रामकोट', 'बैठते', 'तसखीर', 'इशारा', 'सोलापुर', 'मेजबानी', 'फ्लोरेंस', 'परामर्शक', 'झाड़ने', 'थियेटर्स', 'आदान', 'आंबियंस', 'सुरक्षाः', 'हिकारिको', 'बांया', 'रुकवाई', 'मित्रवत', 'बोकारो', 'मौर्या', 'प्रतिनिधिकारी', 'चंद्रमाओं', 'परोसने', 'ढैया', 'स्पिरिट्स', 'लियान्ड्रो', 'शॉन', 'स्वार्थपरक', 'चूचियां', 'महामीडिया', 'पूर्वजन्मों', 'शोहदापंती', 'कुषाण', 'जमलोकी', 'एवरेस्ट', 'तस्वारों', 'अधिवास', 'प्रेमलता', 'मुर्रिएटा', 'वैमनस्य', 'केली', 'टिनप्लेट', 'वाण', 'महामंत्र', 'मेजबान', 'शुमाली', 'फुलाए', 'प्रूट', 'रुजवेल्ट', 'प्रशासनिक', 'उलझानों', 'पत्रकारवार्ता', 'दुआर', 'कठफोड़वे', 'बिपिन', 'ऑफरः', 'ईसाइयों', 'प्रोपेलेंट', 'कंसाई', 'सीखीं', 'सीडीसीएल', 'एबोट', 'कटलरी', 'आदिवादियों', 'चित्रकथा', 'अवशिष्ट', 'फ्यूचुरिस्टिक', 'तेरीः', 'नन्हें', 'एवरी', 'सूबा', 'शाखाएं', 'त्रिकालदर्शी', 'पालसाही', 'फैलाइए', 'झउवा', 'जमाती', 'जनहानि', 'पोंडिंग', 'तस्वारों', 'देशकाल', 'हिचकिचा', 'बस्तीः', 'गरीबी', 'फड़फड़ाएं', 'सीताराम', 'कमेरे', 'बैरकपुर', 'स्वयंस्वीकृत', 'कासोवो', 'मज़बूरी', 'कन्वोकेशन', 'स्किपर', 'जयपुर', 'प्रस्थानों', 'नरम', 'रेडियोप्रेमी', 'टीटागढ़', 'चिको', 'राज्यमंत्रीस्वतंत्र', 'मैनवल', 'गुजारना', 'सतलुज', 'जातियों', 'अनहोनी', 'टेलीलिंक्स', 'लैब्स', 'हरावल', 'मैरेज', 'मनिया', 'ट्रैक्टर्स', 'कंचन', 'लैरी', 'कार्यावधि', 'जलभराव', 'भाड़ा', 'बागोरा', 'पिएगा', 'स्टीफेंस', 'अभिमत', 'एक्सेल्या', 'वायरलेस', 'चौड़ा', 'परभणी', 'खातेदार', 'बढना', 'बर्च', 'उपद्रवों', 'टिकियों', 'मिल्क', 'डुबोना', 'बेकर', 'सुतली', 'बुद्धाराम', 'वेल्थ', 'पटरानी', 'अर्धविश्वास', 'पैम', 'कास्टानेडा', 'बलजीत', 'भटनागर', 'जातकों', 'इक्वाडोर', 'स्वर्गदूत', 'ऋषिकुल', 'टेट', 'कंठहार', 'बेऔलाद', 'यूरोपिया', 'गए', 'ददरेवा', 'बिखेरने', 'हमलो', 'पकड़ाए', 'उपलब्धियों', 'कोलोराडो', 'पैकर्ड', 'जागृति', 'आंध्रा', 'चौंकाते', 'बेख्वाबियां', 'नफ़ा', 'सिन्हा', 'उत्पीडऩ', 'सागा', 'आर्य', 'दिखाइये', 'अनिष्टता', 'उड़ान', 'संयुक्तावस्था', 'शमलात', 'एवव', 'अधिवक्तागण', 'रल्हन', 'झुठलाने', 'पूर्वाभास', 'बिजेन्द्रसिंह', 'चिनमणि', 'लोकसभावाली', 'लड़की', 'नरसिंहगढ़', 'संगठनमंत्रियों', 'रूपी', 'कार्यकर्ताओं', 'अगस्ता', 'मनमर्जी', 'अंतर्मुख', 'अनुमार', 'रिश्तानाता', 'द्विअर्थी', 'चुटीले', 'हैटीज़बर्ग', 'यूजी', 'राज', 'रैगुलाइजेशन', 'विंध्या', 'फिक्सिंगः', 'कमज़ोर', 'भरा', 'चौदहवां', 'फलने', 'श्रंखला', 'विपन्नता', 'प्रूफ़रीड', 'ज़माना', 'घटाएगी', 'दंगा', 'एरिका', 'भोला', 'व्याख्यात्मकता', 'योजनाः', 'वेबुनियादी', 'रुमानी', 'साहू', 'प्रधाननगर', 'सीऐटल', 'स्टैन', 'इनसानी', 'हमला', 'न्यूट्रियो', 'लदड', 'अंतडियां', 'कुशवाहा', 'कोच्चिः', 'गणपति', 'फार्मिक', 'पड़ेंगी', 'अर्थ', 'मुक़र्रर', 'निपटाकर', 'होलिडेस', 'कूच', 'उठ्ठक', 'सुलखान', 'कमेरे', 'जगाएगा', 'संत्री', 'शख्सियतें', 'पंचांग', 'झालाना', 'नित्या', 'इच्छी', 'हाबरा', 'पालियों', 'एजूस्पर्मिया', 'तावीज', 'फ़ूडवर्क्स', 'ग्राहम', 'प्रभानमंत्री', 'सेथ', 'जगताप', 'हर्षित', 'डूबना', 'रक्तदाताओं', 'मेक्सिको', 'तासीर', 'एयरकंडीशनर', 'एड्डी', 'मैकॉन', 'इसरानी', 'ऐंठ', 'श्रीमहापूर्ण', 'डॉर्क', 'जीनों', 'ग़रीबों', 'तराशकर', 'ऑब्जर्वर', 'आर्यो', 'उखड', 'साथसाथ', 'पैकेजों', 'हिंडन', 'अपरिहार्य', 'मंजिल', 'एलएक्स', 'कर्वी', 'दुभाषियों', 'रिकनेक्टिंग', 'विंड', 'क्लांइट', 'शरारत', 'वेंचुरा', 'रोलिंस', 'हैन्स', 'निकेतन', 'क्रांतियों', 'ट्विन', 'दिव्य', 'गिड़गिड़ाते', 'निगमायुक्त', 'गबली', 'नोवाटो', 'रिश्वतखोर', 'फांसी', 'गर्जना', 'निहलानी', 'पिंटा', 'ग्रीर', 'लेविसविल', 'प्रकाषित', 'क्लैरिएंट', 'क़ायल', 'द्विअर्थी', 'राखे', 'बुलंदशहर', 'स्टेफोर्ड', 'नजरियों', 'वर्ल्ड', 'जीवनियां', 'परमेश्वरपुर', 'उठनी', 'न्यूट्रियो', 'जेठा', 'बागबगीचों', 'सुचिकित्सा', 'नागमण्डल', 'प्रदाधिकारियों', 'उर्वरता', 'नील', 'क्रिप्टोकरेंसियों', 'स्वायत्तशासन', 'जर्दा', 'उपलक्ष्य', 'छुड़वाया', 'विदग्धा', 'मुख्यमंत्रीपटना', 'जैने', 'रतनपुर', 'महानतम', 'गुना', 'एमटेक', 'देनेवाली', 'नाभिकुंड', 'विशेषणों', 'लंगरों', 'पॉलिथीनों', 'संबित', 'ढूंढ', 'हां', 'टकरा', 'धंधेखोरी', 'पुलिंदे', 'एपोक्लिप्स', 'विज्ञानपीडिया', 'महोनी', 'पूंजीतंत्र', 'खरे', 'एक्सटेक्टर', 'ज़ुन्हेबोटो', 'प्रियामणि', 'सवाल', 'सूखाकर', 'आलोचक', 'फाँस', 'जयललिता', 'अमझेरा', 'बॉम्बे', 'व्यग्र', 'अपनानी', 'रिसने', 'छुरे', 'शार्लेट', 'जोस', 'रैलीः', 'मेज़बान', 'धनधान्य', 'डाबर', 'बीएसएसएस', 'नजीब', 'अवस्थाएं', 'जबलपुर', 'धर्मनिरपेक्षताके', 'फार्मर', 'एनएसीएल', 'समरविल', 'बुल', 'झुलए', 'खग्यार', 'मेहराम', 'धस्माना', 'रिपन', 'भागदौड़', 'मिथ्या', 'ललानिया', 'भूलों', 'वडाली', 'नागापट्टिनम', 'वैमनस्य', 'बिगेस्ट', 'जोड़ता', 'महत्तरों', 'ओरछा', 'धैर्यवान', 'सूंड़', 'प्रिंस', 'ज़ुबान', 'कैमस्टूडियो', 'यूरोपिया', 'मेज़ा', 'भुसावल', 'गायत्री', 'वेयर', 'बुद्धिजीवों', 'ऐंठ', 'रदर', 'इलाइची', 'उबाल', 'श्रीगंगानगरवासियों', 'फिजराल्ड़', 'जीवनशैली', 'चार्ट', 'सरगी', 'वेदों', 'मरमर', 'भाते', 'विप्ख', 'बयाने', 'मदनगंज', 'पैकेजों', 'वर्णनकर्ताओं', 'ज़यादा', 'लोकोत्सव', 'तेवरी', 'झाउगंज', 'मालवान', 'तदंरुस्ती', 'ऐल', 'क़ब्ज़ा', 'सुसंस्कृत', 'संधोल', 'आमरियापाड़ा', 'हाब्बन', 'बाउलिंग', 'रस्मे', 'एमडब्ल्यूपीएल', 'विद्याओं', 'बोवी', 'चेन्नई', 'कमलजीत', 'सिंहा', 'पेंशनधारियों', 'बारह', 'डूबना', 'एसेटल', 'चौहान', 'फलने', 'सिद्धार्थः', 'एपेक्स', 'डाल्टन', 'श्रीखंड', 'टेक्सटाइल्स', 'अग्रवाल', 'मिथ्याचारियों', 'सिमटे', 'क्रान्फ्रेंसिंग', 'संस्कृतियों', 'ढंककर', 'निज़ामाबाद', 'छतेनी', 'दुष्क्रिया', 'सासाराम', 'चिढ़ते', 'लाम्बा', 'लउटिस', 'खाएँ', 'धंधे', 'अन्त्यन्त', 'मास', 'बरामद', 'क्रेमिस्ट्री', 'उठनेवाले', 'लहना', 'सिरगिट्टी', 'कंट्रोल', 'अंदाजी', 'कैटलिन', 'पक्षपात', 'फोड़ों', 'फ्रांसिस्का', 'प्रयोगपृष्ठ', 'क्रांतिधरा', 'डैशवाला', 'खुरासान', 'क्वॉरेनटाइन', 'फोंड', 'पक्षपात', 'पुतला', 'ट्रुथ', 'साथसाथ', 'मोहिम', 'जॉनसन', 'सीपीएम', 'बाताया', 'पाल्मर', 'तुगलकाबाद', 'एपकोटेक्स', 'हैरम', 'सरेबाजार', 'येरुशलम', 'मोल्ड', 'वर्णनकर्ताओं', 'हूपर', 'वाटर्स', 'लुभाते', 'फेफड़ा', 'कामोत्तेजना', 'दंपति', 'सोया', 'बर्बरतापूर्ण', 'तड़ीपार', 'लुत्फ', 'तरीको', 'चता', 'पिटमैन', 'पहला', 'मल्टीमीडिया', 'त्यौहार', 'लेबल', 'ले', 'तीर्थाटन', 'सतुआ', 'वर्गस', 'डाबोलिम', 'सूचनाः', 'लेबलिंग', 'रोज़विल', 'फ़ाईब्रेट्स', 'ऑल्टो', 'परतानी', 'अस्मिताओं', 'वांट', 'तड़पती', 'पटेल', 'काजी', 'दोस्तानापूर्ण', 'क्षेत्राें', 'लिंच', 'स्टेट', 'रागों', 'मल्होत्रा', 'प्रज्ञातंत्र', 'दुर्नीति', 'क्रॉस', 'अव्यवसायी', 'धैर्यवान', 'टाइम', 'अशरीरी', 'चन्द्रदास', 'ज्योतिषि', 'एलेक्जेंड्रिया', 'बेवकूफाना', 'सिरपुर', 'उज़्बेक', 'खरुवार', 'धर्मविहीनता', 'सुरेंद्रनगर', 'आल्हा', 'अरुणाचल', 'क्रुएगर', 'बागली', 'दविन्दरपाल', 'चापलूसी', 'संस्कारियों', 'इंजन्स', 'मेंडेज़', 'सियाह', 'गुजारने', 'गजरा', 'कवि', 'मिदनापुर', 'वृत्तों', 'सिरमोन', 'वर्तमान', 'उभरेगा', 'पायलट', 'नरभक्षी', 'एंट्रीक्स', 'डेटन', 'बडू', 'ऑलराउंडर', 'निश्रा', 'वधावन', 'जेन्सन', 'पाली', 'त्रैमासिक', 'अट्रैक्ट', 'वविद्यालय', 'चंदन', 'मेगा', 'मैन्सफील्ड', 'मट्टानचेरी', 'नवकेतन', 'कमतर', 'पिट्यूनिया', 'पुरूषोत्तमपुर', 'तपन', 'ज़ुबान', 'एनसीआरडब्ल्यूसी', 'हैम्बलिन', 'आराम', 'यशपाल', 'वोखा', 'छेत्री', 'ओमैक्स', 'परवीन', 'कुकरेजा', 'प्रेमफलः', 'नरमी', 'श्रंखलाओं', 'अवरोधक', 'तीरों', 'गणेशा', 'झाड़ा', 'अनुपमा', 'तलबगार', 'बिन्दल', 'ज़वाला', 'आमरियापाड़ा', 'प्रतिनिधिकारी', 'हलमतपुरा', 'बूदम', 'मैकियास', 'मेडीकल', 'रिस्पेक्टिंग', 'रंजकता', 'दा', 'सक्शन', 'भूमी', 'त्यौहारों', 'रंगते', 'उत्तरा', 'पेंशनधारियों', 'कार्यकर्ताओं', 'विद्याओं', 'द़फन', 'सरहिंद', 'ख़ासकर', 'रैथ', 'गुडगौंव', 'साहब', 'उड़ानों', 'मेजेस्को', 'पुष्पा', 'केशरी', 'बांबी', 'कारगिल', 'टकरा', 'बिजी', 'क्रोम', 'स्तिथि', 'गल्फ', 'कालोनीवासियों', 'आवृत्तियों', 'सुहानुभूति', 'चमच', 'विरोधाभासी', 'साभार', 'ऑलकार्गो', 'हारना', 'अव्यवसायी', 'प्राविंसेस', 'छेत्री', 'प्रतिष्ठी', 'सपा्', 'पटकी', 'पर्चियों', 'प्रतिवाद', 'लिफ़ाफ़ा', 'दर्शाना', 'गेरीसन', 'आकंड़ों', 'धंधों', 'डिस्ट्रीब्यूटरी', 'खत्री', 'पंजिका', 'बातः', 'रावले', 'कंगन', 'प्रेमात्मक', 'सिपाही', 'नोटबंदीशुदा', 'देवलहा', 'हल्ला', 'ज़मातें', 'मैसी', 'उसक', 'पितामह', 'विवरणःभारतीय', 'नागेरकोइल', 'लख्खी', 'अच्छी', 'सैटिन', 'नागपुर', 'बसीरहाट', 'छेलै', 'उबरकर', 'संयुक्तावस्था', 'सूरी', 'भपाई', 'व्यक्तिगत', 'महाथिर', 'फ्लेश', 'राष्ट्रक', 'राजभाई', 'हॉन्ग', 'लंगरों', 'सुभाय', 'फंड', 'फ्लावर्स', 'उठने', 'बडा़', 'मिश्रा', 'षट्', 'मैनहट्टन', 'सरगुजा', 'ईवनिंग', 'ग्रहणकाल', 'बागली', 'नीऊ', 'मुंडवा', 'तोलासन', 'जेडटीईसाफ्ट', 'नागमण्डल', 'कनाल', 'मछलीपट्टनम', 'फेलिक्स', 'हस्ताक्षरों', 'भिलाई', 'कॉन्ट्रेक्टिंग', 'क़रार', 'जौं', 'भाालू', 'फोर्टिस', 'गिरजाघरों', 'जैनों', 'अर्थव्यवस्थाः', 'ऑक्सीज', 'खिताबों', 'एनका', 'चष्मा', 'बताअाे', 'घृतकुमारी', 'प्राटेस्टेंट', 'ब्युर', 'लक्ष्मीधर', 'सियासी', 'उपयोगितावादियों', 'टूगा', 'समाधियों', 'खुरपका', 'कुमावत', 'एमडब्ल्यूपी', 'सूरज', 'न्यूरोसाइंटिस्ट्स', 'चंद्रेश्वरनगर', 'टैनिस', 'फर्रूखनगर', 'आवाज़ों', 'नजराने', 'पशुचारा', 'वेबुनियादी', 'डेनबरी', 'नईदिल्ली', 'छल्ला', 'रोवन', 'श्योपुर', 'रव्लानी', 'संवरी', 'धाक', 'मस्से', 'इंश्योरेंस', 'संप्रभुता', 'राष्ट्रा', 'जौहरी', 'जुदाई', 'बदमाशाें', 'खिताबों', 'स्वयँ', 'आग़ा', 'ढिंडवाल', 'घिसे', 'सप्पांवाली', 'निखारें', 'बाधित', 'ब्रह्मपुर', 'बैटाउन', 'कोलिंग', 'समाधियों', 'यूनियनवादी', 'छापेमार', 'ग़रीबों', 'थाऊजेंड', 'डसीला', 'कंजेंटेवाइटिस', 'बाधाओं', 'लगेगा', 'दुर्घटना', 'नितियों', 'कैपधारी', 'अत्री', 'सिंगम', 'वास्तविक', 'सबस्टेंसिस', 'पीलेपन', 'उठनी', 'हंडिया', 'प्रतिरक्षी', 'ललकारता', 'दुकानों', 'निविदाताओं', 'सर्वजातीय', 'नरसंहारों', 'नीमकाथाना', 'हेरेरा', 'जुनून', 'इकाई', 'जगदलपुर', 'स्विफ्टलेट', 'जलगति', 'पिट्स', 'रोपी', 'अड़ंगा', 'आलसी', 'चौकियां', 'लेटन', 'वकरंगी', 'डेवलपमेंट', 'शॉनी', 'परदेसियों', 'भूगोल', 'बगीची', 'सिवान', 'स्ट्रे', 'आलसी', 'व्यू', 'विषहीन', 'किस्सागोई', 'महानिदेशक', 'चिकित्साएवं', 'भट्टाचार्य', 'ट्रेंटन', 'कन्याएं', 'प्रियदर्शिनी', 'हुक़ूक़', 'शुल्कः', 'राणे', 'महाविद्या', 'संशयों', 'श्रेणीः', 'ओडोम', 'बेनिटेज़', 'त्यौहार', 'मतियाना', 'शवयात्रा', 'रिश्ते', 'रेहाना', 'क्यूएसएस', 'अनावश्यक', 'रिझाया', 'ब्रिगेड', 'सपने', 'चुनीं', 'कोषाधिकारी', 'करब', 'पलटने', 'कर्णेश्वरधाम', 'आर्यनस', 'प्रतिष्ठानोंं', 'कराईकल', 'उसकी', 'विपरीतता', 'परीक्षाओ', 'फ्यूजी', 'लामिनार', 'जुटाती', 'कौशिक', 'बेकाबू', 'नैनो', 'ओडिसा', 'तोमर', 'रोपी', 'थप्पड़बाज़ी', 'बाबत', 'अट्टहास', 'कोलन', 'प्रतिलीटर', 'भूसी', 'हलिया', 'उत्पीडऩ', 'पोप', 'करखेले', 'बाहुल्य', 'अस्वभाविक', 'कठनाईयों', 'रामजीलाल', 'वसूलता', 'मुख्यमंत्री', 'मारिया', 'सत्मेव', 'बक्सा', 'उदर', 'मैन', 'बुद्धिजीवों', 'सुदीप', 'जोड़ो', 'तसदीक', 'निकालनी', 'भटकाना', 'हारना', 'डिल्लों', 'रजिस्टर्ड', 'भंडारा', 'ललानिया', 'लिमा', 'लालकृष्ण', 'रत्नाभूषण', 'सपरिवार', 'साह', 'समेटती', 'पाइरिया', 'मामलोंमें', 'बरात', 'वैइसन', 'विला', 'लिंडा', 'खरिया', 'चेलानी', 'इलेक्ट्रॉनिक्स', 'ऋषिराज', 'उदयपुर', 'पगला', 'ऋतुकांत', 'कुर्मी', 'दस्ताना', 'एमरल्ड', 'घुमाई', 'उपद्रवियों', 'ओक्लाहोमा', 'धर्मराजने', 'झाओहुई', 'उप्पीड़न', 'खेमिक', 'तुगलकी', 'दोआर', 'अवि', 'जड़ित', 'टैबू', 'प्रोग्रामर्स', 'टेलर्सविले', 'चादरों', 'रेसर', 'भका', 'अंधभक्तो', 'ओब्रायन', 'कृत्या', 'पीरान', 'नजरियों', 'मयूर', 'चौदहवां', 'स्वर्गदूत', 'फेका', 'इंडिपेन्डेट', 'टिंका', 'गुर्दों', 'जातियों', 'समन्वयक', 'सूबे', 'चंदन', 'प्रारंभिकता', 'ट्रैप', 'उदंत', 'डायनामेटिक', 'विद्युतीकृत', 'ललानिया', 'वदरा', 'वेड', 'फड़फड़ाएं', 'ट्रेडेड', 'अखुआपाड़ा', 'सराहा', 'विज्ञानवादियों', 'कमज़ोर', 'यंगस्टाउन', 'आर्यम्', 'पटकथाएं', 'बाजपेयी', 'जस्सी', 'नाऊ', 'एवव', 'लागातार', 'सुमन', 'पड़नी', 'माइंडट्री', 'ड्रिस्ट्रीब्यूट्री', 'जानकारों', 'शंकचराचार्य', 'ऑफशोर', 'दुखों', 'नेस्को', 'फूलती', 'टूल्स', 'वर्गर', 'दमघोंटू', 'वीडियोः', 'राजमां', 'आत्ममुग्ध', 'रॉकफोर्ड', 'मित्रा', 'देवनार', 'ओकोई', 'उत्तरिया', 'कैनविज', 'गैलेक्सियों', 'जीवनियां', 'हकीकत', 'एलिमिनेटर', 'अगस्टाइन', 'कर', 'बीताने', 'दफ्तरवाले', 'बैराढ', 'कंबलों', 'ज्वार', 'फातमा', 'विवेस', 'डीडब्ल्यूटी', 'धातुएं', 'सियाह', 'पीटने', 'बिच्चों', 'जिता', 'सेवाला', 'बताैर', 'आदित्या', 'क्षेत्रें', 'एंकेनी', 'छेत्र', 'मुकरते', 'ऐंठे', 'बाल्टी', 'खंगाली', 'बीएसएसएस', 'ब्ंजजसम', 'पुष्पित', 'लिंमर्ग', 'पेरेड्डी', 'बोदरा', 'फ़ोकस', 'दूताय', 'श्रीलेदर्स', 'महंकमदान', 'घूंसा', 'काव्यविधाओं', 'क्षत्रियादि', 'जानकारों', 'रखना', 'रिश्तेदारो', 'श्रावणी', 'कुबुद्दीन', 'ज्वेलर्स', 'मेहमान', 'रोजलिन', 'जयकारा', 'चबूतरे', 'हरदिल', 'ट्रक', 'न्यूरोवेस्कुलर', 'खेलाने', 'स्ट्रेशन', 'लक्ष्यतीर्थ', 'नेशंस', 'पाठशालाएं', 'निवेदनः', 'लीडरों', 'टेनला', 'सेवकों', 'पूर्वापेक्षाओं', 'मणि', 'साेमवार', 'प्राण', 'अवैज्ञानिक', 'ऐवीऐशन', 'ब्राउन', 'नाकाम', 'अधिवास', 'जनजागरण', 'राजनंदगांव', 'लैरी', 'भाालू', 'तरीको', 'चिकोपी', 'रिफ्रेक्टरीज़', 'बरामद', 'काव', 'एमरल्ड', 'विवेकाधीन', 'फड़फड़ाएं', 'कायलाना', 'पेंट्स', 'पिट्सबर्ग', 'होखत', 'चौरसिया', 'सच्चिदानंद', 'सीड', 'चारों', 'रिज़वी', 'क्ले', 'दंपति', 'दूर्गध', 'देवापुर', 'मनवाया', 'लटककर', 'मेहमान', 'निया', 'उधमपुर', 'अतहर', 'छुपता', 'तुंगनाथ', 'रघुपति', 'प्रकाण्ड़', 'चेंज्ड', 'गंगटोक', 'क्रिकेट', 'फ्रांसिस्को', 'भगाने', 'अड़ंगा', 'फिक्सिंगः', 'कमाऊ', 'तिकोने', 'पैम', 'तरीक़ों', 'आगमन', 'किदवई', 'आश्रितों', 'राघवन', 'जनेऊधारी', 'डेवनपोर्ट', 'प्रेरणापुरी', 'महासिंह', 'लोरदा', 'इंट्रोडक्शन', 'स्वभावतः', 'ग्रीष्मोत्सव', 'तलाशेगा', 'सहरसा', 'मैके', 'मोशे', 'ग्रंथियां', 'लोहाती', 'अलायंस', 'तगड़े', 'छींके', 'सिवान', 'थकी', 'लेटकर', 'हिकारिको', 'टायर्स', 'नृत्यों', 'डियरफील्ड', 'चरित', 'बैथलहम', 'फिनोटेक्स', 'असाही', 'पहन', 'धनश्याम', 'फारेंसिस', 'लहना', 'द्वारिकेश', 'डुबाना', 'काराबोरियों', 'गोलमुरी', 'राखणौ', 'विपणक', 'पंचांग', 'ब्रीद', 'गुल्लरवाला', 'एडब्ल्यूपी', 'बाज़ी', 'हरपाल', 'प्रेमेश्वर', 'प्राप्त', 'नक्सलवाद', 'कंठहार', 'ऑक्साइड', 'खैराती', 'देशके', 'सुनासीर', 'अफसराें', 'सेहो', 'चबाते', 'मिति', 'बेलचा', 'सफ़लता', 'शबाना', 'खातूटोला', 'शिवास्तव', 'प्रेरणापुरी']\n",
            "51200\n",
            "4096\n",
            "4096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating tokenizied dataset here\n",
        "\n",
        "# Define a function to generate unique tokens for Hindi and English words from a dataset\n",
        "def uni_tok(dataset):\n",
        "  # Extract Hindi and English sentences from the dataset\n",
        "  hin = dataset['hin'].values\n",
        "  eng = dataset['eng'].values\n",
        "\n",
        "  # Initialize sets to store unique tokens for Hindi and English\n",
        "  hin_token = set()\n",
        "  eng_token = set()\n",
        "\n",
        "  # Iterate through pairs of Hindi and English sentences\n",
        "  for i, j in zip(eng, hin):\n",
        "    # Iterate through characters in Hindi sentence\n",
        "    for chare in j:\n",
        "      # Add each character to Hindi tokens set\n",
        "      hin_token.add(chare)\n",
        "    # Iterate through characters in English sentence\n",
        "    for chare in i:\n",
        "      # Add each character to English tokens set\n",
        "      eng_token.add(chare)\n",
        "\n",
        "  # Sort the sets and convert them to lists\n",
        "  hin_token = sorted(list(hin_token))\n",
        "  eng_token = sorted(list(eng_token))\n",
        "\n",
        "  # Return the lists of unique Hindi and English tokens\n",
        "  return hin_token, eng_token\n",
        "\n",
        "# Call the function to generate tokens for the training data\n",
        "hindi_token, english_token = uni_tok(train_data)\n",
        "\n",
        "# Print some statistics and samples of the generated tokens\n",
        "print(\"english_token : \", english_token)\n",
        "print(\"length of english words : \", len(english_token))\n",
        "print(\"hindi_token : \", hindi_token)\n",
        "print(\"length of hindi words : \", len(hindi_token))\n",
        "\n",
        "# \"Matraon\" ke liye alag se token hai mtlb ki"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOO8dojV7snM",
        "outputId": "37f9874b-3ff8-4520-a09a-bf42daf3a2b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "english_token :  ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "length of english words :  26\n",
            "hindi_token :  ['ँ', 'ं', 'ः', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ए', 'ऐ', 'ऑ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'ळ', 'व', 'श', 'ष', 'स', 'ह', '़', 'ऽ', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॅ', 'े', 'ै', 'ॉ', 'ो', 'ौ', '्']\n",
            "length of hindi words :  64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating token map here\n",
        "\n",
        "def tokenize_map(language_tokens , english_tokens):\n",
        "\n",
        "    # Create English token map with characters as keys and their index + 1 as values\n",
        "    english_token_map = dict([(ch,i+1) for i,ch in enumerate(english_tokens)])\n",
        "\n",
        "    # Create language token map with characters as keys and their index + 1 as values\n",
        "    language_token_map = dict([(ch,i+1) for i,ch in enumerate(language_tokens)])\n",
        "\n",
        "    # Create a reverse language token map with index + 1 as keys and characters as values\n",
        "    reverse_language_token_map = dict([(i+1,ch) for i,ch in enumerate(language_tokens)])\n",
        "\n",
        "    # Adding blank space to both token maps with value 0\n",
        "    language_token_map[\" \"] = 0\n",
        "    english_token_map[\" \"] = 0\n",
        "\n",
        "    # Add special tokens for beginning and end of sentence in language token map\n",
        "    language_token_map[';']=65\n",
        "    language_token_map['.']=66\n",
        "\n",
        "    # Add special tokens for beginning and end of sentence in English token map\n",
        "    english_token_map[';']=27\n",
        "    english_token_map['.']=28\n",
        "\n",
        "    # Add <unk> token for unknown characters to language token maps\n",
        "    language_token_map['<unk>']=64\n",
        "\n",
        "    # Update the reverse language token map with special tokens\n",
        "    reverse_language_token_map[64]='<unk>'\n",
        "    reverse_language_token_map[65]=';'\n",
        "    reverse_language_token_map[66]='.'\n",
        "    reverse_language_token_map[0]=''\n",
        "\n",
        "    # Return the Marathi token map, English token map, and reverse Marathi token map\n",
        "    return language_token_map, reverse_language_token_map, english_token_map\n",
        "\n",
        "# Call the function to generate token maps for hindi and english\n",
        "hin_token_map, reverse_hin_token_map, eng_token_map = tokenize_map(hindi_token, english_token)\n",
        "\n",
        "# Print the generated token maps\n",
        "print(hin_token_map)\n",
        "print(reverse_hin_token_map)\n",
        "print(eng_token_map)\n",
        "\n",
        "# Print the lengths of Marathi and English token maps\n",
        "print('hindi token map length:', len(hin_token_map))\n",
        "print('english token map length:', len(eng_token_map))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EP1SUzLZZx1X",
        "outputId": "d740ce72-fdf8-4725-925e-e0c31b18557c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ँ': 1, 'ं': 2, 'ः': 3, 'अ': 4, 'आ': 5, 'इ': 6, 'ई': 7, 'उ': 8, 'ऊ': 9, 'ऋ': 10, 'ए': 11, 'ऐ': 12, 'ऑ': 13, 'ओ': 14, 'औ': 15, 'क': 16, 'ख': 17, 'ग': 18, 'घ': 19, 'ङ': 20, 'च': 21, 'छ': 22, 'ज': 23, 'झ': 24, 'ञ': 25, 'ट': 26, 'ठ': 27, 'ड': 28, 'ढ': 29, 'ण': 30, 'त': 31, 'थ': 32, 'द': 33, 'ध': 34, 'न': 35, 'प': 36, 'फ': 37, 'ब': 38, 'भ': 39, 'म': 40, 'य': 41, 'र': 42, 'ल': 43, 'ळ': 44, 'व': 45, 'श': 46, 'ष': 47, 'स': 48, 'ह': 49, '़': 50, 'ऽ': 51, 'ा': 52, 'ि': 53, 'ी': 54, 'ु': 55, 'ू': 56, 'ृ': 57, 'ॅ': 58, 'े': 59, 'ै': 60, 'ॉ': 61, 'ो': 62, 'ौ': 63, '्': 64, ' ': 0, ';': 65, '.': 66, '<unk>': 64}\n",
            "{1: 'ँ', 2: 'ं', 3: 'ः', 4: 'अ', 5: 'आ', 6: 'इ', 7: 'ई', 8: 'उ', 9: 'ऊ', 10: 'ऋ', 11: 'ए', 12: 'ऐ', 13: 'ऑ', 14: 'ओ', 15: 'औ', 16: 'क', 17: 'ख', 18: 'ग', 19: 'घ', 20: 'ङ', 21: 'च', 22: 'छ', 23: 'ज', 24: 'झ', 25: 'ञ', 26: 'ट', 27: 'ठ', 28: 'ड', 29: 'ढ', 30: 'ण', 31: 'त', 32: 'थ', 33: 'द', 34: 'ध', 35: 'न', 36: 'प', 37: 'फ', 38: 'ब', 39: 'भ', 40: 'म', 41: 'य', 42: 'र', 43: 'ल', 44: 'ळ', 45: 'व', 46: 'श', 47: 'ष', 48: 'स', 49: 'ह', 50: '़', 51: 'ऽ', 52: 'ा', 53: 'ि', 54: 'ी', 55: 'ु', 56: 'ू', 57: 'ृ', 58: 'ॅ', 59: 'े', 60: 'ै', 61: 'ॉ', 62: 'ो', 63: 'ौ', 64: '<unk>', 65: ';', 66: '.', 0: ''}\n",
            "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, ' ': 0, ';': 27, '.': 28}\n",
            "hindi token map length: 68\n",
            "english token map length: 29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets see what is the maximun word length avaiolable in the dataset\n",
        "\n",
        "# Assigning values from the 'hin' and 'eng' columns of the test_data DataFrame to variables 'hiii' and 'ennn' respectively.\n",
        "hiii = test_data['hin'].values\n",
        "ennn = test_data['eng'].values\n",
        "\n",
        "# Adding ';' at the beginning and '.' at the end of each element in the 'hiii' and 'ennn' arrays.\n",
        "# Adding special characters like ';' and '.' the start and end of a sentence or phrase, which is necessary for subsequent processing or analysis being performed on the strings.\n",
        "hiii = ';' + hiii + '.'\n",
        "ennn = ';' + ennn + '.'\n",
        "\n",
        "#print(hiii)\n",
        "\n",
        "# Finding the maximum length of a string in the 'hiii' array.\n",
        "maximum_hin = max([len(i) for i in hiii])\n",
        "# Finding the maximum length of a string in the 'ennn' array.\n",
        "maximum_eng = max([len(i) for i in ennn])\n",
        "\n",
        "# Printing the maximum word length in Hindi.\n",
        "print(\"maximum word length in hindi is : \", maximum_hin)\n",
        "# Printing the maximum word length in English.\n",
        "print(\"maximum word length in english is : \", maximum_eng)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3t1NmzzG-FEi",
        "outputId": "bcc44ca2-ee88-467f-8814-1b989cd3dddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maximum word length in hindi is :  22\n",
            "maximum word length in english is :  28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NOw we do one hot encoding\n",
        "\n",
        "import torch\n",
        "#unknown token present in validation set as 'r.(in hindi)'\n",
        "unknown_token=64\n",
        "def process(data):\n",
        "    x,y = data['eng'].values, data['hin'].values\n",
        "    x = \";\" + x + \".\"\n",
        "    y = \";\" + y + \".\"\n",
        "    print(x[0:3])\n",
        "    print(y[0:3])\n",
        "\n",
        "    a = torch.zeros((len(x),maximum_eng),dtype=torch.int64)\n",
        "    print(a.shape)\n",
        "\n",
        "    b = torch.zeros((len(y),maximum_eng),dtype=torch.int64)\n",
        "\n",
        "    data=[]\n",
        "    for i,(xx,yy) in enumerate(zip(x,y)):\n",
        "        for j,ch in enumerate(xx):\n",
        "            a[i,j] = eng_token_map[ch]\n",
        "\n",
        "        #a[i,j+1:] = eng_token_map[\" \"]\n",
        "        for j,ch in enumerate(yy):\n",
        "            if ch in hin_token_map:\n",
        "             b[i,j] = hin_token_map[ch]\n",
        "            else:\n",
        "              b[i,j]= unknown_token\n",
        "\n",
        "\n",
        "    '''\n",
        "    data = []\n",
        "    for xx, yy in zip(x, y):\n",
        "        a_seq = [eng_token_map[ch] for ch in xx]\n",
        "        b_seq = [hin_token_map.get(ch, unknown_token) for ch in yy]\n",
        "        data.append((a_seq, b_seq))\n",
        "    '''\n",
        "\n",
        "    data = [(a[i], b[i]) for i in range(len(x))]\n",
        "    print(a.shape)\n",
        "    print(b.shape)\n",
        "    return data\n",
        "\n",
        "print(train_data)\n",
        "train_procs = process(train_data)\n",
        "valid_procs = process(valid_data)\n",
        "test_procs = process(test_data)\n",
        "# print(train_process.shape)\n",
        "print('\\n')\n",
        "print('num of rows:',len(train_procs))\n",
        "print('num of columns:',len(train_procs[0]))\n",
        "print(train_procs[0][1])\n",
        "#print(valid_procs[0][1])\n",
        "#print(test_procs[0][1])\n",
        "\n"
      ],
      "metadata": {
        "id": "Y50ML0xPARbJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdb7a3fd-6fc8-4047-bb55-54356f92937a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               eng         hin\n",
            "0      shastragaar  शस्त्रागार\n",
            "1          bindhya    बिन्द्या\n",
            "2        kirankant    किरणकांत\n",
            "3      yagyopaveet   यज्ञोपवीत\n",
            "4          ratania     रटानिया\n",
            "...            ...         ...\n",
            "51195        toned        टोंड\n",
            "51196   mutanaazaa    मुतनाज़ा\n",
            "51197    asahmaton     असहमतों\n",
            "51198    sulgaayin    सुलगायीं\n",
            "51199  anchuthengu   अंचुतेंगु\n",
            "\n",
            "[51200 rows x 2 columns]\n",
            "[';shastragaar.' ';bindhya.' ';kirankant.']\n",
            "[';शस्त्रागार.' ';बिन्द्या.' ';किरणकांत.']\n",
            "torch.Size([51200, 28])\n",
            "torch.Size([51200, 28])\n",
            "torch.Size([51200, 28])\n",
            "[';jaisawal.' ';bajai.' ';sanghthan.']\n",
            "[';जयसवाल.' ';बजाई.' ';संघठन.']\n",
            "torch.Size([4096, 28])\n",
            "torch.Size([4096, 28])\n",
            "torch.Size([4096, 28])\n",
            "[';thermax.' ';sikhaaega.' ';learn.']\n",
            "[';थरमैक्स.' ';सिखाएगा.' ';लर्न.']\n",
            "torch.Size([4096, 28])\n",
            "torch.Size([4096, 28])\n",
            "torch.Size([4096, 28])\n",
            "\n",
            "\n",
            "num of rows: 51200\n",
            "num of columns: 2\n",
            "tensor([65, 46, 48, 64, 31, 64, 42, 52, 18, 52, 42, 66,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For reading the words, bro...\n",
        "\n",
        "def reverse_tokenize(data):\n",
        "    # Convert each element in data to an integer\n",
        "    data = map(int, data)\n",
        "    # Map each integer to its corresponding character using reverse_marathi_token_map\n",
        "    characters = map(reverse_hin_token_map.get, data)\n",
        "    # Join the characters into a single string\n",
        "    predicted_seq = ''.join(characters)\n",
        "    return predicted_seq"
      ],
      "metadata": {
        "id": "VvnAb8a5BQzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "BATCH_bitch_SIZE = 16\n",
        "\n",
        "PAD_IDX = 0\n",
        "BOS_IDX = ';'\n",
        "EOS_IDX = '.'\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#WE ARE NOT USING GENERATE BATCH FUNCTION\n",
        "'''\n",
        "def generate_batch(data_batch):\n",
        "  ma_batch, en_batch = [], []\n",
        "  for (en_item,ma_item) in data_batch:\n",
        "    #ma_batch.append(torch.cat([torch.tensor(mar_token_map[BOS_IDX]), ma_item, torch.tensor(mar_token_map[EOS_IDX])], dim=0))\n",
        "    #en_batch.append(torch.cat([torch.tensor(eng_token_map[BOS_IDX]), en_item, torch.tensor(eng_token_map[EOS_IDX])], dim=0))\n",
        "    #print(ma_item[0])\n",
        "    ma_batch=torch.tensor(ma_item,dtype=torch.int64)\n",
        "    en_batch=torch.tensor(en_item,dtype=torch.int64)\n",
        "\n",
        "  return  en_batch.to(device),ma_batch.to(device)\n",
        "\n",
        "'''\n",
        "\n",
        "train_itersn = DataLoader(train_procs, batch_size=BATCH_bitch_SIZE,\n",
        "                        shuffle=False)\n",
        "valid_itersn = DataLoader(valid_procs, batch_size=BATCH_bitch_SIZE,\n",
        "                        shuffle=False)\n",
        "test_itersn = DataLoader(test_procs, batch_size=BATCH_bitch_SIZE,\n",
        "                       shuffle=False)\n",
        "\n",
        "# Let's see what we got\n",
        "print(len(train_itersn))\n",
        "print(train_itersn)\n",
        "print(len(test_itersn))\n",
        "print(len(valid_itersn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUiH0-giEBGS",
        "outputId": "af117c8d-55a1-4f6a-e390-8e1c51c342da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3200\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x000001976520C340>\n",
            "256\n",
            "256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import string\n",
        "import random\n",
        "from collections import Counter\n",
        "# Set random seed for reproducibility\n",
        "SEED = 1234\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "import os\n"
      ],
      "metadata": {
        "id": "aFI61OHpGqhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from typing import Tuple\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dimension: int, emb_dimension: int, enc_hid_dimension: int, dec_hid_dimension: int, dropout: float):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_dimension = input_dimension\n",
        "        self.emb_dimension = emb_dimension\n",
        "        self.enc_hid_dimension = enc_hid_dimension\n",
        "        self.dec_hid_dimension = dec_hid_dimension\n",
        "        self.dropout = dropout\n",
        "\n",
        "        #print('inp. dim')\n",
        "        #print(self.input_dim)\n",
        "        #print('emb. dim')\n",
        "        #print(self.emb_dim)\n",
        "        self.embedding = nn.Embedding(self.input_dimension, self.emb_dimension)\n",
        "\n",
        "\n",
        "        self.rnn = nn.GRU(emb_dimension, enc_hid_dimension, bidirectional = True)\n",
        "\n",
        "        self.fc = nn.Linear(enc_hid_dimension * 2, dec_hid_dimension)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src: Tensor) -> Tuple[Tensor]:\n",
        "        src = src.permute(1,0)\n",
        "        #print(src)\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "\n",
        "        return outputs, hidden\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, enc_hid_dimension: int, dec_hid_dimension: int, attn_dimension: int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.enc_hid_dimension = enc_hid_dimension\n",
        "        self.dec_hid_dimension = dec_hid_dimension\n",
        "\n",
        "        self.attn_in = (enc_hid_dimension * 2) + dec_hid_dimension\n",
        "\n",
        "        self.attn = nn.Linear(self.attn_in, attn_dimension)\n",
        "\n",
        "    def forward(self, decoder_hidden: Tensor, encoder_outputs: Tensor) -> Tensor:\n",
        "\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "\n",
        "        repeated_decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        energy = torch.tanh(self.attn(torch.cat((\n",
        "            repeated_decoder_hidden,\n",
        "            encoder_outputs),\n",
        "            dim = 2)))\n",
        "\n",
        "        attention = torch.sum(energy, dim=2)\n",
        "\n",
        "        return F.softmax(attention, dim=1)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dimension: int, emb_dimension: int, enc_hid_dimension: int, dec_hid_dimension: int, dropout: int, attention: nn.Module):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dimension = emb_dimension\n",
        "        self.enc_hid_dimension = enc_hid_dimension\n",
        "        self.dec_hid_dimension = dec_hid_dimension\n",
        "        self.output_dimension = output_dimension\n",
        "        self.dropout = dropout\n",
        "        self.attention = attention\n",
        "\n",
        "        self.embedding = nn.Embedding(output_dimension, emb_dimension)\n",
        "\n",
        "        self.rnn = nn.GRU((enc_hid_dimension * 2) + emb_dimension, dec_hid_dimension)\n",
        "\n",
        "        self.out = nn.Linear(self.attention.attn_in + emb_dimension, output_dimension)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def _weighted_encoder_rep(self, decoder_hidden: Tensor, encoder_outputs: Tensor) -> Tensor:\n",
        "\n",
        "        a = self.attention(decoder_hidden, encoder_outputs)\n",
        "\n",
        "        a = a.unsqueeze(1)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        weighted_encoder_rep = torch.bmm(a, encoder_outputs)\n",
        "\n",
        "        weighted_encoder_rep = weighted_encoder_rep.permute(1, 0, 2)\n",
        "\n",
        "        return weighted_encoder_rep\n",
        "\n",
        "\n",
        "    def forward(self, input_: Tensor, decoder_hidden: Tensor, encoder_outputs: Tensor) -> Tuple[Tensor]:\n",
        "\n",
        "        input_ = input_.unsqueeze(0)\n",
        "        input_ = input_.permute(1,0)\n",
        "        embedded = self.dropout(self.embedding(input_))\n",
        "        weighted_encoder_rep = self._weighted_encoder_rep(decoder_hidden,\n",
        "                                                          encoder_outputs)\n",
        "\n",
        "        #print(weighted_encoder_rep.shape)\n",
        "        embedded = embedded.permute(1,0,2)\n",
        "\n",
        "        rnn_input = torch.cat((embedded, weighted_encoder_rep), dim = 2)\n",
        "\n",
        "        output, decoder_hidden = self.rnn(rnn_input, decoder_hidden.unsqueeze(0))\n",
        "\n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted_encoder_rep = weighted_encoder_rep.squeeze(0)\n",
        "\n",
        "        output = self.out(torch.cat((output, weighted_encoder_rep, embedded), dim = 1))\n",
        "\n",
        "        return output, decoder_hidden.squeeze(0)\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder: nn.Module, decoder: nn.Module, device: torch.device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src: Tensor, trg: Tensor, teacher_forcing_ratio: float = 0.5) -> Tensor:\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "        max_len = trg.shape[1]\n",
        "        trg_vocab_size = self.decoder.output_dimension\n",
        "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        #ATTENTION HEAT MAP METHOD\n",
        "        #attentions = torch.zeros(max_len, batch_size, src.shape[1]).to(self.device)\n",
        "\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "\n",
        "        # first input to the decoder is the <sos> token\n",
        "        trg = trg.permute(1,0)\n",
        "        output = trg[0,:]\n",
        "\n",
        "        for t in range(1, max_len):\n",
        "            output, hidden = self.decoder(output, hidden, encoder_outputs)\n",
        "            outputs[t] = output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.max(1)[1]\n",
        "            output = (trg[t] if teacher_force else top1)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "INPUT_DIMENSION = len(eng_token_map)\n",
        "OUTPUT_DIMENSION = len(hin_token_map)\n",
        "ENC_EMB_DIMENSION = 512\n",
        "DEC_EMB_DIMENSION = 512\n",
        "ENC_HID_DIMENSION  = 256\n",
        "DEC_HID_DIMENSION  = 256\n",
        "ATTN_DIMENSION  = 256\n",
        "ENC_DROPOUT = 0.3\n",
        "DEC_DROPOUT = 0.3\n",
        "\n",
        "encoder_bkl = Encoder(INPUT_DIMENSION , ENC_EMB_DIMENSION, ENC_HID_DIMENSION, DEC_HID_DIMENSION, ENC_DROPOUT)\n",
        "attension_bkl = Attention(ENC_HID_DIMENSION, DEC_HID_DIMENSION, ATTN_DIMENSION)\n",
        "decoder_bkl = Decoder(OUTPUT_DIMENSION , DEC_EMB_DIMENSION,  ENC_HID_DIMENSION, DEC_HID_DIMENSION, DEC_DROPOUT, attension_bkl)\n",
        "model_bkl = Seq2Seq(encoder_bkl, decoder_bkl, device).to(device)\n",
        "\n",
        "\n",
        "def init_weights(m: nn.Module):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "\n",
        "#added custom weights\n",
        "model_bkl.apply(init_weights)\n",
        "\n",
        "optimizer = optim.Adam(model_bkl.parameters())\n",
        "\n",
        "\n",
        "def count_parameters(model: nn.Module):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "print(f'The model has {count_parameters(model_bkl):,} trainable parameters')\n",
        "print(\"That's alot of parameters!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbIItUKpwflu",
        "outputId": "5fb5f8a0-69f0-4c1c-a209-472e9d7b22f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 2,632,260 trainable parameters\n",
            "That's alot of parameters!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wandb implimenststion of Attantion"
      ],
      "metadata": {
        "id": "b9Rd9asq8Wk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade wandb\n",
        "!wandb login 3c21150eb43b007ee446a1ff6e87f640ec7528c4 #my API key for wandb login\n",
        "import wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qNbTSZcFxOk",
        "outputId": "06c899de-fb1f-4703-d69d-9614b9ca8fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.17.0-py3-none-win_amd64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\asl 5\\.conda\\envs\\cuda121_pytorch222\\lib\\site-packages (from wandb) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in c:\\users\\asl 5\\.conda\\envs\\cuda121_pytorch222\\lib\\site-packages (from wandb) (3.10.0)\n",
            "Collecting protobuf!=4.21.0,<5,>=3.19.0 (from wandb)\n",
            "  Downloading protobuf-4.25.3-cp38-cp38-win_amd64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\asl 5\\.conda\\envs\\cuda121_pytorch222\\lib\\site-packages (from wandb) (5.9.0)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\asl 5\\.conda\\envs\\cuda121_pytorch222\\lib\\site-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\asl 5\\.conda\\envs\\cuda121_pytorch222\\lib\\site-packages (from wandb) (2.31.0)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.1.1-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp38-cp38-win_amd64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: setuptools in c:\\users\\asl 5\\.conda\\envs\\cuda121_pytorch222\\lib\\site-packages (from wandb) (68.2.2)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\asl 5\\.conda\\envs\\cuda121_pytorch222\\lib\\site-packages (from wandb) (4.9.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\asl 5\\.conda\\envs\\cuda121_pytorch222\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
            "Requirement already satisfied: six>=1.4.0 in c:\\users\\asl 5\\.conda\\envs\\cuda121_pytorch222\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asl 5\\.conda\\envs\\cuda121_pytorch222\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asl 5\\.conda\\envs\\cuda121_pytorch222\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asl 5\\.conda\\envs\\cuda121_pytorch222\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asl 5\\.conda\\envs\\cuda121_pytorch222\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading wandb-0.17.0-py3-none-win_amd64.whl (6.7 MB)\n",
            "   ---------------------------------------- 0.0/6.7 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/6.7 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/6.7 MB 991.0 kB/s eta 0:00:07\n",
            "   ---------------------------------------- 0.1/6.7 MB 491.5 kB/s eta 0:00:14\n",
            "    --------------------------------------- 0.1/6.7 MB 877.7 kB/s eta 0:00:08\n",
            "   - -------------------------------------- 0.2/6.7 MB 935.2 kB/s eta 0:00:07\n",
            "   - -------------------------------------- 0.3/6.7 MB 1.2 MB/s eta 0:00:06\n",
            "   -- ------------------------------------- 0.5/6.7 MB 1.4 MB/s eta 0:00:05\n",
            "   --- ------------------------------------ 0.5/6.7 MB 1.4 MB/s eta 0:00:05\n",
            "   --- ------------------------------------ 0.6/6.7 MB 1.4 MB/s eta 0:00:05\n",
            "   ---- ----------------------------------- 0.7/6.7 MB 1.4 MB/s eta 0:00:05\n",
            "   ---- ----------------------------------- 0.8/6.7 MB 1.5 MB/s eta 0:00:05\n",
            "   ----- ---------------------------------- 1.0/6.7 MB 1.7 MB/s eta 0:00:04\n",
            "   ------ --------------------------------- 1.1/6.7 MB 1.7 MB/s eta 0:00:04\n",
            "   ------- -------------------------------- 1.2/6.7 MB 1.8 MB/s eta 0:00:04\n",
            "   ------- -------------------------------- 1.3/6.7 MB 1.8 MB/s eta 0:00:04\n",
            "   -------- ------------------------------- 1.4/6.7 MB 1.8 MB/s eta 0:00:03\n",
            "   -------- ------------------------------- 1.5/6.7 MB 1.8 MB/s eta 0:00:03\n",
            "   --------- ------------------------------ 1.5/6.7 MB 1.8 MB/s eta 0:00:03\n",
            "   --------- ------------------------------ 1.5/6.7 MB 1.8 MB/s eta 0:00:03\n",
            "   --------- ------------------------------ 1.6/6.7 MB 1.7 MB/s eta 0:00:04\n",
            "   --------- ------------------------------ 1.6/6.7 MB 1.7 MB/s eta 0:00:04\n",
            "   ---------- ----------------------------- 1.7/6.7 MB 1.6 MB/s eta 0:00:04\n",
            "   ---------- ----------------------------- 1.8/6.7 MB 1.6 MB/s eta 0:00:04\n",
            "   ---------- ----------------------------- 1.9/6.7 MB 1.6 MB/s eta 0:00:04\n",
            "   ---------- ----------------------------- 1.9/6.7 MB 1.6 MB/s eta 0:00:04\n",
            "   ----------- ---------------------------- 2.0/6.7 MB 1.5 MB/s eta 0:00:04\n",
            "   ----------- ---------------------------- 2.0/6.7 MB 1.5 MB/s eta 0:00:04\n",
            "   ----------- ---------------------------- 2.0/6.7 MB 1.5 MB/s eta 0:00:04\n",
            "   ------------ --------------------------- 2.1/6.7 MB 1.5 MB/s eta 0:00:04\n",
            "   ------------ --------------------------- 2.2/6.7 MB 1.5 MB/s eta 0:00:04\n",
            "   ------------- -------------------------- 2.2/6.7 MB 1.5 MB/s eta 0:00:04\n",
            "   ------------- -------------------------- 2.3/6.7 MB 1.5 MB/s eta 0:00:04\n",
            "   -------------- ------------------------- 2.4/6.7 MB 1.5 MB/s eta 0:00:03\n",
            "   -------------- ------------------------- 2.4/6.7 MB 1.4 MB/s eta 0:00:03\n",
            "   -------------- ------------------------- 2.5/6.7 MB 1.4 MB/s eta 0:00:03\n",
            "   --------------- ------------------------ 2.5/6.7 MB 1.4 MB/s eta 0:00:03\n",
            "   --------------- ------------------------ 2.6/6.7 MB 1.4 MB/s eta 0:00:03\n",
            "   --------------- ------------------------ 2.7/6.7 MB 1.5 MB/s eta 0:00:03\n",
            "   ---------------- ----------------------- 2.7/6.7 MB 1.4 MB/s eta 0:00:03\n",
            "   ---------------- ----------------------- 2.8/6.7 MB 1.4 MB/s eta 0:00:03\n",
            "   ----------------- ---------------------- 2.9/6.7 MB 1.4 MB/s eta 0:00:03\n",
            "   ----------------- ---------------------- 2.9/6.7 MB 1.4 MB/s eta 0:00:03\n",
            "   ----------------- ---------------------- 3.0/6.7 MB 1.4 MB/s eta 0:00:03\n",
            "   ------------------ --------------------- 3.1/6.7 MB 1.4 MB/s eta 0:00:03\n",
            "   ------------------ --------------------- 3.1/6.7 MB 1.4 MB/s eta 0:00:03\n",
            "   ------------------ --------------------- 3.2/6.7 MB 1.4 MB/s eta 0:00:03\n",
            "   ------------------- -------------------- 3.2/6.7 MB 1.4 MB/s eta 0:00:03\n",
            "   ------------------- -------------------- 3.3/6.7 MB 1.4 MB/s eta 0:00:03\n",
            "   ------------------- -------------------- 3.4/6.7 MB 1.4 MB/s eta 0:00:03\n",
            "   ------------------- -------------------- 3.4/6.7 MB 1.4 MB/s eta 0:00:03\n",
            "   ------------------- -------------------- 3.4/6.7 MB 1.4 MB/s eta 0:00:03\n",
            "   -------------------- ------------------- 3.5/6.7 MB 1.4 MB/s eta 0:00:03\n",
            "   --------------------- ------------------ 3.6/6.7 MB 1.4 MB/s eta 0:00:03\n",
            "   --------------------- ------------------ 3.6/6.7 MB 1.4 MB/s eta 0:00:03\n",
            "   --------------------- ------------------ 3.7/6.7 MB 1.4 MB/s eta 0:00:03\n",
            "   --------------------- ------------------ 3.7/6.7 MB 1.4 MB/s eta 0:00:03\n",
            "   ---------------------- ----------------- 3.7/6.7 MB 1.4 MB/s eta 0:00:03\n",
            "   ---------------------- ----------------- 3.9/6.7 MB 1.4 MB/s eta 0:00:03\n",
            "   ----------------------- ---------------- 3.9/6.7 MB 1.4 MB/s eta 0:00:03\n",
            "   ------------------------ --------------- 4.1/6.7 MB 1.4 MB/s eta 0:00:02\n",
            "   ------------------------ --------------- 4.1/6.7 MB 1.4 MB/s eta 0:00:02\n",
            "   ------------------------- -------------- 4.2/6.7 MB 1.4 MB/s eta 0:00:02\n",
            "   ------------------------- -------------- 4.4/6.7 MB 1.4 MB/s eta 0:00:02\n",
            "   -------------------------- ------------- 4.5/6.7 MB 1.4 MB/s eta 0:00:02\n",
            "   --------------------------- ------------ 4.6/6.7 MB 1.4 MB/s eta 0:00:02\n",
            "   --------------------------- ------------ 4.7/6.7 MB 1.5 MB/s eta 0:00:02\n",
            "   ---------------------------- ----------- 4.8/6.7 MB 1.5 MB/s eta 0:00:02\n",
            "   ----------------------------- ---------- 4.9/6.7 MB 1.5 MB/s eta 0:00:02\n",
            "   ------------------------------ --------- 5.1/6.7 MB 1.5 MB/s eta 0:00:02\n",
            "   ------------------------------ --------- 5.1/6.7 MB 1.5 MB/s eta 0:00:02\n",
            "   ------------------------------- -------- 5.3/6.7 MB 1.5 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 5.4/6.7 MB 1.5 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 5.6/6.7 MB 1.6 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 5.7/6.7 MB 1.6 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 5.8/6.7 MB 1.6 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 5.9/6.7 MB 1.6 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 6.0/6.7 MB 1.6 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 6.1/6.7 MB 1.6 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 6.3/6.7 MB 1.6 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 6.3/6.7 MB 1.6 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 6.3/6.7 MB 1.6 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 6.5/6.7 MB 1.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  6.7/6.7 MB 1.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  6.7/6.7 MB 1.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  6.7/6.7 MB 1.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  6.7/6.7 MB 1.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  6.7/6.7 MB 1.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  6.7/6.7 MB 1.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  6.7/6.7 MB 1.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  6.7/6.7 MB 1.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  6.7/6.7 MB 1.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 6.7/6.7 MB 1.5 MB/s eta 0:00:00\n",
            "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "   ---------------------------------------- 0.0/207.3 kB ? eta -:--:--\n",
            "   ----- --------------------------------- 30.7/207.3 kB 660.6 kB/s eta 0:00:01\n",
            "   --------------------- ------------------ 112.6/207.3 kB 1.3 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 153.6/207.3 kB 1.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 207.3/207.3 kB 1.2 MB/s eta 0:00:00\n",
            "Downloading protobuf-4.25.3-cp38-cp38-win_amd64.whl (413 kB)\n",
            "   ---------------------------------------- 0.0/413.4 kB ? eta -:--:--\n",
            "   --- ------------------------------------ 41.0/413.4 kB 1.9 MB/s eta 0:00:01\n",
            "   ------------- -------------------------- 143.4/413.4 kB 1.4 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 317.4/413.4 kB 2.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------  409.6/413.4 kB 2.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 413.4/413.4 kB 1.8 MB/s eta 0:00:00\n",
            "Downloading sentry_sdk-2.1.1-py2.py3-none-any.whl (277 kB)\n",
            "   ---------------------------------------- 0.0/277.3 kB ? eta -:--:--\n",
            "   ---------------- ----------------------- 112.6/277.3 kB 6.4 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 204.8/277.3 kB 2.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 277.3/277.3 kB 1.9 MB/s eta 0:00:00\n",
            "Downloading setproctitle-1.3.3-cp38-cp38-win_amd64.whl (11 kB)\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "   ---------------------------------------- 0.0/62.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 62.7/62.7 kB 1.1 MB/s eta 0:00:00\n",
            "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, protobuf, docker-pycreds, gitdb, gitpython, wandb\n",
            "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 protobuf-4.25.3 sentry-sdk-2.1.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.17.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\ASL 5\\.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import time\n",
        "sweep_config = {\n",
        "    'method': 'bayes', #grid, random,bayes\n",
        "    'metric': {\n",
        "      'name': 'valid_accuracy',\n",
        "      'goal': 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'embed_dimension': {\n",
        "            'values': [128,256,512]\n",
        "        },\n",
        "        'hidden_layer_dimension': {\n",
        "            'values': [128,256,512]\n",
        "        },\n",
        "        'attention_dimension':{\n",
        "            'values':[64,128,256]\n",
        "        },\n",
        "        'dropout':{\n",
        "            'values':[0.3,0.5,0.6]\n",
        "        },\n",
        "    }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, entity='ed23d015', project=\"DL_Assignment_3\")\n",
        "\n",
        "def sweep_train():\n",
        "  # Default values for hyper-parameters we're going to sweep over\n",
        "  config_defaults = {\n",
        "      'embed_dimension':256,\n",
        "      'hidden_layer_dimension':256,\n",
        "      'attention_dimension':128,\n",
        "      'dropout':0.6,\n",
        "  }\n",
        "\n",
        "  # Initialize a new wandb run\n",
        "  wandb.init(project='DL_Assignment_3', entity='ed23d015',config=config_defaults)\n",
        "  wandb.run.name = 'embed_dimension:'+ str(wandb.config.embed_dimension)+' ;hl:'+str(wandb.config.hidden_layer_dimension)+ ' ;attention_dimension:'+str(wandb.config.attention_dimension)+ ' ;dropout:'+str(wandb.config.dropout)\n",
        "  config = wandb.config\n",
        "  embed_dimension = config.embed_dimension\n",
        "  hidden_layer_dimension = config.hidden_layer_dimension\n",
        "  attention_dimension = config.attention_dimension\n",
        "  dropout = config.dropout\n",
        "\n",
        "  # Doing Model training here\n",
        "  INPUT_DIM = len(eng_token_map)\n",
        "  OUTPUT_DIM = len(hin_token_map)\n",
        "\n",
        "\n",
        "  encoder_bkl = Encoder(INPUT_DIM, embed_dimension, hidden_layer_dimension, hidden_layer_dimension, dropout)\n",
        "\n",
        "  attension_bkl = Attention(hidden_layer_dimension, hidden_layer_dimension, attention_dimension)\n",
        "\n",
        "  decoder_bkl = Decoder(OUTPUT_DIM, embed_dimension, hidden_layer_dimension, hidden_layer_dimension, dropout, attension_bkl)\n",
        "\n",
        "  model_bkl = Seq2Seq(encoder_bkl, decoder_bkl, device).to(device)\n",
        "  model_bkl.apply(init_weights)\n",
        "  optimizer = optim.Adam(model_bkl.parameters())\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  model_bkl.train()\n",
        "\n",
        "  # Initializing losses and accuracies\n",
        "  training_epoch_loss = 0\n",
        "  training_epoch_accuracy = 0\n",
        "  validation_epoch_loss = 0\n",
        "  validation_epoch_accuracy = 0\n",
        "\n",
        "  N_EPOCHS = 10\n",
        "  CLIP = 1\n",
        "\n",
        "  for epoch in range(N_EPOCHS):\n",
        "\n",
        "  #TRAINING BLOCK\n",
        "    model_bkl.train()\n",
        "    for _, (source, target) in enumerate(train_itersn):\n",
        "        source, target = source.to(device), target.to(device)\n",
        "        #print(\"target1: \", target)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model_bkl(source, target)\n",
        "\n",
        "        output = output[1:].view(-1, output.shape[-1])\n",
        "        target = target.permute(1,0)\n",
        "        target = torch.reshape(target[1:], (-1,))\n",
        "        #print(\"target2: \", target.shape)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # calculating accuracy\n",
        "        preds = torch.argmax(output, dim=1)\n",
        "        #print(\"pred: \", preds)\n",
        "        #print(\"target3: \", target)\n",
        "        non_pad_elements = (target != 0).nonzero(as_tuple=True)[0]\n",
        "        #print(\"non_pad_elements: \", non_pad_elements)\n",
        "        train_correct = preds[non_pad_elements] == target[non_pad_elements]\n",
        "\n",
        "        #print(\"len(non_pad_elements): \", len(non_pad_elements))\n",
        "        training_epoch_accuracy += train_correct.sum().item() / len(non_pad_elements)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model_bkl.parameters(), CLIP)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        training_epoch_loss += loss.item()\n",
        "\n",
        "\n",
        "    training_epoch_loss = training_epoch_loss / len(train_itersn)\n",
        "    training_epoch_accuracy = training_epoch_accuracy / len(train_itersn)\n",
        "\n",
        "\n",
        "    #EVALUATION MODE ON\n",
        "    model_bkl.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for _, (source, target) in enumerate(valid_itersn):\n",
        "            source, target = source.to(device), target.to(device)\n",
        "\n",
        "            output = model_bkl(source, target, 0) # Turn off teacher forcing\n",
        "\n",
        "            output = output[1:].view(-1, output.shape[-1])\n",
        "            target = target.permute(1,0)\n",
        "            target = torch.reshape(target[1:], (-1,))\n",
        "\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            validation_epoch_loss += loss.item()\n",
        "            # Calculating accuracy\n",
        "            preds = torch.argmax(output, dim=1)\n",
        "            non_pad_elements = (target != 0).nonzero(as_tuple=True)[0]\n",
        "            val_correct = preds[non_pad_elements] == target[non_pad_elements]\n",
        "            validation_epoch_accuracy += val_correct.sum().item() / len(non_pad_elements)\n",
        "\n",
        "    validation_epoch_accuracy = validation_epoch_accuracy / len(valid_itersn)\n",
        "    validation_epoch_loss = validation_epoch_loss / len(valid_itersn)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} |Train Loss: {training_epoch_loss:.3f} | Train accuracy: {training_epoch_accuracy:.3f}|Val. Loss: {validation_epoch_loss:.3f} | Val accuracy: {validation_epoch_accuracy:.3f}')\n",
        "    wandb.log({\"train_loss\":training_epoch_loss,\"train_accuracy\": training_epoch_accuracy,\"val_loss\":validation_epoch_loss,\"val_accuracy\":validation_epoch_accuracy},)\n",
        "\n",
        "    # Emptying the cache after one complete run\n",
        "    if epoch==N_EPOCHS-1:\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "#RUNNING THE SWEEP\n",
        "wandb.agent(sweep_id, function=sweep_train, count=120)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q_mn5Fzk8j9r",
        "outputId": "abbca1d3-9e67-415b-e93f-dea0a5d5df9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: sf8drmdd\n",
            "Sweep URL: https://wandb.ai/ed23d015/DL_Assignment_3/sweeps/sf8drmdd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nn3raelg with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dimension: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_dimension: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_dimension: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33med23d015\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>C:\\Users\\ASL 5\\wandb\\run-20240514_223926-nn3raelg</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ed23d015/DL_Assignment_3/runs/nn3raelg' target=\"_blank\">grateful-sweep-1</a></strong> to <a href='https://wandb.ai/ed23d015/DL_Assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ed23d015/DL_Assignment_3/sweeps/sf8drmdd' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3/sweeps/sf8drmdd</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ed23d015/DL_Assignment_3' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/ed23d015/DL_Assignment_3/sweeps/sf8drmdd' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3/sweeps/sf8drmdd</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ed23d015/DL_Assignment_3/runs/nn3raelg' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3/runs/nn3raelg</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 |Train Loss: 0.722 | Train accuracy: 0.406|Val. Loss: 0.441 | Val accuracy: 0.584\n",
            "Epoch: 02 |Train Loss: 0.348 | Train accuracy: 0.688|Val. Loss: 0.391 | Val accuracy: 0.637\n",
            "Epoch: 03 |Train Loss: 0.296 | Train accuracy: 0.734|Val. Loss: 0.393 | Val accuracy: 0.647\n",
            "Epoch: 04 |Train Loss: 0.282 | Train accuracy: 0.747|Val. Loss: 0.402 | Val accuracy: 0.644\n",
            "Epoch: 05 |Train Loss: 0.279 | Train accuracy: 0.751|Val. Loss: 0.392 | Val accuracy: 0.652\n",
            "Epoch: 06 |Train Loss: 0.271 | Train accuracy: 0.757|Val. Loss: 0.405 | Val accuracy: 0.650\n",
            "Epoch: 07 |Train Loss: 0.270 | Train accuracy: 0.760|Val. Loss: 0.401 | Val accuracy: 0.656\n",
            "Epoch: 08 |Train Loss: 0.272 | Train accuracy: 0.757|Val. Loss: 0.407 | Val accuracy: 0.647\n",
            "Epoch: 09 |Train Loss: 0.271 | Train accuracy: 0.759|Val. Loss: 0.410 | Val accuracy: 0.653\n",
            "Epoch: 10 |Train Loss: 0.275 | Train accuracy: 0.756|Val. Loss: 0.415 | Val accuracy: 0.647\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▇████████</td></tr><tr><td>train_loss</td><td>█▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▆▇▇█▇█▇█▇</td></tr><tr><td>val_loss</td><td>█▁▁▃▁▃▂▃▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.75632</td></tr><tr><td>train_loss</td><td>0.27464</td></tr><tr><td>val_accuracy</td><td>0.64717</td></tr><tr><td>val_loss</td><td>0.41456</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">grateful-sweep-1</strong> at: <a href='https://wandb.ai/ed23d015/DL_Assignment_3/runs/nn3raelg' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3/runs/nn3raelg</a><br/> View project at: <a href='https://wandb.ai/ed23d015/DL_Assignment_3' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20240514_223926-nn3raelg\\logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1n188z2b with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dimension: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_dimension: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_dimension: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>C:\\Users\\ASL 5\\wandb\\run-20240514_232627-1n188z2b</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ed23d015/DL_Assignment_3/runs/1n188z2b' target=\"_blank\">zany-sweep-2</a></strong> to <a href='https://wandb.ai/ed23d015/DL_Assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ed23d015/DL_Assignment_3/sweeps/sf8drmdd' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3/sweeps/sf8drmdd</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ed23d015/DL_Assignment_3' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/ed23d015/DL_Assignment_3/sweeps/sf8drmdd' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3/sweeps/sf8drmdd</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ed23d015/DL_Assignment_3/runs/1n188z2b' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3/runs/1n188z2b</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 |Train Loss: 0.787 | Train accuracy: 0.357|Val. Loss: 0.461 | Val accuracy: 0.566\n",
            "Epoch: 02 |Train Loss: 0.323 | Train accuracy: 0.711|Val. Loss: 0.416 | Val accuracy: 0.633\n",
            "Epoch: 03 |Train Loss: 0.269 | Train accuracy: 0.759|Val. Loss: 0.398 | Val accuracy: 0.654\n",
            "Epoch: 04 |Train Loss: 0.243 | Train accuracy: 0.781|Val. Loss: 0.382 | Val accuracy: 0.666\n",
            "Epoch: 05 |Train Loss: 0.226 | Train accuracy: 0.797|Val. Loss: 0.374 | Val accuracy: 0.676\n",
            "Epoch: 06 |Train Loss: 0.215 | Train accuracy: 0.807|Val. Loss: 0.384 | Val accuracy: 0.682\n",
            "Epoch: 07 |Train Loss: 0.205 | Train accuracy: 0.817|Val. Loss: 0.368 | Val accuracy: 0.683\n",
            "Epoch: 08 |Train Loss: 0.200 | Train accuracy: 0.820|Val. Loss: 0.370 | Val accuracy: 0.688\n",
            "Epoch: 09 |Train Loss: 0.192 | Train accuracy: 0.828|Val. Loss: 0.394 | Val accuracy: 0.681\n",
            "Epoch: 10 |Train Loss: 0.189 | Train accuracy: 0.831|Val. Loss: 0.377 | Val accuracy: 0.686\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▆▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▃▂▂▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▆▇▇█████</td></tr><tr><td>val_loss</td><td>█▅▃▂▁▂▁▁▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.8313</td></tr><tr><td>train_loss</td><td>0.18904</td></tr><tr><td>val_accuracy</td><td>0.68615</td></tr><tr><td>val_loss</td><td>0.37686</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">zany-sweep-2</strong> at: <a href='https://wandb.ai/ed23d015/DL_Assignment_3/runs/1n188z2b' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3/runs/1n188z2b</a><br/> View project at: <a href='https://wandb.ai/ed23d015/DL_Assignment_3' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20240514_232627-1n188z2b\\logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gw3apqd6 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dimension: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_dimension: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_dimension: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>C:\\Users\\ASL 5\\wandb\\run-20240515_000945-gw3apqd6</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ed23d015/DL_Assignment_3/runs/gw3apqd6' target=\"_blank\">flowing-sweep-3</a></strong> to <a href='https://wandb.ai/ed23d015/DL_Assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ed23d015/DL_Assignment_3/sweeps/sf8drmdd' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3/sweeps/sf8drmdd</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ed23d015/DL_Assignment_3' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/ed23d015/DL_Assignment_3/sweeps/sf8drmdd' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3/sweeps/sf8drmdd</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ed23d015/DL_Assignment_3/runs/gw3apqd6' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3/runs/gw3apqd6</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 |Train Loss: 0.658 | Train accuracy: 0.460|Val. Loss: 0.423 | Val accuracy: 0.611\n",
            "Epoch: 02 |Train Loss: 0.286 | Train accuracy: 0.743|Val. Loss: 0.392 | Val accuracy: 0.656\n",
            "Epoch: 03 |Train Loss: 0.243 | Train accuracy: 0.783|Val. Loss: 0.378 | Val accuracy: 0.673\n",
            "Epoch: 04 |Train Loss: 0.220 | Train accuracy: 0.803|Val. Loss: 0.377 | Val accuracy: 0.681\n",
            "Epoch: 05 |Train Loss: 0.207 | Train accuracy: 0.815|Val. Loss: 0.367 | Val accuracy: 0.695\n",
            "Epoch: 06 |Train Loss: 0.195 | Train accuracy: 0.826|Val. Loss: 0.372 | Val accuracy: 0.694\n",
            "Epoch: 07 |Train Loss: 0.189 | Train accuracy: 0.831|Val. Loss: 0.371 | Val accuracy: 0.694\n",
            "Epoch: 08 |Train Loss: 0.181 | Train accuracy: 0.838|Val. Loss: 0.375 | Val accuracy: 0.698\n",
            "Epoch: 09 |Train Loss: 0.177 | Train accuracy: 0.842|Val. Loss: 0.375 | Val accuracy: 0.700\n",
            "Epoch: 10 |Train Loss: 0.176 | Train accuracy: 0.843|Val. Loss: 0.367 | Val accuracy: 0.703\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▆▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▃▂▂▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▆▆▇▇▇███</td></tr><tr><td>val_loss</td><td>█▄▂▂▁▂▁▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.84261</td></tr><tr><td>train_loss</td><td>0.17626</td></tr><tr><td>val_accuracy</td><td>0.70346</td></tr><tr><td>val_loss</td><td>0.36707</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">flowing-sweep-3</strong> at: <a href='https://wandb.ai/ed23d015/DL_Assignment_3/runs/gw3apqd6' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3/runs/gw3apqd6</a><br/> View project at: <a href='https://wandb.ai/ed23d015/DL_Assignment_3' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20240515_000945-gw3apqd6\\logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tvfo0tc6 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dimension: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_dimension: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_dimension: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>C:\\Users\\ASL 5\\wandb\\run-20240515_005554-tvfo0tc6</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ed23d015/DL_Assignment_3/runs/tvfo0tc6' target=\"_blank\">winter-sweep-4</a></strong> to <a href='https://wandb.ai/ed23d015/DL_Assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ed23d015/DL_Assignment_3/sweeps/sf8drmdd' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3/sweeps/sf8drmdd</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ed23d015/DL_Assignment_3' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/ed23d015/DL_Assignment_3/sweeps/sf8drmdd' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3/sweeps/sf8drmdd</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ed23d015/DL_Assignment_3/runs/tvfo0tc6' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3/runs/tvfo0tc6</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 |Train Loss: 0.713 | Train accuracy: 0.417|Val. Loss: 0.438 | Val accuracy: 0.600\n",
            "Epoch: 02 |Train Loss: 0.301 | Train accuracy: 0.729|Val. Loss: 0.402 | Val accuracy: 0.641\n",
            "Epoch: 03 |Train Loss: 0.254 | Train accuracy: 0.771|Val. Loss: 0.393 | Val accuracy: 0.657\n",
            "Epoch: 04 |Train Loss: 0.233 | Train accuracy: 0.790|Val. Loss: 0.368 | Val accuracy: 0.672\n",
            "Epoch: 05 |Train Loss: 0.218 | Train accuracy: 0.804|Val. Loss: 0.367 | Val accuracy: 0.679\n",
            "Epoch: 06 |Train Loss: 0.209 | Train accuracy: 0.814|Val. Loss: 0.380 | Val accuracy: 0.680\n",
            "Epoch: 07 |Train Loss: 0.202 | Train accuracy: 0.820|Val. Loss: 0.367 | Val accuracy: 0.689\n",
            "Epoch: 08 |Train Loss: 0.194 | Train accuracy: 0.826|Val. Loss: 0.376 | Val accuracy: 0.686\n",
            "Epoch: 09 |Train Loss: 0.188 | Train accuracy: 0.831|Val. Loss: 0.389 | Val accuracy: 0.684\n",
            "Epoch: 10 |Train Loss: 0.183 | Train accuracy: 0.836|Val. Loss: 0.373 | Val accuracy: 0.694\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▆▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▃▂▂▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▆▇▇█▇▇█</td></tr><tr><td>val_loss</td><td>█▄▄▁▁▂▁▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.83553</td></tr><tr><td>train_loss</td><td>0.1833</td></tr><tr><td>val_accuracy</td><td>0.69446</td></tr><tr><td>val_loss</td><td>0.37348</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">winter-sweep-4</strong> at: <a href='https://wandb.ai/ed23d015/DL_Assignment_3/runs/tvfo0tc6' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3/runs/tvfo0tc6</a><br/> View project at: <a href='https://wandb.ai/ed23d015/DL_Assignment_3' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20240515_005554-tvfo0tc6\\logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vttv67s5 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dimension: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_dimension: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_dimension: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>C:\\Users\\ASL 5\\wandb\\run-20240515_013804-vttv67s5</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ed23d015/DL_Assignment_3/runs/vttv67s5' target=\"_blank\">divine-sweep-5</a></strong> to <a href='https://wandb.ai/ed23d015/DL_Assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ed23d015/DL_Assignment_3/sweeps/sf8drmdd' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3/sweeps/sf8drmdd</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ed23d015/DL_Assignment_3' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/ed23d015/DL_Assignment_3/sweeps/sf8drmdd' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3/sweeps/sf8drmdd</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ed23d015/DL_Assignment_3/runs/vttv67s5' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3/runs/vttv67s5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 |Train Loss: 0.771 | Train accuracy: 0.368|Val. Loss: 0.441 | Val accuracy: 0.576\n",
            "Epoch: 02 |Train Loss: 0.322 | Train accuracy: 0.710|Val. Loss: 0.391 | Val accuracy: 0.634\n",
            "Epoch: 03 |Train Loss: 0.267 | Train accuracy: 0.758|Val. Loss: 0.396 | Val accuracy: 0.659\n",
            "Epoch: 04 |Train Loss: 0.248 | Train accuracy: 0.776|Val. Loss: 0.382 | Val accuracy: 0.666\n",
            "Epoch: 05 |Train Loss: 0.233 | Train accuracy: 0.789|Val. Loss: 0.363 | Val accuracy: 0.678\n",
            "Epoch: 06 |Train Loss: 0.223 | Train accuracy: 0.798|Val. Loss: 0.365 | Val accuracy: 0.682\n",
            "Epoch: 07 |Train Loss: 0.214 | Train accuracy: 0.807|Val. Loss: 0.374 | Val accuracy: 0.687\n",
            "Epoch: 08 |Train Loss: 0.209 | Train accuracy: 0.812|Val. Loss: 0.362 | Val accuracy: 0.687\n",
            "Epoch: 09 |Train Loss: 0.202 | Train accuracy: 0.818|Val. Loss: 0.356 | Val accuracy: 0.691\n",
            "Epoch: 10 |Train Loss: 0.198 | Train accuracy: 0.822|Val. Loss: 0.371 | Val accuracy: 0.693\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▆▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▃▂▂▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▆▆▇▇████</td></tr><tr><td>val_loss</td><td>█▄▄▃▂▂▃▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.82182</td></tr><tr><td>train_loss</td><td>0.19806</td></tr><tr><td>val_accuracy</td><td>0.69299</td></tr><tr><td>val_loss</td><td>0.37051</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">divine-sweep-5</strong> at: <a href='https://wandb.ai/ed23d015/DL_Assignment_3/runs/vttv67s5' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3/runs/vttv67s5</a><br/> View project at: <a href='https://wandb.ai/ed23d015/DL_Assignment_3' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20240515_013804-vttv67s5\\logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pxoik5d9 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dimension: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_dimension: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_dimension: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>C:\\Users\\ASL 5\\wandb\\run-20240515_021953-pxoik5d9</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ed23d015/DL_Assignment_3/runs/pxoik5d9' target=\"_blank\">deft-sweep-6</a></strong> to <a href='https://wandb.ai/ed23d015/DL_Assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ed23d015/DL_Assignment_3/sweeps/sf8drmdd' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3/sweeps/sf8drmdd</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ed23d015/DL_Assignment_3' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/ed23d015/DL_Assignment_3/sweeps/sf8drmdd' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3/sweeps/sf8drmdd</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ed23d015/DL_Assignment_3/runs/pxoik5d9' target=\"_blank\">https://wandb.ai/ed23d015/DL_Assignment_3/runs/pxoik5d9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 |Train Loss: 0.821 | Train accuracy: 0.324|Val. Loss: 0.555 | Val accuracy: 0.452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vanilla Sequence to Sequence Model"
      ],
      "metadata": {
        "id": "4es7SQFZMaUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(model_bkl: nn.Module, iterator: torch.utils.data.DataLoader, optimizer: optim.Optimizer, criterion: nn.Module, clip: float):\n",
        "\n",
        "    model_bkl_bkl.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_accuracy = 0\n",
        "    epoch_word_accuracy = 0\n",
        "    total_charecters = 0\n",
        "    correct_charecters = 0\n",
        "    total_words = 0\n",
        "    correct_words = 0\n",
        "\n",
        "\n",
        "    for _, (source, target) in enumerate(iterator):\n",
        "        source, target = source.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model_bkl(source, target)\n",
        "        output = output[1:].view(-1, output.shape[-1])\n",
        "        target = target.permute(1,0)\n",
        "        target = torch.reshape(target[1:], (-1,))\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # calculate character level accuracy\n",
        "        preds = torch.argmax(output, dim=1)\n",
        "        non_pad_elements = (target != 0).nonzero(as_tuple=True)[0]\n",
        "        correct = preds[non_pad_elements] == target[non_pad_elements]\n",
        "        epoch_accuracy += correct.sum().item() / len(non_pad_elements)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model_bkl.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_accuracy / len(iterator)\n",
        "\n",
        "\n",
        "def evaluate(model_bkl: nn.Module,\n",
        "             iterator: torch.utils.data.DataLoader,\n",
        "             criterion: nn.Module):\n",
        "\n",
        "    model_bkl.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_accuracy = 0\n",
        "    epoch_word_accuracy = 0\n",
        "    total_charecters = 0\n",
        "    correct_charecters = 0\n",
        "    total_words = 0\n",
        "    correct_words = 0\n",
        "    solution=[]\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for _, (source, target) in enumerate(iterator):\n",
        "            source, target = source.to(device), target.to(device)\n",
        "\n",
        "            output = model_bkl(source, target, 0) #turn off teacher forcing\n",
        "\n",
        "            output = output[1:].view(-1, output.shape[-1])\n",
        "            target = target.permute(1,0)\n",
        "            target = torch.reshape(target[1:], (-1,))\n",
        "\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            # calculate accuracy\n",
        "            preds = torch.argmax(output, dim=1)\n",
        "            non_pad_elements = (target != 0).nonzero(as_tuple=True)[0]\n",
        "            correct = preds[non_pad_elements] == target[non_pad_elements]\n",
        "            epoch_accuracy += correct.sum().item() / len(non_pad_elements)\n",
        "\n",
        "            b=np.zeros((16,29))\n",
        "            for i in range(16):\n",
        "              for j in range (29):\n",
        "                 b[i][j]=preds[16*j+i]\n",
        "\n",
        "            for i in range(16):\n",
        "              solution.append(reverse_tokenize(b[i]))\n",
        "\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_accuracy / len(iterator), solution\n",
        "\n",
        "\n",
        "def epoch_time(start_time: int,\n",
        "               end_time: int):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "\n",
        "CLIP = 1\n",
        "num_epoch = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss,train_acc = train(model_bkl_bkl, train_itersn, optimizer, criterion, CLIP)\n",
        "    valid_loss,valid_accuracy,solution_valid = evaluate(model_bkl_bkl, valid_itersn, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_in_mins, epoch_in_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_in_mins}m {epoch_in_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train accuracy: {train_acc:.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} | Val accuracy: {valid_accuracy:.3f}')\n",
        "    print(solution_valid[0])\n",
        "\n",
        "test_loss,test_accuracy,solution_test_att = evaluate(model_bkl, train_itersn, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test accuracy: {test_accuracy:.3f} |')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "Y1RliBYNjSRm",
        "outputId": "646fa554-1bf6-40a4-dda7-1336eebf46da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'nn' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m criterion \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model_bkl: nn\u001b[38;5;241m.\u001b[39mModule, iterator: torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader, optimizer: optim\u001b[38;5;241m.\u001b[39mOptimizer, criterion: nn\u001b[38;5;241m.\u001b[39mModule, clip: \u001b[38;5;28mfloat\u001b[39m):\n\u001b[0;32m      9\u001b[0m     model_bkl_bkl\u001b[38;5;241m.\u001b[39mtrain()\n",
            "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vanilla implimentation on Wandb"
      ],
      "metadata": {
        "id": "8cBGRudnY5ER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'bayes', #grid, random,bayes\n",
        "    'metric': {\n",
        "      'name': 'val_accuracy',\n",
        "      'goal': 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'lr': {\n",
        "            'values': [0.001,0.0001]\n",
        "        },\n",
        "        'layer_size': {\n",
        "            'values': [1,2,3,4]\n",
        "        },\n",
        "        'cell_type':{\n",
        "            'values':['rnn','lstm','gru']\n",
        "        },\n",
        "        'dropout':{\n",
        "            'values':[0,0.2,0.4,0.6]\n",
        "        },\n",
        "        'hidden_layers':{\n",
        "            'values':[64,128,256]\n",
        "        },\n",
        "\n",
        "    }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, entity='shreyashgadgil007', project=\"CS6910-Assignment3\")\n",
        "\n",
        "def sweep_train():\n",
        "  # Default values for hyper-parameters we're going to sweep over\n",
        "  config_defaults = {\n",
        "      'lr':0.0001,\n",
        "      'layer_size':4,\n",
        "      'cell_type':'lstm',\n",
        "      'dropout':0.4,\n",
        "      'hidden_layers':128,\n",
        "  }\n",
        "\n",
        "  # Initialize a new wandb run\n",
        "  wandb.init(project='CS6910-Assignment3', entity='shreyashgadgil007',config=config_defaults)\n",
        "  wandb.run.name = 'cell:'+ str(wandb.config.cell_type)+' ;lr:'+str(wandb.config.lr)+ ' ;layer_size:'+str(wandb.config.layer_size)+ ' ;dropout:'+str(wandb.config.dropout)+' ;hidden:'+str(wandb.config.hidden_layers)\n",
        "  config = wandb.config\n",
        "  lr = config.lr\n",
        "  layer_size = config.layer_size\n",
        "  cell_type = config.cell_type\n",
        "  hidden_layers = config.hidden_layers\n",
        "  dropout = config.dropout\n",
        "  # Model training here\n",
        "\n",
        "  input_size_encoder = len(eng_token_map)\n",
        "  output_size=input_size_decoder=len(mar_token_map)\n",
        "\n",
        "  encoder_embedding_size=29\n",
        "  decoder_embedding_size=67\n",
        "  encoder_net=Encoder(input_size_encoder,encoder_embedding_size,hidden_layers,layer_size,cell_type,p=dropout).to(device)\n",
        "  decoder_net=Decoder(input_size_decoder,decoder_embedding_size,hidden_layers,output_size,layer_size,cell_type,p=dropout).to(device)\n",
        "  model=Seq2Seq(encoder_net,decoder_net,cell_type).to(device)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  import math\n",
        "  import time\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(),lr=lr)\n",
        "  model.train()\n",
        "\n",
        "  training_epoch_loss = 0\n",
        "  training_epoch_accuracy = 0\n",
        "  validation_epoch_loss = 0\n",
        "  validation_epoch_accuracy = 0\n",
        "\n",
        "  N_EPOCHS = 10\n",
        "  CLIP = 1\n",
        "\n",
        "  for epoch in range(N_EPOCHS):\n",
        "\n",
        "  #TRAINING BLOCK\n",
        "    model.train()\n",
        "    for _, (source, target) in enumerate(train_iter):\n",
        "        source, target = source.to(device), target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(source, target)\n",
        "        output = output[1:].view(-1, output.shape[-1])\n",
        "        target = target.permute(1,0)\n",
        "        target = torch.reshape(target[1:], (-1,))\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # calculate accuracy\n",
        "        preds = torch.argmax(output, dim=1)\n",
        "        non_pad_elements = (target != 0).nonzero(as_tuple=True)[0]\n",
        "        train_correct = preds[non_pad_elements] == target[non_pad_elements]\n",
        "        training_epoch_accuracy += train_correct.sum().item() / len(non_pad_elements)\n",
        "        loss.backward()\n",
        "\n",
        "        #READ IF WE CAN PASS CLIP AS A HYPERPARAMETER\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        training_epoch_loss += loss.item()\n",
        "\n",
        "\n",
        "    training_epoch_loss = training_epoch_loss / len(train_iter)\n",
        "    training_epoch_accuracy = training_epoch_accuracy / len(train_iter)\n",
        "\n",
        "\n",
        "    #EVALUATION MODE\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for _, (source, target) in enumerate(valid_iter):\n",
        "            source, target = source.to(device), target.to(device)\n",
        "\n",
        "            output = model(source, target, 0) #turn off teacher forcing\n",
        "\n",
        "            output = output[1:].view(-1, output.shape[-1])\n",
        "            target = target.permute(1,0)\n",
        "            target = torch.reshape(target[1:], (-1,))\n",
        "\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            validation_epoch_loss += loss.item()\n",
        "            # calculate accuracy\n",
        "            preds = torch.argmax(output, dim=1)\n",
        "            non_pad_elements = (target != 0).nonzero(as_tuple=True)[0]\n",
        "            val_correct = preds[non_pad_elements] == target[non_pad_elements]\n",
        "            validation_epoch_accuracy += val_correct.sum().item() / len(non_pad_elements)\n",
        "\n",
        "    validation_epoch_loss = validation_epoch_loss / len(valid_iter)\n",
        "    validation_epoch_accuracy = validation_epoch_accuracy / len(valid_iter)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} |Train Loss: {training_epoch_loss:.3f} | Train accuracy: {training_epoch_accuracy:.3f}|Val. Loss: {validation_epoch_loss:.3f} | Val accuracy: {validation_epoch_accuracy:.3f}')\n",
        "    wandb.log({\"train_loss\":training_epoch_loss,\"train_accuracy\": training_epoch_accuracy,\"val_loss\":validation_epoch_loss,\"val_accuracy\":validation_epoch_accuracy},)\n",
        "    #emptying the cache after one complete run\n",
        "    if epoch==N_EPOCHS-1:\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "#RUNNING THE SWEEP\n",
        "wandb.agent(sweep_id, function=sweep_train, count=120)\n"
      ],
      "metadata": {
        "id": "7XilzV75Y2XS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CSV files and Word level accuracy"
      ],
      "metadata": {
        "id": "u6_EGlcOZHok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#removing end of sentence token\n",
        "solution_test_att = [word.replace('.', '') for word in solution_test_att]\n",
        "solution_test = [word.replace('.', '') for word in solution_test]\n",
        "def calculate_accuracy(list1, list2):\n",
        "    total_words = len(list1)\n",
        "    correct_words = 0\n",
        "\n",
        "    for word1, word2 in zip(list1, list2):\n",
        "        if word1 == word2:\n",
        "            correct_words += 1\n",
        "\n",
        "    accuracy = correct_words / total_words * 100\n",
        "    return accuracy\n",
        "\n",
        "vanilla_seq2seq_accuracy=calculate_accuracy(test_ma,solution_test)\n",
        "attention_seq2seq_accuracy=calculate_accuracy(test_ma,solution_test_att)\n",
        "print('vanilla_seq2seq_Acc.:',vanilla_seq2seq_accuracy)\n",
        "print('attention_seq2seq_Acc.:',attention_seq2seq_accuracy)"
      ],
      "metadata": {
        "id": "PTv4z41cZFno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Predictions_attention.csv'\n",
        "with open(file_path, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Write the column headers\n",
        "    writer.writerow(['ENGLISH', 'HINDI_translation', 'Attention_seq2seq_pred'])\n",
        "\n",
        "    # Write the data rows\n",
        "    for row in zip(test_en, test_ma, solution_test_att):\n",
        "        writer.writerow(row)"
      ],
      "metadata": {
        "id": "TS3P4TLMawgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "file_path = '/content/drive/MyDrive/Predictions_vanilla.csv'\n",
        "with open(file_path, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Write the column headers\n",
        "    writer.writerow(['ENGLISH', 'HINDI_translation', 'Vanilla_seq2seq_pred'])\n",
        "\n",
        "    # Write the data rows\n",
        "    for row in zip(test_en, test_ma, solution_test):\n",
        "        writer.writerow(row)"
      ],
      "metadata": {
        "id": "rrK51JlnayWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pay \"Attension\" Here!! remove the code below"
      ],
      "metadata": {
        "id": "Hhf_JITdNWi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size: int, embedding_dim: int, hidden_size: int, num_layers=1, cell_type='LSTM', bidirectional=False, dropout=0):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_size, embedding_dim)\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        if cell_type == 'LSTM':\n",
        "            self.rnn = nn.LSTM(embedding_dim, hidden_size, num_layers=num_layers, bidirectional=bidirectional, dropout=dropout)\n",
        "        elif cell_type == 'GRU':\n",
        "            self.rnn = nn.GRU(embedding_dim, hidden_size, num_layers=num_layers, bidirectional=bidirectional, dropout=dropout)\n",
        "        elif cell_type == 'RNN':\n",
        "            self.rnn = nn.RNN(embedding_dim, hidden_size, num_layers=num_layers, bidirectional=bidirectional, dropout=dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "        return outputs, (hidden, cell)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_size, embedding_dim, hidden_size, num_layers=1, cell_type='LSTM', dropout=0, beam_search=False, beam_size=1):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, embedding_dim)\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.beam_search = beam_search\n",
        "        self.beam_size = beam_size\n",
        "\n",
        "        if cell_type == 'LSTM':\n",
        "            self.rnn = nn.LSTM(embedding_dim, hidden_size, num_layers=num_layers, dropout=dropout)\n",
        "        elif cell_type == 'GRU':\n",
        "            self.rnn = nn.GRU(embedding_dim, hidden_size, num_layers=num_layers, dropout=dropout)\n",
        "        elif cell_type == 'RNN':\n",
        "            self.rnn = nn.RNN(embedding_dim, hidden_size, num_layers=num_layers, dropout=dropout)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self,\n",
        "                decoder_hidden: Tensor,\n",
        "                encoder_outputs: Tensor) -> Tensor:\n",
        "\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "\n",
        "        repeated_decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        energy = torch.tanh(self.attn(torch.cat((\n",
        "            repeated_decoder_hidden,\n",
        "            encoder_outputs),\n",
        "            dim = 2)))\n",
        "\n",
        "        attention = torch.sum(energy, dim=2)\n",
        "\n",
        "        return F.softmax(attention, dim=1)\n",
        "\n",
        "\n",
        "    '''\n",
        "    def forward(self, x, hidden, cell=None):\n",
        "\n",
        "        if self.beam_search:\n",
        "            return self.beam_search_decoder(x, hidden)\n",
        "        else:\n",
        "            return self.teacher_forcing(x, hidden, cell)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def teacher_forcing(self, x, hidden, cell):\n",
        "        x = x.unsqueeze(0)\n",
        "        print(\"x is here: \",x)\n",
        "        print(\"hidden: \", hidden.shape)\n",
        "        embedded = self.embedding(x)\n",
        "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "        prediction = self.fc(output.squeeze(0))\n",
        "        return prediction, hidden, cell\n",
        "\n",
        "    def beam_search_decoder(self, x, hidden):  # Beter then greedy search\n",
        "        #print(\"x_shape: \", x.shape)\n",
        "        batch_size = x.shape[0]\n",
        "        target_len = 1  # Beam search for single token at a time\n",
        "\n",
        "        outputs = torch.zeros(target_len, batch_size, self.output_size).to(x.device)\n",
        "        sequences = [[[0], 0.0, hidden]]\n",
        "\n",
        "        for _ in range(target_len):\n",
        "            all_candidates = []\n",
        "            for i in range(len(sequences)):\n",
        "                #print(\"sequences: \", sequences)\n",
        "                seq, score, hidden = sequences[i]\n",
        "                print(\"seq: \", seq)\n",
        "                print(\"score: \", score)\n",
        "                print(\"hidden: \", hidden.shape)\n",
        "                print(\"x: \",x)\n",
        "                x = torch.tensor([seq[-1]]).unsqueeze(0).unsqueeze(0).to(x.device)  # Fix here\n",
        "                #x = torch.tensor([seq[-1]]).unsqueeze(0).to(x.device)\n",
        "                print(\"x after: \",x)\n",
        "                embedded = self.embedding(x)\n",
        "                output, (hidden, cell) = self.rnn(embedded, hidden)\n",
        "                log_prob = nn.functional.log_softmax(output, dim=1)\n",
        "                topk_log_prob, topk_indices = torch.topk(log_prob, self.beam_size)\n",
        "                for j in range(self.beam_size):\n",
        "                    candidate_seq = seq + [topk_indices[0][0][j].item()]\n",
        "                    candidate_score = score + topk_log_prob[0][0][j].item()\n",
        "                    all_candidates.append([candidate_seq, candidate_score, hidden])\n",
        "            ordered = sorted(all_candidates, key=lambda tup:tup[1], reverse=True)\n",
        "            sequences = ordered[:self.beam_size]\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            outputs[0][i][sequences[i][0][-1]] = 1.0\n",
        "\n",
        "        return outputs, sequences[0][2]\n",
        "        '''\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
        "        batch_size = source.shape[1]\n",
        "        target_len = target.shape[0]\n",
        "        target_vocab_size = self.decoder.output_size\n",
        "\n",
        "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(source.device)\n",
        "\n",
        "        encoder_outputs, (hidden, cell) = self.encoder(source)\n",
        "\n",
        "        x = target[0]\n",
        "\n",
        "        for t in range(1, target_len):\n",
        "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
        "            outputs[t] = output\n",
        "            teacher_force = np.random.random() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1)\n",
        "            x = target[t] if teacher_force else top1\n",
        "\n",
        "        return outputs\n",
        "\n",
        "# Example usage:\n",
        "input_size = len(eng_token_map)\n",
        "output_size = len(hin_token_map)\n",
        "encoder_embedding_dim = 64\n",
        "decoder_embedding_dim = 64\n",
        "hidden_size = 128\n",
        "num_encoder_layers = 2\n",
        "num_decoder_layers = 2\n",
        "encoder_bidirectional = True\n",
        "encoder_dropout = 0.1\n",
        "decoder_dropout = 0.1\n",
        "beam_search = True\n",
        "beam_size = 3\n",
        "\n",
        "encoder = Encoder(input_size, encoder_embedding_dim, hidden_size, num_layers=num_encoder_layers, cell_type='LSTM', bidirectional=encoder_bidirectional, dropout=encoder_dropout)\n",
        "decoder = Decoder(output_size, decoder_embedding_dim, hidden_size, num_layers=num_decoder_layers, cell_type='LSTM', dropout=decoder_dropout, beam_search=beam_search, beam_size=beam_size)\n",
        "\n",
        "model = Seq2Seq(encoder, decoder)\n",
        "\n",
        "# Example input and output tensors\n",
        "source = torch.randint(0, input_size, (10, 32))  # (seq_len, batch_size)\n",
        "target = torch.randint(0, output_size, (8, 32))  # (seq_len, batch_size)\n",
        "\n",
        "output = model(source, target)\n",
        "print(output.shape)  # Output shape: (target_seq_len, batch_size, output_vocab_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "xs4TVE_oho5d",
        "outputId": "5073aa37-36fc-466f-8808-5f738de1bb36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x is here:  tensor([[11, 23, 29, 26, 28, 28, 18, 53, 50,  9, 26, 16,  1, 25, 45, 28, 23,  0,\n",
            "         54,  9, 18, 23, 58, 50,  9, 55, 34, 44, 10, 35, 63,  6]])\n",
            "hidden:  torch.Size([4, 32, 128])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected hidden[0] size (2, 32, 128), got [4, 32, 128]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-66eb85f08958>\u001b[0m in \u001b[0;36m<cell line: 148>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (seq_len, batch_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Output shape: (target_seq_len, batch_size, output_vocab_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-66eb85f08958>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, source, target, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mteacher_force\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-66eb85f08958>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden, cell)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteacher_forcing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         '''\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteacher_forcing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-66eb85f08958>\u001b[0m in \u001b[0;36mteacher_forcing\u001b[0;34m(self, x, hidden, cell)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hidden: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;31m# Each batch of the hidden state should match the input sequence that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0;31m# the user believes he/she is passing in.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m                 \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    788\u001b[0m                            ):\n\u001b[1;32m    789\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         self.check_hidden_size(hidden[0], self.get_expected_hidden_size(input, batch_sizes),\n\u001b[0m\u001b[1;32m    791\u001b[0m                                'Expected hidden[0] size {}, got {}')\n\u001b[1;32m    792\u001b[0m         self.check_hidden_size(hidden[1], self.get_expected_cell_size(input, batch_sizes),\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    257\u001b[0m                           msg: str = 'Expected hidden size {}, got {}') -> None:\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_weights_have_changed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden[0] size (2, 32, 128), got [4, 32, 128]"
          ]
        }
      ]
    }
  ]
}